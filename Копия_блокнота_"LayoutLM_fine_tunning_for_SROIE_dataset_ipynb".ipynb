{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"LayoutLM fine tunning for SROIE dataset.ipynb\"",
      "provenance": [],
      "collapsed_sections": [
        "NKI4qpxUP-dk"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChicoQ/my-bookmarks/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22LayoutLM_fine_tunning_for_SROIE_dataset_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhsgXwhFoXaf"
      },
      "source": [
        "# Fine tune SROIE on LayoutLM\n",
        "This notebook is an effort to fine tune the LayoutLM model for the SROIE dataset. The model is presented in the paper \"[LayoutLM: Pre-training of Text and Layout for Document Image Understanding](https://arxiv.org/abs/1912.13318)\" by Yiheng Xu, Minghao Li, Lei Cui, Shaohan Huang, Furu Wei and Ming Zhou. \n",
        "\n",
        "- Git-hub repo [here](https://github.com/microsoft/unilm/tree/master/layoutlm).\n",
        "\n",
        "- Read about the SROIE competition and dataset [here](https://rrc.cvc.uab.es/?ch=13).\n",
        "\n",
        "- Inspiration from this Kaggle notebook [here](https://www.kaggle.com/jpmiller/layoutlm-starter)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySxxGRALM1E-"
      },
      "source": [
        "##Notes:\n",
        "- The repo includes a pre processing script and fune tunning for the FUNSD dataset, but not for the SROIE dataset (though the paper includes computations on the SROIE dataset). So this notebook intends to fill that gap\n",
        "\n",
        "- I have used my google drive to manage the files. If you want to use it, just change the folder names (both the ones where you keep the SROIE files and also were you keep the LayoutLM files)\n",
        "\n",
        "- The best f1 results on the predicitons I got were between 93%~ 94.5%, which is a bit less than the value presented in the paper (~94%/95%). The differences may be explained by \n",
        "  - different parameters (I haven't done an exaustive grid search)\n",
        "  - different sampling\n",
        "  - different pre processing. This one is far from perfect, some labels and invoices are lost in the way. \n",
        "  - different OCR base. As I understood, the authors also did their own OCR, while I run from th one provided in the dataset\n",
        "  - I was having difficulties with the label \"company address\" so I have dropped it\n",
        "  - any other differences, as the paper doesn't explain this fine tunning in detail\n",
        "\n",
        "- Make sure you have GPU enabled on the notebook (Edit->Notebook settings)\n",
        "\n",
        "- Yes I know, the code is horrible and badly explained, sorry for that. Nevertheless, hope it helps somehow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgkoxJF8P7Gw"
      },
      "source": [
        "# 1. Pre-process dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEOrg6ePPzj9"
      },
      "source": [
        "# Imports  \n",
        "import os\n",
        "import pandas as pd\n",
        "import glob\n",
        "import json \n",
        "import ast\n",
        "import re\n",
        "import random"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSmwMiADoV8y",
        "outputId": "f0aaaed9-3dbe-42d8-bc79-894c5e34dd0a"
      },
      "source": [
        "# Connection to google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ7VWGtnQZVB"
      },
      "source": [
        "# Define path for the dataset files (you should previously download the dataset from the link given at the header of the notebook)\n",
        "# This is the folder with the files that contain the bounding boxes and the words\n",
        "spath_words = '/content/drive/My Drive/data/layoutml/'\n",
        "os.chdir(spath_words)\n",
        "# Create a dataframe to store and manage the invoices bounding boxes and words\n",
        "df_sentences = pd.DataFrame(columns=['filename', 'sentence'])\n",
        "\n",
        "# Loops over every file in the folder\n",
        "for file in glob.glob(\"*.txt\"):\n",
        "  try:\n",
        "    # Treat each invoice as a sentence and a row of the df\n",
        "    sfullpath = spath_words + file\n",
        "    df_file = pd.read_csv(sfullpath, header=None, names=['x0', 'y0', 'x1', 'y1', 'x2', 'y2', 'x3', 'y3', 'words'])\n",
        "    if not df_file['words'].isnull().values.any():\n",
        "      sentence_list = [str(i) for i in df_file['words']]\n",
        "      bbox_list = []\n",
        "      for index, row in df_file.iterrows():\n",
        "        bbox_list.append([row['x0'],row['y0'],row['x2'],row['y2']])\n",
        "      new_row = {'filename':file, 'sentence':sentence_list, 'bboxes':bbox_list}\n",
        "      # Append row to the dataframe\n",
        "      df_sentences = df_sentences.append(new_row, ignore_index=True)\n",
        "  except Exception as e:\n",
        "    # There are a few problems, we will just ignore them and print the error associated with it\n",
        "    print(file + \" | \" + repr(e))"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "wKyx3Ap6s6kP",
        "outputId": "0acd4560-ef15-4f83-ff14-f4c439cc900d"
      },
      "source": [
        "df_sentences"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-39566b95f103>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_sentences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df_sentences' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mysx1l8QZRN",
        "outputId": "f2383438-000b-49be-ee6a-c2e829db220b"
      },
      "source": [
        "# Define path for the dataset files (you should previously download the dataset from the link given at the header of the notebook)\n",
        "# This is the folder with the files that contain the values (company name, date, address and total)\n",
        "spath_labels = '/content/drive/My Drive/data/layoutml/'\n",
        "os.chdir(spath_labels)\n",
        "# Create a dataframe to store and manage the invoices tags\n",
        "df_labels = pd.DataFrame(columns=['filename', 'value_company', 'value_date', 'value_address', 'value_total'])\n",
        "\n",
        "for file in glob.glob(\"*.txt\"):\n",
        "  try:\n",
        "    with open(file, 'r') as fileread:\n",
        "      data = res = json.loads(fileread.read()) \n",
        "    new_row = {'filename':file, 'value_company':data['company'], 'value_date':data['date'], 'value_address':data['address'], 'value_total':data['total']}\n",
        "    # Append row to the dataframe\n",
        "    df_labels = df_labels.append(new_row, ignore_index=True)\n",
        "  except Exception as e:\n",
        "    print(file + \" | \" + repr(e))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X51005663280(1).txt | KeyError('address',)\n",
            "X51005663280.txt | KeyError('address',)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBrnDgl1QZPr"
      },
      "source": [
        "# Now let's merge the two dataframes based on the filename\n",
        "df = pd.merge(df_sentences,df_labels,on='filename')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzOtABk5sa3o"
      },
      "source": [
        "# In case you want to store the df on drive (to avoid running the previous cells again and again), just uncomment this cell\n",
        "#os.chdir('/content/drive/My Drive/Datasets/SROIE2019/')\n",
        "#df.to_csv('df.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4loa38UeswtT"
      },
      "source": [
        "# In case the df is stored on drive, just uncomment this cell\n",
        "df = pd.read_csv('/content/drive/MyDrive/data/layoutml/df.csv')\n",
        "    #'/content/drive/My Drive/Datasets/SROIE2019/df.csv')\n",
        "df = df.drop(['Unnamed: 0'], axis=1)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMUshjyKQZMO"
      },
      "source": [
        "# Drop unecessary column and parse data (need to avoid some quotes inside the lists)\n",
        "df['sentence'] = df['sentence'].map(lambda a: ast.literal_eval(a))\n",
        "df['bboxes'] = df['bboxes'].map(lambda a: ast.literal_eval(a))"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "d5adQ_5_QZIK",
        "outputId": "fed78371-dfea-452d-92b7-d8e000dbb693"
      },
      "source": [
        "df.head(5)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>sentence</th>\n",
              "      <th>bboxes</th>\n",
              "      <th>value_company</th>\n",
              "      <th>value_date</th>\n",
              "      <th>value_address</th>\n",
              "      <th>value_total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>X51006555072.txt</td>\n",
              "      <td>[DIGI TELECOMMUNICATIONS SDN BHD, (201283-M), ...</td>\n",
              "      <td>[[106, 179, 502, 204], [239, 205, 364, 231], [...</td>\n",
              "      <td>DIGI TELECOMMUNICATIONS SDN BHD</td>\n",
              "      <td>13/10/2017</td>\n",
              "      <td>LOT LG 315, 1-UTAMA SHOPPING CENTRE, LEBUH BAN...</td>\n",
              "      <td>234.40</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>X51006557117.txt</td>\n",
              "      <td>[GARDENIA BAKERIES (KL) SDN BHD (139386 X), LO...</td>\n",
              "      <td>[[35, 87, 590, 110], [172, 109, 448, 133], [16...</td>\n",
              "      <td>GARDENIA BAKERIES (KL) SDN BHD</td>\n",
              "      <td>30/10/2017</td>\n",
              "      <td>LOT 3, JALAN PELABUR 23/1, 40300 SHAH ALAM, SE...</td>\n",
              "      <td>62.60</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>X51005568884.txt</td>\n",
              "      <td>[MR. D.I.Y. SDN BHD, (CO.REG :704427-T), LOT 1...</td>\n",
              "      <td>[[259, 337, 632, 374], [241, 380, 627, 421], [...</td>\n",
              "      <td>MR. D.I.Y. SDN BHD</td>\n",
              "      <td>24-11-17</td>\n",
              "      <td>LOT 1851-A &amp; 1851-B, JALAN KPB 6, KAWASAN PERI...</td>\n",
              "      <td>RM 3.90</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>X51005711441.txt</td>\n",
              "      <td>[RESTORAN WAN SHENG, 002043319-W, NO.2, SEKSYE...</td>\n",
              "      <td>[[224, 266, 553, 308], [282, 316, 484, 350], [...</td>\n",
              "      <td>RESTORAN WAN SHENG</td>\n",
              "      <td>21-03-2018</td>\n",
              "      <td>NO.2, JALAN TEMENGGUNG 19/9, SEKSYEN 9, BANDAR...</td>\n",
              "      <td>6.70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>X51005757304(1).txt</td>\n",
              "      <td>[#000002 BAIFU (M) SDN BHD, COMPANY NO(814198-...</td>\n",
              "      <td>[[147, 153, 549, 193], [195, 193, 514, 226], [...</td>\n",
              "      <td>BAIFU (M) SDN BHD</td>\n",
              "      <td>20/03/2018</td>\n",
              "      <td>DAISO JAPAN, IOI MALL</td>\n",
              "      <td>35.40</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              filename  ... value_total\n",
              "0     X51006555072.txt  ...      234.40\n",
              "1     X51006557117.txt  ...       62.60\n",
              "2     X51005568884.txt  ...     RM 3.90\n",
              "3     X51005711441.txt  ...        6.70\n",
              "4  X51005757304(1).txt  ...       35.40\n",
              "\n",
              "[5 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bL2puOnnQZFA"
      },
      "source": [
        "# Define some auxiliary functions\n",
        "def a_in_x(A, X):\n",
        "  '''\n",
        "  Returns list with indexes of elements of list X which contain A\n",
        "  '''\n",
        "  l = []\n",
        "  for i in range(len(X) - len(A) + 1):\n",
        "    if str(A[0]) in str(X[i:i+len(A)][0]): \n",
        "      l.append(i)\n",
        "  return l\n",
        "\n",
        "def flat_list_one_level(l):\n",
        "  '''\n",
        "  Flattens list\n",
        "  Doesn't include second level list of lists, only first level\n",
        "  '''\n",
        "  flat_list = []\n",
        "  for sublist in l:\n",
        "    if type(sublist) is list:\n",
        "      for item in sublist:\n",
        "          flat_list.append(item)\n",
        "    else:\n",
        "      flat_list.append(sublist)\n",
        "  return flat_list\n",
        "\n",
        "def flat_list_one_level_list_of_lists(l):\n",
        "  '''\n",
        "  Flattens list\n",
        "  Flattens only the first element of the sub-list\n",
        "  '''\n",
        "  flat_list = []\n",
        "  for sublist in l:\n",
        "    if type(sublist) is list and len(sublist) > 0 and type(sublist[0]) is list:\n",
        "      for item in sublist:\n",
        "        flat_list.append(item)\n",
        "    else:\n",
        "      flat_list.append(sublist)\n",
        "  return flat_list\n",
        "    \n",
        "def intersperse(lst, item):\n",
        "  '''\n",
        "  Places an item between elements of a list\n",
        "  '''\n",
        "  result = [item] * (len(lst) * 2 - 1)\n",
        "  result[0::2] = lst\n",
        "  return result\n",
        "\n",
        "def split_box(box, n_splits):\n",
        "  '''\n",
        "  Splits a bbox [x0,y0,x1,y1] by its coordinates into n_splits bboxes of equal size\n",
        "  '''\n",
        "  boxs_splitted = []\n",
        "  x0 = box[0]\n",
        "  y0 = box[1]\n",
        "  x1 = box[2]\n",
        "  y1 = box[3]\n",
        "  width = x1 - x0\n",
        "  for i_split in range(0, n_splits):\n",
        "    boxs_splitted.append([x0 + i_split * int(width/n_splits), y0, x0 + (i_split + 1) * int(width/n_splits), y1])\n",
        "  return boxs_splitted\n",
        "\n",
        "def split_box_weighted(box, l_splits):\n",
        "  '''\n",
        "  Splits a bbox [x0,y0,x1,y1] by its coordinates into len(l_splits)\n",
        "  The size of each bbox is proportional to the weight present in l_splits\n",
        "  '''\n",
        "  boxs_splitted = []\n",
        "  x0 = box[0]\n",
        "  y0 = box[1]\n",
        "  x1 = box[2]\n",
        "  y1 = box[3]\n",
        "  width = x1 - x0\n",
        "  sum_splits = sum(l_splits)\n",
        "  for i_split in l_splits:\n",
        "    split_fraction = i_split/sum_splits\n",
        "    x1f = x0 + int(width * split_fraction)\n",
        "    boxs_splitted.append([x0, y0, x1f, y1])\n",
        "    x0 = x1f\n",
        "  return boxs_splitted"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TyMuxO6CQZB8"
      },
      "source": [
        "# Define function to set the labels to the words\n",
        "def define_labels(pos, sent, labels, bbox, class_value, classification, label_other = 'O'):\n",
        "  # Pos is a list whith the position of the words associated with this label\n",
        "  # So this loops each group of words which has some relation to the label\n",
        "  for i_pos in pos:\n",
        "    if sent[i_pos] == class_value:\n",
        "      # If the group of words is equal to the class value, then this group of words is attributted the label\n",
        "      labels[i_pos] = classification\n",
        "    else:\n",
        "      # The value is contained within the group of words, so we have to split the group (ex: [... , \"Date: 01/01/2020\", ...] -> [..., [\"Date: \", \"01/01/2020\"], ...])\n",
        "      # We start by replacing the group of words by a splitted list \n",
        "      sent[i_pos] = intersperse(sent[i_pos].split(str(class_value)), str(class_value))\n",
        "      # This split leaves a white space element at the initial or final position, so we have to remove it\n",
        "      if sent[i_pos][0].isspace() or len(sent[i_pos][0])==0: sent[i_pos] = sent[i_pos][1:]\n",
        "      if sent[i_pos][-1].isspace() or len(sent[i_pos][-1])==0: sent[i_pos] = sent[i_pos][0:-1]\n",
        "      # Now we may associate the labels with the correct group of words (ex: [... , \"Date: 01/01/2020\", ...] -> [..., [\"Date: \", \"01/01/2020\"], ...], the labels would be [..., [\"O\", \"B-DATE\"], ...])\n",
        "      labels[i_pos] = [classification if s == class_value else label_other for s in sent[i_pos]]\n",
        "      # The bounding boxes should also be splitted\n",
        "      # Here we do it proportionally to the number of chars of the words\n",
        "      bbox[i_pos] = split_box_weighted(bbox[i_pos], [len(i) for i in sent[i_pos]])\n",
        "\n",
        "  # The obtained lists have now some second level lists, so we have to flatten\n",
        "  sent = flat_list_one_level(sent)\n",
        "  labels = flat_list_one_level(labels)\n",
        "  bbox = flat_list_one_level_list_of_lists(bbox)\n",
        "  return sent, labels, bbox"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a1aaCv6uQY93"
      },
      "source": [
        "# Finally the loop to create lists with the sentences and their corresponding labels and bboxes\n",
        "sentences_list = []\n",
        "labels_list = []\n",
        "bbox_list = []\n",
        "class_other = 'O'\n",
        "for index, row in df.iterrows():\n",
        "  labels = [class_other] * len(row['sentence'])\n",
        "  sent = row['sentence'].copy()\n",
        "  bbox = row['bboxes'].copy()\n",
        "  \n",
        "  # Define labels for date\n",
        "  class_value = row['value_date']\n",
        "  classification = 'B-DATE'\n",
        "  pos = a_in_x([class_value], sent)\n",
        "  if len(pos) > 0:\n",
        "    sent, labels, bbox = define_labels(pos, sent, labels, bbox, class_value, classification)\n",
        "  \n",
        "  # Define labels for total value\n",
        "  class_value = row['value_total']\n",
        "  classification = 'B-TOTAL'\n",
        "  pos = a_in_x([class_value], sent)\n",
        "  if len(pos) > 0:\n",
        "    sent, labels, bbox = define_labels(pos, sent, labels, bbox, class_value, classification)  \n",
        "\n",
        "  # Define labels for company name\n",
        "  class_value = row['value_company']\n",
        "  classification = 'B-COMPANY'\n",
        "  pos = a_in_x([class_value], sent)\n",
        "  if len(pos) > 0:\n",
        "    sent, labels, bbox = define_labels(pos, sent, labels, bbox, class_value, classification)\n",
        "\n",
        "  # Define labels for address \n",
        "  # class_value = row['value_address']\n",
        "  # classification = 'B-ADDRESS'\n",
        "  # pos = a_in_x([class_value], sent)\n",
        "  # if len(pos) > 0:\n",
        "  #   sent, labels, bbox = define_labels(pos, sent, labels, bbox, class_value, classification)\n",
        "\n",
        "  # Appends the group of words, labels and bboxes to lists\n",
        "  sentences_list.append(sent.copy())\n",
        "  labels_list.append(labels.copy())\n",
        "  bbox_list.append(bbox.copy())"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJyX76wIjKMz"
      },
      "source": [
        "At this point we have lists in which the elements are also lists (groups of words)\n",
        "\n",
        "In order to discretize the problem, we should split the groups of words into single words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "utJcFc73exM4"
      },
      "source": [
        "def break_sentences(sl, bl, ll):\n",
        "  sentences_list_temp = []\n",
        "  bbox_list_temp = []\n",
        "  labels_list_temp = []\n",
        "  for sents, labels, boxs in zip(sl, bl, ll):\n",
        "    sentences_list3 = []\n",
        "    bbox_list3 = []\n",
        "    labels_list3 = []\n",
        "    for sent, label, box in zip(sents, labels, boxs):\n",
        "      word_tokens = sent.split(\" \")\n",
        "      # Strip white spaces\n",
        "      word_tokens = [w for w in word_tokens if (w != \"\" and w != \" \")] \n",
        "      sentences_list3.extend(word_tokens)\n",
        "      splitted_boxes = split_box_weighted(box, [len(i) for i in word_tokens])\n",
        "      bbox_list3.extend(splitted_boxes)\n",
        "      # BO\n",
        "      labels_list3.extend([label] * len(word_tokens))\n",
        "      # BIO\n",
        "      #labels_list3.extend([label] + [label.replace('B-','I-')] * (len(word_tokens) - 1))\n",
        "    sentences_list_temp.append(sentences_list3)\n",
        "    bbox_list_temp.append(bbox_list3)\n",
        "    labels_list_temp.append(labels_list3)\n",
        "  return sentences_list_temp, bbox_list_temp, labels_list_temp"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IwIpq3aexH2"
      },
      "source": [
        "sentences_list, bbox_list, labels_list = break_sentences(sentences_list, labels_list, bbox_list)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JV9kuYURtNji",
        "outputId": "2efb4b0c-bcd1-4746-99c3-52ae3cd94436"
      },
      "source": [
        "# Check the first invoice data\n",
        "for s, l, b in zip(sentences_list[0],labels_list[0],bbox_list[0]):\n",
        "  print(\"{}\\t\\t{}\\t\\t{}\".format(s,l,b))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DIGI\t\tB-COMPANY\t\t[106, 179, 162, 204]\n",
            "TELECOMMUNICATIONS\t\tB-COMPANY\t\t[162, 179, 416, 204]\n",
            "SDN\t\tB-COMPANY\t\t[416, 179, 458, 204]\n",
            "BHD\t\tB-COMPANY\t\t[458, 179, 500, 204]\n",
            "(201283-M)\t\tO\t\t[239, 205, 364, 231]\n",
            "LOT\t\tO\t\t[80, 229, 252, 256]\n",
            "LG\t\tO\t\t[252, 229, 366, 256]\n",
            "315\t\tO\t\t[366, 229, 538, 256]\n",
            "LEBUH\t\tO\t\t[98, 255, 169, 280]\n",
            "BANDAR\t\tO\t\t[169, 255, 254, 280]\n",
            "UTAMA-BANDAR\t\tO\t\t[254, 255, 425, 280]\n",
            "UTAMA\t\tO\t\t[425, 255, 496, 280]\n",
            "PETALING\t\tO\t\t[172, 278, 343, 307]\n",
            "JAYA\t\tO\t\t[343, 278, 428, 307]\n",
            "SELANGOR\t\tO\t\t[247, 305, 350, 328]\n",
            "TAX\t\tO\t\t[236, 354, 277, 380]\n",
            "INVOICE\t\tO\t\t[277, 354, 374, 380]\n",
            "GST\t\tO\t\t[72, 380, 115, 406]\n",
            "REG\t\tO\t\t[115, 380, 158, 406]\n",
            "NUMBER:\t\tO\t\t[158, 380, 259, 406]\n",
            "001211957248\t\tO\t\t[335, 381, 490, 405]\n",
            "13/10/2017\t\tB-DATE\t\t[48, 429, 177, 451]\n",
            "12:35\t\tO\t\t[487, 427, 552, 453]\n",
            "POS\t\tO\t\t[48, 452, 91, 479]\n",
            "LOGIN\t\tO\t\t[91, 452, 163, 479]\n",
            "ID:\t\tO\t\t[163, 452, 206, 479]\n",
            "DMGR34013\t\tO\t\t[206, 452, 336, 479]\n",
            "STORE\t\tO\t\t[48, 480, 120, 503]\n",
            "NAME:\t\tO\t\t[120, 480, 192, 503]\n",
            "DS001-BP009\t\tO\t\t[192, 480, 350, 503]\n",
            "OSCAR\t\tO\t\t[350, 480, 422, 503]\n",
            "COLOUR\t\tO\t\t[422, 480, 508, 503]\n",
            "LAB\t\tO\t\t[508, 480, 551, 503]\n",
            "&\t\tO\t\t[57, 503, 70, 530]\n",
            "TELECOMMUNICATION\t\tO\t\t[70, 503, 302, 530]\n",
            "SDN.\t\tO\t\t[302, 503, 356, 530]\n",
            "BHD.\t\tO\t\t[356, 503, 410, 530]\n",
            "(523847-W)\t\tO\t\t[410, 503, 546, 530]\n",
            "BILL\t\tO\t\t[223, 551, 277, 576]\n",
            "PAYMENT\t\tO\t\t[277, 551, 373, 576]\n",
            "PAID\t\tO\t\t[47, 579, 104, 603]\n",
            "AMOUNT\t\tO\t\t[104, 579, 189, 603]\n",
            "234.40\t\tB-TOTAL\t\t[422, 578, 501, 603]\n",
            "SUB\t\tO\t\t[46, 603, 90, 628]\n",
            "TOTAL\t\tO\t\t[90, 603, 163, 628]\n",
            "AMOUNT\t\tO\t\t[163, 603, 251, 628]\n",
            "234.40\t\tB-TOTAL\t\t[424, 604, 503, 628]\n",
            "TOTAL\t\tO\t\t[49, 629, 119, 653]\n",
            "AMOUNT\t\tO\t\t[119, 629, 203, 653]\n",
            "234.40\t\tB-TOTAL\t\t[422, 629, 502, 653]\n",
            "CREDIT\t\tO\t\t[45, 654, 131, 678]\n",
            "CARD\t\tO\t\t[131, 654, 188, 678]\n",
            "234.40\t\tB-TOTAL\t\t[421, 653, 502, 678]\n",
            "CREDIT\t\tO\t\t[74, 679, 162, 704]\n",
            "CARD\t\tO\t\t[162, 679, 220, 704]\n",
            "NO.:XXXX\t\tO\t\t[220, 679, 337, 704]\n",
            "XXXX\t\tO\t\t[337, 679, 395, 704]\n",
            "XXXX\t\tO\t\t[395, 679, 453, 704]\n",
            "6974\t\tO\t\t[453, 679, 511, 704]\n",
            "TOTAL\t\tO\t\t[48, 730, 117, 755]\n",
            "AMOUNT\t\tO\t\t[117, 730, 200, 755]\n",
            "COLLECTED\t\tO\t\t[200, 730, 324, 755]\n",
            "234.40\t\tB-TOTAL\t\t[424, 730, 498, 753]\n",
            "CUSTOMER\t\tO\t\t[48, 754, 166, 779]\n",
            "NAME:\t\tO\t\t[166, 754, 239, 779]\n",
            "LIM\t\tO\t\t[239, 754, 283, 779]\n",
            "RUEY\t\tO\t\t[283, 754, 342, 779]\n",
            "CHYI\t\tO\t\t[342, 754, 401, 779]\n",
            "MOBILE\t\tO\t\t[45, 781, 129, 806]\n",
            "NO.:\t\tO\t\t[129, 781, 185, 806]\n",
            "60143149319\t\tO\t\t[199, 782, 340, 805]\n",
            "ACCOUNT\t\tO\t\t[48, 805, 144, 831]\n",
            "NO.:\t\tO\t\t[144, 805, 199, 831]\n",
            "1000004587104\t\tO\t\t[212, 805, 378, 832]\n",
            "CUSTOMER\t\tO\t\t[222, 833, 334, 862]\n",
            "COPY\t\tO\t\t[334, 833, 390, 862]\n",
            "THANK\t\tO\t\t[250, 881, 323, 909]\n",
            "YOU\t\tO\t\t[323, 881, 367, 909]\n",
            "HAVE\t\tO\t\t[208, 907, 272, 934]\n",
            "A\t\tO\t\t[272, 907, 288, 934]\n",
            "NICE\t\tO\t\t[288, 907, 352, 934]\n",
            "DAY\t\tO\t\t[352, 907, 400, 934]\n",
            "34013001929120171013\t\tO\t\t[172, 933, 425, 959]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCZM2Ne_jQ41"
      },
      "source": [
        "Now everything is ready to write the files in the correct format (accepted by the layoutLM process)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2G-esUmGexBk"
      },
      "source": [
        "def bbox_string(box, width, length):\n",
        "    return (\n",
        "        str(int(1000 * (box[0] / width)))\n",
        "        + \" \"\n",
        "        + str(int(1000 * (box[1] / length)))\n",
        "        + \" \"\n",
        "        + str(int(1000 * (box[2] / width)))\n",
        "        + \" \"\n",
        "        + str(int(1000 * (box[3] / length)))\n",
        "    )\n",
        "\n",
        "def actual_bbox_string(box, width, length):\n",
        "    return (\n",
        "        str(box[0])\n",
        "        + \" \"\n",
        "        + str(box[1])\n",
        "        + \" \"\n",
        "        + str(box[2])\n",
        "        + \" \"\n",
        "        + str(box[3])\n",
        "        + \"\\t\"\n",
        "        + str(width)\n",
        "        + \" \"\n",
        "        + str(length)\n",
        "    )\n",
        "\n",
        "def size(bboxes):\n",
        "  max_width = 0\n",
        "  max_height = 0\n",
        "  min_x0 = 10e8\n",
        "  min_y0 = 10e8\n",
        "  for box in bboxes:\n",
        "    if box[0] < min_x0: min_x0 = box[0]\n",
        "    if box[1] < min_y0: min_y0 = box[1]\n",
        "    if box[2] > max_width: max_width = box[2]\n",
        "    if box[3] > max_height: max_height = box[3]\n",
        "  max_width += min_x0\n",
        "  max_height += min_y0\n",
        "  return max_height, max_width"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uUKRS6uew_l"
      },
      "source": [
        "def write_files(output_dir, data_split, sentences_list, labels_list, bbox_list, split_indexes):\n",
        "  with open(\n",
        "      os.path.join(output_dir, data_split + \".txt\"),\n",
        "      \"w\",\n",
        "      encoding=\"utf8\",\n",
        "  ) as fw, open(\n",
        "      os.path.join(output_dir, data_split + \"_box.txt\"),\n",
        "      \"w\",\n",
        "      encoding=\"utf8\",\n",
        "  ) as fbw, open(\n",
        "      os.path.join(output_dir, data_split + \"_image.txt\"),\n",
        "      \"w\",\n",
        "      encoding=\"utf8\",\n",
        "  ) as fiw:\n",
        "      for index in split_indexes:\n",
        "          sent = sentences_list[index]\n",
        "          lab = labels_list[index]\n",
        "          boxes = bbox_list[index]\n",
        "          length, width = size(boxes)\n",
        "\n",
        "          for words, label, box in zip(sent, lab, boxes):\n",
        "              fw.write(\"{}\\t{}\\n\".format(words, label))\n",
        "              fbw.write(\"{}\\t{}\\n\".format(words, bbox_string(box, width, length)))\n",
        "              fiw.write(\"{}\\t{}\\t{}\\n\".format(words, actual_bbox_string(box, width, length), \"filename.jpg\"))\n",
        "          fw.write(\"\\n\")\n",
        "          fbw.write(\"\\n\")\n",
        "          fiw.write(\"\\n\")"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JPik5XFdew6e"
      },
      "source": [
        "# First we split into train and test set\n",
        "split_indexes = [*range(len(sentences_list))]\n",
        "random.Random(4).shuffle(split_indexes)\n",
        "cut = int(len(sentences_list) * 0.8)\n",
        "split_indexes_train = split_indexes[:cut]\n",
        "split_indexes_test = split_indexes[cut:]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OG_FtTFQew23"
      },
      "source": [
        "write_files('/content/drive/MyDrive/data/SROIE2019',\n",
        "    #'/content/drive/My Drive/Datasets/SROIE2019/',\n",
        "            'train', sentences_list, labels_list, bbox_list, split_indexes_train)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiEgjjPSm83z"
      },
      "source": [
        "write_files('/content/drive/MyDrive/data/SROIE2019',\n",
        "    #'/content/drive/My Drive/Datasets/SROIE2019/',\n",
        "     'test', sentences_list, labels_list, bbox_list, split_indexes_test)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKI4qpxUP-dk"
      },
      "source": [
        "# 2. Fine tune LayoutLM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaCCceLFups_"
      },
      "source": [
        "os.chdir('/content')"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KLhS7g4gQEKz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a70268f0-6612-4667-8de5-e28247a1dc93"
      },
      "source": [
        "%%bash\n",
        "git clone https://github.com/microsoft/unilm.git\n",
        "cd unilm/layoutlm\n",
        "pip install ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Processing /content/unilm/layoutlm\n",
            "Collecting transformers==2.9.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cd/38/c9527aa055241c66c4d785381eaf6f80a28c224cae97daa1f8b183b5fabb/transformers-2.9.0-py3-none-any.whl (635kB)\n",
            "Collecting tensorboardX==2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "Collecting lxml==4.5.1\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/39/0b5d76e64681243db516491bc449eff847d2708b465b60465b31ca13522e/lxml-4.5.1-cp37-cp37m-manylinux1_x86_64.whl (5.5MB)\n",
            "Collecting seqeval==0.0.12\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: Pillow==7.1.2 in /usr/local/lib/python3.7/dist-packages (from layoutlm==0.0) (7.1.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0->layoutlm==0.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0->layoutlm==0.0) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0->layoutlm==0.0) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0->layoutlm==0.0) (3.0.12)\n",
            "Collecting tokenizers==0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ea/59/bb06dd5ca53547d523422d32735585493e0103c992a52a97ba3aa3be33bf/tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6MB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0->layoutlm==0.0) (2.23.0)\n",
            "Collecting sacremoses\n",
            "  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "Collecting sentencepiece\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.0->layoutlm==0.0) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX==2.0->layoutlm==0.0) (1.15.0)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12->layoutlm==0.0) (2.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0->layoutlm==0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0->layoutlm==0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0->layoutlm==0.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0->layoutlm==0.0) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0->layoutlm==0.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0->layoutlm==0.0) (8.0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.8.0->tensorboardX==2.0->layoutlm==0.0) (56.1.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12->layoutlm==0.0) (1.4.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12->layoutlm==0.0) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from Keras>=2.2.4->seqeval==0.0.12->layoutlm==0.0) (2.10.0)\n",
            "Building wheels for collected packages: layoutlm, seqeval\n",
            "  Building wheel for layoutlm (setup.py): started\n",
            "  Building wheel for layoutlm (setup.py): finished with status 'done'\n",
            "  Created wheel for layoutlm: filename=layoutlm-0.0-cp37-none-any.whl size=11483 sha256=e609f9769f71bb0dd69c65f3c497220e04553b621fec6f39b89a49d9ccfb9939\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-_q07r_j2/wheels/e8/9a/90/87de19930fb582e6176ea7912010f101efa37def32b8ced268\n",
            "  Building wheel for seqeval (setup.py): started\n",
            "  Building wheel for seqeval (setup.py): finished with status 'done'\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp37-none-any.whl size=7424 sha256=f7c6fe328eaaa6400742aa2e40dca127030c88fb95139b5f1aaf489f9cd75c6f\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built layoutlm seqeval\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers, tensorboardX, lxml, seqeval, layoutlm\n",
            "  Found existing installation: lxml 4.2.6\n",
            "    Uninstalling lxml-4.2.6:\n",
            "      Successfully uninstalled lxml-4.2.6\n",
            "Successfully installed layoutlm-0.0 lxml-4.5.1 sacremoses-0.0.45 sentencepiece-0.1.95 seqeval-0.0.12 tensorboardX-2.0 tokenizers-0.7.0 transformers-2.9.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'unilm'...\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rWOvS1fgoja9"
      },
      "source": [
        "os.chdir('/content/unilm/layoutlm/examples/seq_labeling')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xwaathndok3P"
      },
      "source": [
        "# Move the previously created files\n",
        "%%bash\n",
        "mkdir data\n",
        "cp '/content/drive/My Drive/Datasets/SROIE2019/train.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Datasets/SROIE2019/train_box.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Datasets/SROIE2019/train_image.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Datasets/SROIE2019/test.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Datasets/SROIE2019/test_box.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Datasets/SROIE2019/test_image.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/My Drive/Datasets/SROIE2019/labels.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "# Try to remove cached files (this is optional and only important if we make changes on the input files)\n",
        "#rm '/content/unilm/layoutlm/examples/seq_labeling/data/cached_train_layoutlm-base-uncased_512'\n",
        "#rm '/content/unilm/layoutlm/examples/seq_labeling/data/cached_test_layoutlm-base-uncased_512'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36YZ2yVzQ3hn"
      },
      "source": [
        "%%bash\n",
        "mkdir data\n",
        "cp '/content/drive/MyDrive/data/SROIE2019/train.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/MyDrive/data/SROIE2019/train_box.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/MyDrive/data/SROIE2019/train_image.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/MyDrive/data/SROIE2019/test.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/MyDrive/data/SROIE2019/test_box.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/MyDrive/data/SROIE2019/test_image.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'\n",
        "cp '/content/drive/MyDrive/data/SROIE2019/labels.txt' '/content/unilm/layoutlm/examples/seq_labeling/data'"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DsmESs_9okzf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a63aaafb-7175-4196-b491-8200a4ed166b"
      },
      "source": [
        "%%bash\n",
        "ls /content/unilm/layoutlm/examples/seq_labeling/data/\n",
        "cat /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels.txt\n",
            "test_box.txt\n",
            "test_image.txt\n",
            "test.txt\n",
            "train_box.txt\n",
            "train_image.txt\n",
            "train.txt\n",
            "S-COMPANY\n",
            "S-DATE\n",
            "S-ADDRESS\n",
            "S-TOTAL\n",
            "O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ys6E6dNyokwi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94c4df0a-0849-4528-ea13-20ff64f502e0"
      },
      "source": [
        "# Check model parameters\n",
        "%%bash\n",
        "cat \"/content/drive/My Drive/Models/layoutlm-base-uncased/config.json\""
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cat: '/content/drive/My Drive/Models/layoutlm-base-uncased/config.json': No such file or directory\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyyVgZhOSJaN",
        "outputId": "a780e1bd-686c-43af-a636-9814fcaa733a"
      },
      "source": [
        "%%bash\n",
        "cat \"/content/drive/MyDrive/data/Models/config.json\""
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_2d_position_embeddings\": 1024,\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522,\n",
            "  \"model_type\": \"layoutlm\"\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6OahJzprO4-"
      },
      "source": [
        "# Want to change any model parameter? For example here I just replace the number of attention heads from 12 to 8 (the results are much better)\n",
        "%%bash\n",
        "sed -i 's/\"num_attention_heads\": 12,/\"num_attention_heads\": 8,/' \"/content/drive/My Drive/Msc/Tese/Modelos/layoutlm-base-uncased/config.json\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uItatZuHSpdM",
        "outputId": "0957560d-e702-411f-c28e-50e03cb41589"
      },
      "source": [
        "%%bash\n",
        "ls '/content/drive/MyDrive/data/Models/layoutlm-base-uncased/'\n",
        "#touch '/content/drive/MyDrive/data/Models/layoutlm-base-uncased/config.json'"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "config.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3uqnqceTZz7"
      },
      "source": [
        "%%bash\n",
        "cp '/content/drive/MyDrive/data/Models/config.json' '/content/drive/MyDrive/data/Models/layoutlm-base-uncased/config.json'"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Rc4uQtvSeln"
      },
      "source": [
        "%%bash\n",
        "sed -i 's/\"num_attention_heads\": 12,/\"num_attention_heads\": 8,/' \"/content/drive/MyDrive/data/Models/layoutlm-base-uncased/config.json\""
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v088_seqTDEB",
        "outputId": "f014fcb7-ec87-4b36-f79b-f1d45e3c9e6b"
      },
      "source": [
        "%%bash\n",
        "cat '/content/drive/MyDrive/data/Models/layoutlm-base-uncased/config.json'"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"finetuning_task\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"is_decoder\": false,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"max_2d_position_embeddings\": 1024,\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"num_labels\": 2,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pruned_heads\": {},\n",
            "  \"torchscript\": false,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 30522,\n",
            "  \"model_type\": \"layoutlm\"\n",
            "}"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgkLXCd7okvR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "4a34c2f3-f6fa-4620-e8d2-939d40b7bc3d"
      },
      "source": [
        "# Train the model\n",
        "! CUDA_LAUNCH_BLOCKING=1 python run_seq_labeling.py  --data_dir data \\\n",
        "--model_type layoutlm \\\n",
        "                            --model_name_or_path '/content/drive/MyDrive/data/Models/layoutlm-base-uncased/' \\ \n",
        "                            --do_lower_case \\\n",
        "                            --max_seq_length 512 \\\n",
        "                            --do_train \\\n",
        "                            --num_train_epochs 5.0 \\\n",
        "                            --logging_steps 10 \\\n",
        "                            --save_steps -1 \\\n",
        "                            --output_dir output1 \\\n",
        "                            --overwrite_output_dir \\\n",
        "                            --labels data/labels.txt \\\n",
        "                            --per_gpu_train_batch_size 8 \\\n",
        "                            --per_gpu_eval_batch_size 8"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-53-1587e8482807>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    --do_lower_case                             --max_seq_length 512                             --do_train                             --num_train_epochs 5.0                             --logging_steps 10                             --save_steps -1                             --output_dir output1                             --overwrite_output_dir                             --labels data/labels.txt                             --per_gpu_train_batch_size 8                             --per_gpu_eval_batch_size 8\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gceePqWlVQzl",
        "outputId": "34ea6845-83dc-4d6b-994b-3432a81b2c85"
      },
      "source": [
        "! CUDA_LAUNCH_BLOCKING=1 python run_seq_labeling.py  \\\n",
        "--data_dir data --model_type layoutlm \\\n",
        "--model_name_or_path '/content/drive/MyDrive/data/Models/layoutlm-base-uncased/' \\\n",
        "--do_lower_case --max_seq_length 512 --do_train --num_train_epochs 5.0 \\\n",
        "--logging_steps 10 \\\n",
        "--save_steps -1 \\\n",
        "--output_dir output1 \\\n",
        "--overwrite_output_dir \\\n",
        "--labels data/labels.txt \\\n",
        "--per_gpu_train_batch_size 8 \\\n",
        "--per_gpu_eval_batch_size 8"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-16 23:09:53.425615: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Epoch:   0% 0/5 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:155: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:1005.)\n",
            "  exp_avg.mul_(beta1).add_(1.0 - beta1, grad)\n",
            "\n",
            "Iteration:   1% 1/71 [00:00<01:08,  1.02it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<01:02,  1.11it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:57,  1.18it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:03<00:54,  1.24it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:03<00:51,  1.28it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:49,  1.31it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:48,  1.33it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:06<00:46,  1.35it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:06<00:45,  1.36it/s]\u001b[A/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "\n",
            "Iteration:  14% 10/71 [00:07<00:44,  1.37it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:08<00:43,  1.37it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:08<00:42,  1.38it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:09<00:41,  1.38it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:10<00:41,  1.38it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:11<00:40,  1.39it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:11<00:39,  1.39it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:12<00:38,  1.39it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:13<00:38,  1.39it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:13<00:37,  1.39it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:14<00:36,  1.39it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:15<00:36,  1.38it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:16<00:35,  1.38it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:16<00:34,  1.38it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:17<00:33,  1.38it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:18<00:33,  1.38it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:19<00:32,  1.38it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:19<00:32,  1.37it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:20<00:31,  1.37it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:21<00:30,  1.38it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:21<00:29,  1.37it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:22<00:29,  1.36it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:23<00:28,  1.36it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:24<00:27,  1.36it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:24<00:27,  1.37it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:25<00:26,  1.37it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:26<00:25,  1.36it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:27<00:24,  1.36it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:27<00:24,  1.37it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:28<00:23,  1.37it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:29<00:22,  1.37it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:29<00:21,  1.37it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:30<00:21,  1.37it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:31<00:20,  1.37it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:32<00:19,  1.37it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:32<00:18,  1.37it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:33<00:18,  1.36it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:34<00:17,  1.36it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:35<00:16,  1.36it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:35<00:16,  1.37it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:36<00:15,  1.37it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:37<00:14,  1.37it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:38<00:13,  1.37it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:38<00:13,  1.36it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:39<00:12,  1.36it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:40<00:11,  1.36it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:40<00:11,  1.36it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:41<00:10,  1.35it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:42<00:09,  1.36it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:43<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:43<00:08,  1.35it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:44<00:07,  1.35it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:45<00:06,  1.35it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:46<00:05,  1.36it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:46<00:05,  1.36it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:47<00:04,  1.36it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:48<00:03,  1.35it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:49<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:49<00:02,  1.35it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:50<00:01,  1.34it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:51<00:00,  1.35it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:52<00:00,  1.36it/s]\n",
            "Epoch:  20% 1/5 [00:52<03:28, 52.11s/it]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/71 [00:00<00:50,  1.37it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<00:50,  1.37it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:49,  1.37it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:02<00:49,  1.36it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:03<00:48,  1.36it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:47,  1.36it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:47,  1.35it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:05<00:46,  1.35it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:06<00:46,  1.35it/s]\u001b[A\n",
            "Iteration:  14% 10/71 [00:07<00:45,  1.34it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:08<00:44,  1.34it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:08<00:44,  1.34it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:09<00:43,  1.34it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:10<00:42,  1.34it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:11<00:41,  1.34it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:11<00:41,  1.34it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:12<00:40,  1.34it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:13<00:39,  1.35it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:14<00:38,  1.34it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:14<00:38,  1.34it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:15<00:37,  1.34it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:16<00:36,  1.33it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:17<00:36,  1.33it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:17<00:35,  1.33it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:18<00:34,  1.33it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:19<00:33,  1.33it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:20<00:33,  1.33it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:20<00:32,  1.33it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:21<00:31,  1.33it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:22<00:30,  1.33it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:23<00:29,  1.33it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:23<00:29,  1.33it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:24<00:28,  1.33it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:25<00:27,  1.33it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:26<00:27,  1.32it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:26<00:26,  1.32it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:27<00:25,  1.32it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:28<00:24,  1.32it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:29<00:24,  1.32it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:29<00:23,  1.32it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:30<00:22,  1.32it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:31<00:22,  1.32it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:32<00:21,  1.31it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:33<00:20,  1.31it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:33<00:19,  1.32it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:34<00:18,  1.32it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:35<00:18,  1.32it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:36<00:17,  1.32it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:36<00:16,  1.31it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:37<00:15,  1.32it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:38<00:15,  1.31it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:39<00:14,  1.32it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:39<00:13,  1.31it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:40<00:12,  1.32it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:41<00:12,  1.32it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:42<00:11,  1.32it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:42<00:10,  1.31it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:43<00:09,  1.31it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:44<00:09,  1.30it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:45<00:08,  1.31it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:45<00:07,  1.30it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:46<00:06,  1.31it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:47<00:06,  1.31it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:48<00:05,  1.30it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:49<00:04,  1.30it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:49<00:03,  1.30it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:50<00:03,  1.30it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:51<00:02,  1.30it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:52<00:01,  1.30it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:52<00:00,  1.30it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:53<00:00,  1.32it/s]\n",
            "Epoch:  40% 2/5 [01:45<02:37, 52.57s/it]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/71 [00:00<00:53,  1.30it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<00:53,  1.30it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:52,  1.30it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:03<00:51,  1.30it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:03<00:50,  1.30it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:50,  1.30it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:49,  1.29it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:06<00:48,  1.29it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:06<00:48,  1.29it/s]\u001b[A\n",
            "Iteration:  14% 10/71 [00:07<00:47,  1.29it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:08<00:46,  1.29it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:09<00:45,  1.29it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:10<00:44,  1.29it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:10<00:44,  1.30it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:11<00:43,  1.29it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:12<00:42,  1.30it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:13<00:41,  1.30it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:13<00:40,  1.29it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:14<00:40,  1.30it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:15<00:39,  1.30it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:16<00:38,  1.30it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:17<00:37,  1.29it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:17<00:37,  1.29it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:18<00:36,  1.29it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:19<00:35,  1.29it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:20<00:34,  1.29it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:20<00:34,  1.29it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:21<00:33,  1.29it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:22<00:32,  1.29it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:23<00:31,  1.29it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:23<00:30,  1.29it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:24<00:30,  1.29it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:25<00:29,  1.29it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:26<00:28,  1.29it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:27<00:28,  1.29it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:27<00:27,  1.28it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:28<00:26,  1.28it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:29<00:25,  1.28it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:30<00:24,  1.28it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:30<00:24,  1.28it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:31<00:23,  1.28it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:32<00:22,  1.28it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:33<00:21,  1.28it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:34<00:21,  1.28it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:34<00:20,  1.28it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:35<00:19,  1.28it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:36<00:18,  1.28it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:37<00:18,  1.28it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:38<00:17,  1.28it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:38<00:16,  1.27it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:39<00:15,  1.28it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:40<00:14,  1.28it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:41<00:14,  1.27it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:41<00:13,  1.27it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:42<00:12,  1.27it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:43<00:11,  1.27it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:44<00:10,  1.27it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:45<00:10,  1.27it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:45<00:09,  1.27it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:46<00:08,  1.27it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:47<00:07,  1.27it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:48<00:07,  1.27it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:49<00:06,  1.27it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:49<00:05,  1.27it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:50<00:04,  1.27it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:51<00:03,  1.27it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:52<00:03,  1.26it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:53<00:02,  1.26it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:53<00:01,  1.26it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:54<00:00,  1.27it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:55<00:00,  1.28it/s]\n",
            "Epoch:  60% 3/5 [02:41<01:46, 53.41s/it]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/71 [00:00<00:55,  1.26it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<00:54,  1.26it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:53,  1.26it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:03<00:53,  1.26it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:03<00:52,  1.26it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:51,  1.26it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:50,  1.26it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:06<00:50,  1.26it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:07<00:49,  1.25it/s]\u001b[A\n",
            "Iteration:  14% 10/71 [00:07<00:48,  1.26it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:08<00:47,  1.25it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:09<00:46,  1.26it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:10<00:46,  1.25it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:11<00:45,  1.25it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:11<00:44,  1.25it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:12<00:43,  1.26it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:13<00:42,  1.26it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:14<00:42,  1.26it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:15<00:41,  1.26it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:15<00:40,  1.26it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:16<00:39,  1.26it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:17<00:38,  1.26it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:18<00:38,  1.25it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:19<00:37,  1.25it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:19<00:36,  1.26it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:20<00:35,  1.25it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:21<00:35,  1.25it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:22<00:34,  1.25it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:23<00:33,  1.25it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:23<00:32,  1.25it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:24<00:31,  1.25it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:25<00:31,  1.25it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:26<00:30,  1.25it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:27<00:29,  1.25it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:27<00:28,  1.25it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:28<00:28,  1.25it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:29<00:27,  1.25it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:30<00:26,  1.24it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:31<00:25,  1.24it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:31<00:24,  1.25it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:32<00:24,  1.25it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:33<00:23,  1.25it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:34<00:22,  1.25it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:35<00:21,  1.25it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:35<00:20,  1.25it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:36<00:20,  1.25it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:37<00:19,  1.25it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:38<00:18,  1.25it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:39<00:17,  1.24it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:39<00:16,  1.25it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:40<00:16,  1.25it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:41<00:15,  1.24it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:42<00:14,  1.25it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:43<00:13,  1.24it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:43<00:12,  1.24it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:44<00:12,  1.24it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:45<00:11,  1.24it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:46<00:10,  1.24it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:47<00:09,  1.24it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:47<00:08,  1.24it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:48<00:08,  1.23it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:49<00:07,  1.23it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:50<00:06,  1.23it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:51<00:05,  1.23it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:52<00:04,  1.23it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:52<00:04,  1.23it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:53<00:03,  1.23it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:54<00:02,  1.24it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:55<00:01,  1.23it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:56<00:00,  1.23it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:56<00:00,  1.25it/s]\n",
            "Epoch:  80% 4/5 [03:38<00:54, 54.46s/it]\n",
            "Iteration:   0% 0/71 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/71 [00:00<00:56,  1.24it/s]\u001b[A\n",
            "Iteration:   3% 2/71 [00:01<00:55,  1.24it/s]\u001b[A\n",
            "Iteration:   4% 3/71 [00:02<00:54,  1.24it/s]\u001b[A\n",
            "Iteration:   6% 4/71 [00:03<00:54,  1.23it/s]\u001b[A\n",
            "Iteration:   7% 5/71 [00:04<00:53,  1.23it/s]\u001b[A\n",
            "Iteration:   8% 6/71 [00:04<00:52,  1.23it/s]\u001b[A\n",
            "Iteration:  10% 7/71 [00:05<00:51,  1.23it/s]\u001b[A\n",
            "Iteration:  11% 8/71 [00:06<00:51,  1.23it/s]\u001b[A\n",
            "Iteration:  13% 9/71 [00:07<00:50,  1.23it/s]\u001b[A\n",
            "Iteration:  14% 10/71 [00:08<00:49,  1.23it/s]\u001b[A\n",
            "Iteration:  15% 11/71 [00:08<00:48,  1.23it/s]\u001b[A\n",
            "Iteration:  17% 12/71 [00:09<00:47,  1.23it/s]\u001b[A\n",
            "Iteration:  18% 13/71 [00:10<00:47,  1.23it/s]\u001b[A\n",
            "Iteration:  20% 14/71 [00:11<00:46,  1.23it/s]\u001b[A\n",
            "Iteration:  21% 15/71 [00:12<00:45,  1.23it/s]\u001b[A\n",
            "Iteration:  23% 16/71 [00:12<00:44,  1.23it/s]\u001b[A\n",
            "Iteration:  24% 17/71 [00:13<00:43,  1.23it/s]\u001b[A\n",
            "Iteration:  25% 18/71 [00:14<00:43,  1.23it/s]\u001b[A\n",
            "Iteration:  27% 19/71 [00:15<00:42,  1.23it/s]\u001b[A\n",
            "Iteration:  28% 20/71 [00:16<00:41,  1.23it/s]\u001b[A\n",
            "Iteration:  30% 21/71 [00:17<00:40,  1.22it/s]\u001b[A\n",
            "Iteration:  31% 22/71 [00:17<00:39,  1.23it/s]\u001b[A\n",
            "Iteration:  32% 23/71 [00:18<00:39,  1.23it/s]\u001b[A\n",
            "Iteration:  34% 24/71 [00:19<00:38,  1.23it/s]\u001b[A\n",
            "Iteration:  35% 25/71 [00:20<00:37,  1.23it/s]\u001b[A\n",
            "Iteration:  37% 26/71 [00:21<00:36,  1.23it/s]\u001b[A\n",
            "Iteration:  38% 27/71 [00:21<00:35,  1.23it/s]\u001b[A\n",
            "Iteration:  39% 28/71 [00:22<00:34,  1.23it/s]\u001b[A\n",
            "Iteration:  41% 29/71 [00:23<00:34,  1.23it/s]\u001b[A\n",
            "Iteration:  42% 30/71 [00:24<00:33,  1.23it/s]\u001b[A\n",
            "Iteration:  44% 31/71 [00:25<00:32,  1.23it/s]\u001b[A\n",
            "Iteration:  45% 32/71 [00:26<00:31,  1.23it/s]\u001b[A\n",
            "Iteration:  46% 33/71 [00:26<00:30,  1.23it/s]\u001b[A\n",
            "Iteration:  48% 34/71 [00:27<00:30,  1.23it/s]\u001b[A\n",
            "Iteration:  49% 35/71 [00:28<00:29,  1.23it/s]\u001b[A\n",
            "Iteration:  51% 36/71 [00:29<00:28,  1.23it/s]\u001b[A\n",
            "Iteration:  52% 37/71 [00:30<00:27,  1.23it/s]\u001b[A\n",
            "Iteration:  54% 38/71 [00:30<00:26,  1.23it/s]\u001b[A\n",
            "Iteration:  55% 39/71 [00:31<00:26,  1.23it/s]\u001b[A\n",
            "Iteration:  56% 40/71 [00:32<00:25,  1.23it/s]\u001b[A\n",
            "Iteration:  58% 41/71 [00:33<00:24,  1.22it/s]\u001b[A\n",
            "Iteration:  59% 42/71 [00:34<00:23,  1.23it/s]\u001b[A\n",
            "Iteration:  61% 43/71 [00:34<00:22,  1.23it/s]\u001b[A\n",
            "Iteration:  62% 44/71 [00:35<00:21,  1.23it/s]\u001b[A\n",
            "Iteration:  63% 45/71 [00:36<00:21,  1.23it/s]\u001b[A\n",
            "Iteration:  65% 46/71 [00:37<00:20,  1.23it/s]\u001b[A\n",
            "Iteration:  66% 47/71 [00:38<00:19,  1.23it/s]\u001b[A\n",
            "Iteration:  68% 48/71 [00:39<00:18,  1.23it/s]\u001b[A\n",
            "Iteration:  69% 49/71 [00:39<00:17,  1.23it/s]\u001b[A\n",
            "Iteration:  70% 50/71 [00:40<00:17,  1.23it/s]\u001b[A\n",
            "Iteration:  72% 51/71 [00:41<00:16,  1.23it/s]\u001b[A\n",
            "Iteration:  73% 52/71 [00:42<00:15,  1.23it/s]\u001b[A\n",
            "Iteration:  75% 53/71 [00:43<00:14,  1.23it/s]\u001b[A\n",
            "Iteration:  76% 54/71 [00:43<00:13,  1.23it/s]\u001b[A\n",
            "Iteration:  77% 55/71 [00:44<00:13,  1.22it/s]\u001b[A\n",
            "Iteration:  79% 56/71 [00:45<00:12,  1.23it/s]\u001b[A\n",
            "Iteration:  80% 57/71 [00:46<00:11,  1.23it/s]\u001b[A\n",
            "Iteration:  82% 58/71 [00:47<00:10,  1.23it/s]\u001b[A\n",
            "Iteration:  83% 59/71 [00:47<00:09,  1.23it/s]\u001b[A\n",
            "Iteration:  85% 60/71 [00:48<00:08,  1.23it/s]\u001b[A\n",
            "Iteration:  86% 61/71 [00:49<00:08,  1.23it/s]\u001b[A\n",
            "Iteration:  87% 62/71 [00:50<00:07,  1.24it/s]\u001b[A\n",
            "Iteration:  89% 63/71 [00:51<00:06,  1.24it/s]\u001b[A\n",
            "Iteration:  90% 64/71 [00:52<00:05,  1.23it/s]\u001b[A\n",
            "Iteration:  92% 65/71 [00:52<00:04,  1.23it/s]\u001b[A\n",
            "Iteration:  93% 66/71 [00:53<00:04,  1.23it/s]\u001b[A\n",
            "Iteration:  94% 67/71 [00:54<00:03,  1.24it/s]\u001b[A\n",
            "Iteration:  96% 68/71 [00:55<00:02,  1.23it/s]\u001b[A\n",
            "Iteration:  97% 69/71 [00:56<00:01,  1.23it/s]\u001b[A\n",
            "Iteration:  99% 70/71 [00:56<00:00,  1.23it/s]\u001b[A\n",
            "Iteration: 100% 71/71 [00:57<00:00,  1.23it/s]\n",
            "Epoch: 100% 5/5 [04:35<00:00, 55.15s/it]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cGoSl8siZa8L",
        "outputId": "736f5551-23e6-432d-a37b-d0d21b73385e"
      },
      "source": [
        "%%bash\n",
        "cat '/content/unilm/layoutlm/examples/seq_labeling/data/labels.txt'"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "S-COMPANY\n",
            "S-DATE\n",
            "S-ADDRESS\n",
            "S-TOTAL\n",
            "O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5AmTkR-aLWR"
      },
      "source": [
        "%%bash\n",
        "touch /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZhM8MOHaobq"
      },
      "source": [
        "%%bash\n",
        "sed '$ a O' /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt\n",
        "sed '$ a B-DATE' /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5Xu-6P6byoZ"
      },
      "source": [
        "%%bash\n",
        "echo 'O' >> /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt\n",
        "echo 'B-DATE' >> /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt\n",
        "echo 'B-COMPANY' >> /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt\n",
        "echo 'B-TOTAL' >> /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt\n"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44LDz7S4b582"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkmm307acCyG"
      },
      "source": [
        "%%bash \n",
        "rm  /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRfsosgSa3FW",
        "outputId": "d308d013-2b3a-490b-ad7a-e7b4c8478740"
      },
      "source": [
        "%%bash\n",
        "cat /content/unilm/layoutlm/examples/seq_labeling/data/labels.txt"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "O\n",
            "B-DATE\n",
            "B-COMPANY\n",
            "B-TOTAL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuZandfEUH3k"
      },
      "source": [
        "#'/content/drive/My Drive/Models/layoutlm-base-uncased1'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ER9kk1YIokrm"
      },
      "source": [
        "# Evaluate for test set\n",
        "! python run_seq_labeling.py  --data_dir data \\\n",
        "                            --model_type layoutlm \\\n",
        "                            --model_name_or_path '/content/drive/MyDrive/data/Models/layoutlm-base-uncased/' \\\n",
        "                            --do_lower_case \\\n",
        "                            --max_seq_length 512 \\\n",
        "                            --do_predict \\\n",
        "                            --logging_steps 10 \\\n",
        "                            --save_steps -1 \\\n",
        "                            --output_dir output1 \\\n",
        "                            --labels data/labels.txt \\\n",
        "                            --per_gpu_eval_batch_size 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6irxEadGexor",
        "outputId": "08beba30-66dc-43bd-f379-efed0752922d"
      },
      "source": [
        "! python run_seq_labeling.py  --data_dir data \\\n",
        "                            --model_type layoutlm \\\n",
        "                            --model_name_or_path '/content/drive/MyDrive/data/Models/layoutlm-base-uncased/' \\\n",
        "                            --do_lower_case \\\n",
        "                            --max_seq_length 512 \\\n",
        "                            --do_predict \\\n",
        "                            --logging_steps 10 \\\n",
        "                            --save_steps -1 \\\n",
        "                            --output_dir output1 \\\n",
        "                            --labels data/labels.txt \\\n",
        "                            --per_gpu_eval_batch_size 8"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-16 23:21:16.520865: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
            "Evaluating: 100% 18/18 [00:04<00:00,  4.29it/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qov0PELOokoN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3e172a9-0bf1-4343-bf3d-be3b100cd0fd"
      },
      "source": [
        "cat output1/test_results.txt"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "f1 = 0.9577590040017786\n",
            "loss = 0.025354126203132585\n",
            "precision = 0.9397905759162304\n",
            "recall = 0.9764279238440616\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhvM7Qxg7HkX"
      },
      "source": [
        "ls '/content/drive/My Drive/Models'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iS228XML63bi"
      },
      "source": [
        "!cp -r ./output1 '/content/drive/My Drive/Models'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxZxG40mfOnw",
        "outputId": "6a396137-cf70-4423-eb66-ee32a4304525"
      },
      "source": [
        "ls '/content/drive/MyDrive/data/Models'"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " config.json   \u001b[0m\u001b[01;34mlayoutlm-base-uncased\u001b[0m/  \u001b[01;36m'layoutlm-base-uncased (1)'\u001b[0m@\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ndsrf-DKfkje"
      },
      "source": [
        "!cp -r ./output1 '/content/drive/MyDrive/data/Models'"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rK1Y0XkCoklL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cf14b6c-0c8f-4aad-e6b3-86c136e607e7"
      },
      "source": [
        "# We can check the results on the test set\n",
        "%%bash\n",
        "head -60 output/test_predictions.txt"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "head: cannot open 'output/test_predictions.txt' for reading: No such file or directory\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GH69Fu_ookiA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5cc1a936-6c09-4488-dd95-5d023029862e"
      },
      "source": [
        "%%bash\n",
        "head -60 output1/test_predictions.txt"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TAN O\n",
            "WOON O\n",
            "YANN O\n",
            "MR O\n",
            "D.I.Y. O\n",
            "(M) B-COMPANY\n",
            "SDN B-COMPANY\n",
            "BHD B-COMPANY\n",
            "(CO. O\n",
            "RFG O\n",
            ": O\n",
            "860671-D) O\n",
            "LOT O\n",
            "1851-A O\n",
            "& O\n",
            "1851-B O\n",
            "KAWASAN O\n",
            "PERINDUSTRIAN O\n",
            "BALAKONG O\n",
            "43300 O\n",
            "SERI O\n",
            "KEMBANGAN O\n",
            "(TESCO O\n",
            "PUTRA O\n",
            "NILAI) O\n",
            "-INVOICE- O\n",
            "KILAT O\n",
            "AUTO O\n",
            "ECO O\n",
            "WASH O\n",
            "& O\n",
            "SHINE O\n",
            "ES1000 O\n",
            "1L O\n",
            "WA45 O\n",
            "/2A O\n",
            "- O\n",
            "12 O\n",
            "9555916500133 O\n",
            "1 O\n",
            "X O\n",
            "3.11 O\n",
            "3.11 O\n",
            "KILAT' O\n",
            "ECO O\n",
            "AUTO O\n",
            "WASH O\n",
            "&WAX O\n",
            "EW-1000-1L O\n",
            "WA44-A O\n",
            "- O\n",
            "12 O\n",
            "9555916500126 O\n",
            "1 O\n",
            "X O\n",
            "4.62 O\n",
            "4.62 O\n",
            "WD40 O\n",
            "27ML O\n",
            "MOO O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhLSSEcOf0ZQ",
        "outputId": "47bf5ab2-6661-433b-90f5-a554f92b3a7c"
      },
      "source": [
        "!cat '/content/drive/MyDrive/data/Models/output1/config.json'"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"architectures\": [\n",
            "    \"LayoutlmForTokenClassification\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_2d_position_embeddings\": 1024,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 8,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"vocab_size\": 30522\n",
            "}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gn39Fay4gNby"
      },
      "source": [
        "PRETRAINED_MODEL = \"/content/drive/MyDrive/data/Models/output1\"\n",
        "\n",
        "# Path to ONNX model\n",
        "ONNX_MODEL_PATH = \"/content/drive/MyDrive/data/Models/onnx\"\n",
        "\n",
        "MODEL_NAME = \"LayoutLMSROIE\"\n",
        "\n",
        "TF_MODEL_PATH = \"/content/drive/MyDrive/data/Models/tf\""
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkaKRVfLiBeq",
        "outputId": "aac5ca29-6490-4f16-daa6-12651c859a32"
      },
      "source": [
        "%pip install transformers==2.9.0"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers==2.9.0 in /usr/local/lib/python3.7/dist-packages (2.9.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.0.45)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (2.23.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==2.9.0) (0.1.95)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==2.9.0) (8.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==2.9.0) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9IYdzmDziIK4",
        "outputId": "b2fb2da8-39f8-4a5e-d2ca-c3b9707caaff"
      },
      "source": [
        "import torch\n",
        "torch.__version__"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.8.1+cu101'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cXIuzNnpiOf7",
        "outputId": "a2feb624-5238-49c6-e768-0711e4c96984"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nqW4-sVoiS4s",
        "outputId": "fb03cc1f-6750-4f62-f3c6-cb3befa4e33e"
      },
      "source": [
        "%pip install tensorflow==1.15"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 42kB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.8MB/s \n",
            "\u001b[?25hCollecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 44.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (56.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=d5806d6a87f81cb46b5a0fbb0169c01373cfc42b2e4f417f21bb00172936db59\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, gast, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BjABUzLXiVWF",
        "outputId": "ae800597-6ab5-4c18-8275-6ee9faa2e91f"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n",
            "2.4.1\n",
            "2.9.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T8SNyXII84RB",
        "outputId": "d48c4e5a-0db5-4a55-cc75-a94975a19127"
      },
      "source": [
        "%pip install tensorflow==1.15"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/92/2b/e3af15221da9ff323521565fa3324b0d7c7c5b1d7a8ca66984c8d59cb0ce/tensorflow-1.15.0-cp37-cp37m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 28.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (56.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (2.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.0.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=739662a4f1c011638ce959cf770125927b4f982b03149d306c6b54bb9f02c948\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: keras-applications, tensorflow-estimator, tensorboard, gast, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRVuYcKu86GF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "CN57YfP4nXv4",
        "outputId": "5a522018-f25d-413d-f982-cacd616970c2"
      },
      "source": [
        "%pip install torch==1.8.0"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torch==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/99/5861239a6e1ffe66e120f114a4d67e96e5c4b17c1a785dfc6ca6769585fc/torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5MB)\n",
            "\u001b[K     |████████████████████████████████| 735.5MB 25kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (3.7.4.3)\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.8.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: torch\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "Successfully installed torch-1.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8hah65fSqDhK",
        "outputId": "c7feb10c-83ce-4158-9d64-ad17735cffa1"
      },
      "source": [
        "%pip install torch"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I56qzTVeqLft",
        "outputId": "fcb1844a-5596-4d0e-bd51-b73c614febff"
      },
      "source": [
        "%pip install tensorflow==2.4.1"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.4.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/dc/e8c5e7983866fa4ef3fd619faa35f660b95b01a2ab62b3884f038ccab542/tensorflow-2.4.1-cp37-cp37m-manylinux2010_x86_64.whl (394.3MB)\n",
            "\u001b[K     |████████████████████████████████| 394.3MB 40kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.19.5)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.1.2)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.7.4.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.12.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (0.36.2)\n",
            "Collecting gast==0.3.3\n",
            "  Downloading https://files.pythonhosted.org/packages/d6/84/759f5dd23fec8ba71952d97bcc7e2c9d7d63bdc582421f3cd4be845f0c98/gast-0.3.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.32.0)\n",
            "Collecting tensorboard~=2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/f5/7feea02a3fb54d5db827ac4b822a7ba8933826b36de21880518250b8733a/tensorboard-2.5.0-py3-none-any.whl (6.0MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0MB 42.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.12.4)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.6.3)\n",
            "Collecting tensorflow-estimator<2.5.0,>=2.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/7e/622d9849abf3afb81e482ffc170758742e392ee129ce1540611199a59237/tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462kB)\n",
            "\u001b[K     |████████████████████████████████| 471kB 40.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (2.10.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12.1)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.4.1) (1.12)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (1.30.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (0.4.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (56.1.0)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/f9/802efd84988bffd9f644c03b6e66fde8e76c3aa33db4279ddd11c5d61f4b/tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9MB 23.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (2.23.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow==2.4.1) (3.3.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (4.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.1) (2020.12.5)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (4.0.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.1) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow==2.4.1) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.1) (3.4.1)\n",
            "Installing collected packages: gast, tensorboard-data-server, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.2.2\n",
            "    Uninstalling gast-0.2.2:\n",
            "      Successfully uninstalled gast-0.2.2\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed gast-0.3.3 tensorboard-2.5.0 tensorboard-data-server-0.6.1 tensorflow-2.4.1 tensorflow-estimator-2.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "loe7iZolqfkK",
        "outputId": "6aff7901-109f-4077-802a-03ed48f1ab31"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.8.1+cu101\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ANbpC00bjrjB",
        "outputId": "459963da-5def-4c10-f2c6-6814ac5ac1b9"
      },
      "source": [
        "!test -d onnx-tensorflow || git clone https://github.com/onnx/onnx-tensorflow.git"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'onnx-tensorflow'...\n",
            "remote: Enumerating objects: 6128, done.\u001b[K\n",
            "remote: Counting objects: 100% (77/77), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 6128 (delta 40), reused 28 (delta 15), pack-reused 6051\u001b[K\n",
            "Receiving objects: 100% (6128/6128), 1.87 MiB | 13.03 MiB/s, done.\n",
            "Resolving deltas: 100% (4765/4765), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cTeuCk3_qpg_",
        "outputId": "fd840714-1f88-4b0f-a8d8-53754e493e0e"
      },
      "source": [
        "%cd onnx-tensorflow/\n",
        "%pip install -e ."
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/onnx-tensorflow\n",
            "Obtaining file:///content/onnx-tensorflow\n",
            "Collecting onnx>=1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/9b/54c950d3256e27f970a83cd0504efb183a24312702deed0179453316dbd0/onnx-1.9.0-cp37-cp37m-manylinux2010_x86_64.whl (12.2MB)\n",
            "\u001b[K     |████████████████████████████████| 12.2MB 254kB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (3.13)\n",
            "Collecting tensorflow_addons\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/4b/e893d194e626c24b3df2253066aa418f46a432fdb68250cde14bf9bb0700/tensorflow_addons-0.13.0-cp37-cp37m-manylinux2010_x86_64.whl (679kB)\n",
            "\u001b[K     |████████████████████████████████| 686kB 32.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (3.7.4.3)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons->onnx-tf==1.8.0) (2.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx>=1.8.0->onnx-tf==1.8.0) (56.1.0)\n",
            "Installing collected packages: onnx, tensorflow-addons, onnx-tf\n",
            "  Running setup.py develop for onnx-tf\n",
            "Successfully installed onnx-1.9.0 onnx-tf tensorflow-addons-0.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxZPftVVD-Xb",
        "outputId": "867b6927-b465-4d3e-dcb9-3753783973e9"
      },
      "source": [
        "%cd onnx-tensorflow/\n",
        "!git branch\n",
        "%pip install -e ."
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'onnx-tensorflow/'\n",
            "/content/onnx-tensorflow\n",
            "* \u001b[32m(HEAD detached at v1.6.0-tf-1.15)\u001b[m\n",
            "  master\u001b[m\n",
            "Obtaining file:///content/onnx-tensorflow\n",
            "Requirement already satisfied: onnx>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.6.0) (1.9.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.6.0) (3.13)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (1.15.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (3.12.4)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx>=1.6.0->onnx-tf==1.6.0) (56.1.0)\n",
            "Installing collected packages: onnx-tf\n",
            "  Found existing installation: onnx-tf 1.6.0\n",
            "    Can't uninstall 'onnx-tf'. No files were found to uninstall.\n",
            "  Running setup.py develop for onnx-tf\n",
            "Successfully installed onnx-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB35oh9dEDkG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hh13N3bMoNWJ",
        "outputId": "32e663e2-0d28-4da8-bd0b-b769a29ac230"
      },
      "source": [
        "%cd onnx-tensorflow/\n",
        "!git checkout master\n",
        "!git branch "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'onnx-tensorflow/'\n",
            "/content/onnx-tensorflow\n",
            "Previous HEAD position was 6b9e76d Create Release 1.6.0 for tf-1.x branch (#676)\n",
            "Switched to branch 'master'\n",
            "Your branch is up to date with 'origin/master'.\n",
            "* \u001b[32mmaster\u001b[m\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAGXhFGxqqnE",
        "outputId": "f2692e89-0624-4be1-f142-2f4667d55e2c"
      },
      "source": [
        "%pip install -e ."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/onnx-tensorflow\n",
            "Requirement already satisfied: onnx>=1.8.0 in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (1.9.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (3.13)\n",
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.8.0) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (3.12.4)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.8.0->onnx-tf==1.8.0) (1.15.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons->onnx-tf==1.8.0) (2.7.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx>=1.8.0->onnx-tf==1.8.0) (56.1.0)\n",
            "Installing collected packages: onnx-tf\n",
            "  Found existing installation: onnx-tf 1.6.0\n",
            "    Can't uninstall 'onnx-tf'. No files were found to uninstall.\n",
            "  Running setup.py develop for onnx-tf\n",
            "Successfully installed onnx-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AjVMhZ-jsGT",
        "outputId": "c78b6799-9c95-4ced-aed1-6a4019df00d3"
      },
      "source": [
        "%cd onnx-tensorflow/\n",
        "!git checkout v1.6.0-tf-1.15\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/onnx-tensorflow\n",
            "HEAD is now at 6b9e76d Create Release 1.6.0 for tf-1.x branch (#676)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ubWAvcTFDcQ2",
        "outputId": "1956253b-5307-4e65-c7b7-28f589630c09"
      },
      "source": [
        "%cd onnx-tensorflow/\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: 'onnx-tensorflow/'\n",
            "/content/onnx-tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_skEFkJoOoz",
        "outputId": "9bc1de20-e21d-4cdf-e5ff-b3431a3ca0e3"
      },
      "source": [
        "%pip install -e ."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Obtaining file:///content/onnx-tensorflow\n",
            "Requirement already satisfied: onnx>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.6.0) (1.8.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from onnx-tf==1.6.0) (3.13)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (1.15.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx>=1.6.0->onnx-tf==1.6.0) (3.7.4.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx>=1.6.0->onnx-tf==1.6.0) (56.1.0)\n",
            "Installing collected packages: onnx-tf\n",
            "  Found existing installation: onnx-tf 1.6.0\n",
            "    Can't uninstall 'onnx-tf'. No files were found to uninstall.\n",
            "  Running setup.py develop for onnx-tf\n",
            "Successfully installed onnx-tf\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h18sXTJwjzl2",
        "outputId": "e34c8e2e-4297-4c46-a0f9-174d14653519"
      },
      "source": [
        "import sys\n",
        "print(sys.executable)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/bin/python3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXUdhcQD6Ytp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0Q610K16Ylg",
        "outputId": "a6a3ae0c-6e60-40a6-fe46-51a7b8027e2e"
      },
      "source": [
        "from layoutlm import LayoutlmConfig,  LayoutlmForTokenClassification\n",
        "import torch\n",
        "\n",
        "config = LayoutlmConfig.from_pretrained(\n",
        "    PRETRAINED_MODEL\n",
        ")\n",
        "\n",
        "model =  LayoutlmForTokenClassification.from_pretrained(\n",
        "    PRETRAINED_MODEL,\n",
        "    from_tf=False,\n",
        "    config=config,\n",
        "    cache_dir=None,\n",
        ")\n",
        "\n",
        "dummy_input = {\n",
        "    \"input_ids\": \n",
        "      torch.zeros(1, 128, requires_grad=False, device=\"cpu\").long(),\n",
        "    \"bbox\":\n",
        "      torch.zeros(1, 128, 4, requires_grad=False, device=\"cpu\").long(),\n",
        "    \"attention_mask\":\n",
        "      torch.ones(1, 128, requires_grad=False, device=\"cpu\").long(),    \n",
        "    \"token_type_ids\":\n",
        "      torch.ones(1, 128, requires_grad=False, device=\"cpu\").long(),        \n",
        "}\n",
        "\n",
        "dummy_output = model(**dummy_input)\n",
        "\n",
        "print(\"Model output\")\n",
        "print(dummy_output)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model output\n",
            "(tensor([[[ 0.8069, -0.1788, -0.4051, -0.2850],\n",
            "         [ 2.7433, -2.0159, -0.4349, -0.2556],\n",
            "         [ 2.7621, -2.0289, -0.4286, -0.2532],\n",
            "         [ 2.7492, -2.0275, -0.4348, -0.2430],\n",
            "         [ 2.7467, -2.0339, -0.4338, -0.2303],\n",
            "         [ 2.7492, -2.0386, -0.4296, -0.2257],\n",
            "         [ 2.7362, -2.0325, -0.4301, -0.2362],\n",
            "         [ 2.7345, -2.0248, -0.4347, -0.2265],\n",
            "         [ 2.7510, -2.0378, -0.4413, -0.2196],\n",
            "         [ 2.7688, -2.0385, -0.4472, -0.2155],\n",
            "         [ 2.7815, -2.0299, -0.4554, -0.2153],\n",
            "         [ 2.7901, -2.0295, -0.4565, -0.2276],\n",
            "         [ 2.7840, -2.0086, -0.4553, -0.2370],\n",
            "         [ 2.7899, -2.0141, -0.4502, -0.2415],\n",
            "         [ 2.7865, -2.0097, -0.4500, -0.2458],\n",
            "         [ 2.7906, -2.0139, -0.4488, -0.2501],\n",
            "         [ 2.7991, -2.0167, -0.4519, -0.2573],\n",
            "         [ 2.7824, -2.0061, -0.4605, -0.2621],\n",
            "         [ 2.7848, -2.0127, -0.4633, -0.2577],\n",
            "         [ 2.7836, -2.0172, -0.4679, -0.2557],\n",
            "         [ 2.7872, -2.0200, -0.4726, -0.2500],\n",
            "         [ 2.7962, -2.0234, -0.4757, -0.2485],\n",
            "         [ 2.7937, -2.0156, -0.4804, -0.2582],\n",
            "         [ 2.8013, -2.0152, -0.4825, -0.2485],\n",
            "         [ 2.8234, -2.0274, -0.4847, -0.2413],\n",
            "         [ 2.8270, -2.0267, -0.4830, -0.2398],\n",
            "         [ 2.8326, -2.0303, -0.4751, -0.2462],\n",
            "         [ 2.8253, -2.0289, -0.4672, -0.2594],\n",
            "         [ 2.8131, -2.0278, -0.4609, -0.2615],\n",
            "         [ 2.8169, -2.0397, -0.4604, -0.2506],\n",
            "         [ 2.8095, -2.0439, -0.4644, -0.2443],\n",
            "         [ 2.8024, -2.0456, -0.4602, -0.2394],\n",
            "         [ 2.7988, -2.0465, -0.4561, -0.2384],\n",
            "         [ 2.7780, -2.0410, -0.4539, -0.2363],\n",
            "         [ 2.7792, -2.0445, -0.4566, -0.2278],\n",
            "         [ 2.7921, -2.0504, -0.4607, -0.2169],\n",
            "         [ 2.7890, -2.0406, -0.4626, -0.2248],\n",
            "         [ 2.7978, -2.0380, -0.4656, -0.2192],\n",
            "         [ 2.8036, -2.0379, -0.4644, -0.2191],\n",
            "         [ 2.7969, -2.0314, -0.4621, -0.2186],\n",
            "         [ 2.8076, -2.0320, -0.4599, -0.2226],\n",
            "         [ 2.7992, -2.0304, -0.4501, -0.2351],\n",
            "         [ 2.7868, -2.0223, -0.4530, -0.2483],\n",
            "         [ 2.7896, -2.0195, -0.4550, -0.2524],\n",
            "         [ 2.7873, -2.0191, -0.4656, -0.2537],\n",
            "         [ 2.7907, -2.0299, -0.4775, -0.2509],\n",
            "         [ 2.7932, -2.0270, -0.4818, -0.2560],\n",
            "         [ 2.7793, -2.0172, -0.4826, -0.2640],\n",
            "         [ 2.7832, -2.0153, -0.4867, -0.2582],\n",
            "         [ 2.7957, -2.0181, -0.4911, -0.2545],\n",
            "         [ 2.8163, -2.0187, -0.4978, -0.2487],\n",
            "         [ 2.8351, -2.0270, -0.4953, -0.2488],\n",
            "         [ 2.8369, -2.0162, -0.4905, -0.2595],\n",
            "         [ 2.8337, -2.0152, -0.4865, -0.2649],\n",
            "         [ 2.8430, -2.0256, -0.4750, -0.2626],\n",
            "         [ 2.8312, -2.0230, -0.4750, -0.2611],\n",
            "         [ 2.8375, -2.0306, -0.4686, -0.2624],\n",
            "         [ 2.8281, -2.0328, -0.4628, -0.2673],\n",
            "         [ 2.8075, -2.0228, -0.4710, -0.2608],\n",
            "         [ 2.8009, -2.0382, -0.4685, -0.2465],\n",
            "         [ 2.8032, -2.0450, -0.4731, -0.2397],\n",
            "         [ 2.7928, -2.0465, -0.4666, -0.2350],\n",
            "         [ 2.7980, -2.0437, -0.4651, -0.2364],\n",
            "         [ 2.7856, -2.0297, -0.4695, -0.2405],\n",
            "         [ 2.7945, -2.0334, -0.4744, -0.2250],\n",
            "         [ 2.8117, -2.0421, -0.4773, -0.2179],\n",
            "         [ 2.8084, -2.0353, -0.4774, -0.2218],\n",
            "         [ 2.8086, -2.0337, -0.4724, -0.2338],\n",
            "         [ 2.7923, -2.0257, -0.4553, -0.2416],\n",
            "         [ 2.7808, -2.0159, -0.4583, -0.2388],\n",
            "         [ 2.7960, -2.0263, -0.4626, -0.2326],\n",
            "         [ 2.7888, -2.0168, -0.4660, -0.2451],\n",
            "         [ 2.7816, -2.0149, -0.4732, -0.2508],\n",
            "         [ 2.7747, -2.0125, -0.4840, -0.2536],\n",
            "         [ 2.7762, -2.0132, -0.4949, -0.2513],\n",
            "         [ 2.7840, -2.0238, -0.4931, -0.2469],\n",
            "         [ 2.7836, -2.0145, -0.4960, -0.2597],\n",
            "         [ 2.7800, -1.9967, -0.5008, -0.2571],\n",
            "         [ 2.8062, -2.0053, -0.5001, -0.2473],\n",
            "         [ 2.8203, -2.0069, -0.5035, -0.2488],\n",
            "         [ 2.8274, -2.0055, -0.5029, -0.2484],\n",
            "         [ 2.8371, -2.0056, -0.4948, -0.2556],\n",
            "         [ 2.8205, -1.9951, -0.4900, -0.2620],\n",
            "         [ 2.8247, -2.0027, -0.4855, -0.2535],\n",
            "         [ 2.8205, -2.0061, -0.4761, -0.2506],\n",
            "         [ 2.8185, -2.0035, -0.4837, -0.2521],\n",
            "         [ 2.8078, -2.0050, -0.4745, -0.2520],\n",
            "         [ 2.7943, -2.0073, -0.4761, -0.2466],\n",
            "         [ 2.7804, -2.0163, -0.4752, -0.2367],\n",
            "         [ 2.7917, -2.0227, -0.4790, -0.2218],\n",
            "         [ 2.7846, -2.0174, -0.4797, -0.2194],\n",
            "         [ 2.7703, -1.9981, -0.4825, -0.2232],\n",
            "         [ 2.7813, -2.0083, -0.4823, -0.2199],\n",
            "         [ 2.7821, -2.0065, -0.4835, -0.2110],\n",
            "         [ 2.7947, -2.0061, -0.4860, -0.2041],\n",
            "         [ 2.8016, -2.0136, -0.4825, -0.2071],\n",
            "         [ 2.7836, -1.9999, -0.4687, -0.2277],\n",
            "         [ 2.7691, -1.9925, -0.4641, -0.2325],\n",
            "         [ 2.7711, -2.0036, -0.4567, -0.2311],\n",
            "         [ 2.7699, -2.0066, -0.4593, -0.2316],\n",
            "         [ 2.7781, -2.0063, -0.4711, -0.2337],\n",
            "         [ 2.7717, -1.9997, -0.4757, -0.2457],\n",
            "         [ 2.7528, -1.9868, -0.4838, -0.2494],\n",
            "         [ 2.7559, -1.9935, -0.4982, -0.2373],\n",
            "         [ 2.7701, -1.9939, -0.5038, -0.2349],\n",
            "         [ 2.7778, -1.9789, -0.5164, -0.2436],\n",
            "         [ 2.7941, -1.9705, -0.5189, -0.2437],\n",
            "         [ 2.8003, -1.9732, -0.5134, -0.2471],\n",
            "         [ 2.8039, -1.9713, -0.5174, -0.2366],\n",
            "         [ 2.8283, -1.9836, -0.5222, -0.2298],\n",
            "         [ 2.8299, -1.9754, -0.5168, -0.2413],\n",
            "         [ 2.8192, -1.9647, -0.5102, -0.2452],\n",
            "         [ 2.8196, -1.9689, -0.5023, -0.2490],\n",
            "         [ 2.8028, -1.9695, -0.5027, -0.2417],\n",
            "         [ 2.8071, -1.9777, -0.5036, -0.2329],\n",
            "         [ 2.8074, -1.9846, -0.5063, -0.2296],\n",
            "         [ 2.7882, -1.9765, -0.5074, -0.2312],\n",
            "         [ 2.7775, -1.9823, -0.5039, -0.2240],\n",
            "         [ 2.7686, -1.9835, -0.5047, -0.2098],\n",
            "         [ 2.7645, -1.9789, -0.5021, -0.1987],\n",
            "         [ 2.7802, -1.9869, -0.5024, -0.1939],\n",
            "         [ 2.7719, -1.9778, -0.4999, -0.1992],\n",
            "         [ 2.7665, -1.9696, -0.5026, -0.1992],\n",
            "         [ 2.7780, -1.9773, -0.5001, -0.1893],\n",
            "         [ 2.7799, -1.9783, -0.4978, -0.1877],\n",
            "         [ 2.7873, -1.9733, -0.4935, -0.1960],\n",
            "         [ 2.7826, -1.9713, -0.4768, -0.2168],\n",
            "         [ 2.7649, -1.9649, -0.4668, -0.2339]]], grad_fn=<AddBackward0>),)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gek22AtX-pXS"
      },
      "source": [
        "# Path to ONNX model\n",
        "ONNX_MODEL_PATH = \"/content/drive/MyDrive/data/Models/onnx2\"\n",
        "\n",
        "PRETRAINED_MODEL = \"/content/drive/MyDrive/data/Models/output1\"\n",
        "\n",
        "# Path to ONNX model\n",
        "#ONNX_MODEL_PATH = \"/content/drive/MyDrive/data/Models/onnx\"\n",
        "\n",
        "MODEL_NAME = \"LayoutLMSROIE\"\n",
        "\n",
        "TF_MODEL_PATH = \"/content/drive/MyDrive/data/Models/tf\""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "5RDeZ8ArHULM",
        "outputId": "05ef9c00-afe6-41cc-f806-082483f572cb"
      },
      "source": [
        "%pip install onnx==1.8.0"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting onnx==1.8.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/b6/382e24992ff643fc4293d4e660af982934e3149d2f77354812ca51830638/onnx-1.8.0-cp37-cp37m-manylinux2010_x86_64.whl (7.7MB)\n",
            "\u001b[K     |████████████████████████████████| 7.7MB 4.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.0) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.0) (3.7.4.3)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.0) (3.12.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from onnx==1.8.0) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from protobuf->onnx==1.8.0) (56.1.0)\n",
            "Installing collected packages: onnx\n",
            "  Found existing installation: onnx 1.9.0\n",
            "    Uninstalling onnx-1.9.0:\n",
            "      Successfully uninstalled onnx-1.9.0\n",
            "Successfully installed onnx-1.8.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "onnx"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eyPYESEHroZ"
      },
      "source": [
        "import torch"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OApfSvnv6Yh7",
        "outputId": "aff273a3-eff9-4670-b534-6129f1fc5aae"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(ONNX_MODEL_PATH):\n",
        "    os.mkdir(ONNX_MODEL_PATH)\n",
        "    \n",
        "torch.onnx.export(\n",
        "    model, \n",
        "    (\n",
        "      dummy_input[\"input_ids\"], \n",
        "      dummy_input[\"bbox\"],\n",
        "      dummy_input[\"attention_mask\"],\n",
        "      dummy_input[\"token_type_ids\"],\n",
        "    ),\n",
        "    f\"{ONNX_MODEL_PATH}/{MODEL_NAME}\",\n",
        "    verbose=True,\n",
        "    input_names=['input_ids', 'input_bbox', 'attention_mask', 'token_type_ids'],\n",
        "    output_names=[\"outputs\"],\n",
        "    dynamic_axes={\n",
        "        'input_ids': {0: 'batch', 1: 'max_seq'}, \n",
        "        'attention_mask': {0: 'batch', 1: 'max_seq'}, \n",
        "        'token_type_ids': {0: 'batch', 1: 'max_seq'}, \n",
        "        'bbox': {0: 'batch', 1: 'max_seq'},\n",
        "\n",
        "    }\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py:1190: UserWarning: Provided key bbox for dynamic axes is not a valid input/output name\n",
            "  warnings.warn(\"Provided key {} for dynamic axes is not a valid input/output name\".format(key))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "graph(%input_ids : Long(*, *, strides=[128, 1], requires_grad=0, device=cpu),\n",
            "      %input_bbox : Long(1, 128, 4, strides=[512, 4, 1], requires_grad=0, device=cpu),\n",
            "      %attention_mask : Long(*, *, strides=[128, 1], requires_grad=0, device=cpu),\n",
            "      %token_type_ids : Long(*, *, strides=[128, 1], requires_grad=0, device=cpu),\n",
            "      %bert.embeddings.word_embeddings.weight : Float(30522, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %bert.embeddings.position_embeddings.weight : Float(512, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %bert.embeddings.x_position_embeddings.weight : Float(1024, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %bert.embeddings.y_position_embeddings.weight : Float(1024, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %bert.embeddings.h_position_embeddings.weight : Float(1024, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %bert.embeddings.w_position_embeddings.weight : Float(1024, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %bert.embeddings.token_type_embeddings.weight : Float(2, 768, strides=[768, 1], requires_grad=1, device=cpu),\n",
            "      %bert.embeddings.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.embeddings.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.0.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.1.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.2.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.3.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.4.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.5.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.6.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.7.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.8.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.9.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.10.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.attention.self.query.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.attention.self.key.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.attention.self.value.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.attention.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.attention.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.attention.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.intermediate.dense.bias : Float(3072, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.output.dense.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.output.LayerNorm.weight : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %bert.encoder.layer.11.output.LayerNorm.bias : Float(768, strides=[1], requires_grad=1, device=cpu),\n",
            "      %classifier.bias : Float(4, strides=[1], requires_grad=1, device=cpu),\n",
            "      %1645 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1646 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1647 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1648 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1649 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1650 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1651 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1652 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1653 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1654 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1655 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1656 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1657 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1658 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1659 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1660 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1661 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1662 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1663 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1664 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1665 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1666 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1667 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1668 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1669 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1670 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1671 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1672 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1673 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1674 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1675 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1676 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1677 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1678 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1679 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1680 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1681 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1682 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1683 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1684 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1685 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1686 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1687 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1688 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1689 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1690 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1691 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1692 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1693 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1694 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1695 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1696 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1697 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1698 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1699 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1700 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1701 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1702 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1703 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1704 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1705 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1706 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1707 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1708 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1709 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1710 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1711 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1712 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1713 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1714 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1715 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1716 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1717 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1718 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1719 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1720 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1721 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1722 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1723 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1724 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1725 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1726 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1727 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1728 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1729 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1730 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1731 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1732 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1733 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1734 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1735 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1736 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1737 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1738 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1739 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1740 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1741 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1742 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1743 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1744 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1745 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1746 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1747 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1748 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1749 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1750 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1751 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1752 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1753 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1754 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1755 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1756 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1757 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1758 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1759 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1760 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1761 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1762 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1763 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1764 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1765 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1766 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1767 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1768 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1769 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1770 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1771 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1772 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1773 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1774 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1775 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1776 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1777 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1778 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1779 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1780 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1781 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1782 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1783 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1784 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1785 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1786 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1787 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1788 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1789 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1790 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1791 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1792 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1793 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1794 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1795 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1796 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1797 : Long(1, strides=[1], requires_grad=0, device=cpu),\n",
            "      %1798 : Float(768, 768, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1799 : Float(768, 3072, strides=[1, 768], requires_grad=0, device=cpu),\n",
            "      %1800 : Float(3072, 768, strides=[1, 3072], requires_grad=0, device=cpu),\n",
            "      %1801 : Float(768, 4, strides=[1, 768], requires_grad=0, device=cpu)):\n",
            "  %209 : Long(*, 1, *, strides=[128, 128, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[axes=[1]](%attention_mask) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:135:0\n",
            "  %210 : Long(*, 1, 1, *, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[axes=[2]](%209) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:135:0\n",
            "  %211 : Float(*, 1, 1, *, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = onnx::Cast[to=1](%210) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:143:0\n",
            "  %212 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %213 : Float(*, 1, 1, *, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = onnx::Sub(%212, %211) # /usr/local/lib/python3.7/dist-packages/torch/tensor.py:528:0\n",
            "  %214 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={-10000}]()\n",
            "  %215 : Float(*, 1, 1, *, strides=[128, 128, 128, 1], requires_grad=0, device=cpu) = onnx::Mul(%213, %214)\n",
            "  %216 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids)\n",
            "  %217 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %218 : Long(device=cpu) = onnx::Gather[axis=0](%216, %217) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:63:0\n",
            "  %219 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%218)\n",
            "  %220 : Long(*, device=cpu) = onnx::ConstantOfShape[value={1}](%219)\n",
            "  %221 : LongTensor(device=cpu) = onnx::NonZero(%220)\n",
            "  %222 : LongTensor(device=cpu) = onnx::Transpose[perm=[1, 0]](%221)\n",
            "  %223 : LongTensor(device=cpu) = onnx::Squeeze[axes=[1]](%222)\n",
            "  %224 : Long(128, strides=[1], requires_grad=0, device=cpu) = onnx::Cast[to=7](%223) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:66:0\n",
            "  %225 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Unsqueeze[axes=[0]](%224) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:68:0\n",
            "  %226 : Long(2, strides=[1], device=cpu) = onnx::Shape(%input_ids)\n",
            "  %227 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Expand(%225, %226) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:68:0\n",
            "  %228 : Float(*, *, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Gather(%bert.embeddings.word_embeddings.weight, %input_ids) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1916:0\n",
            "  %229 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Gather(%bert.embeddings.position_embeddings.weight, %227) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1916:0\n",
            "  %230 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %231 : Long(1, 128, strides=[512, 4], requires_grad=0, device=cpu) = onnx::Gather[axis=2](%input_bbox, %230) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:74:0\n",
            "  %232 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Gather(%bert.embeddings.x_position_embeddings.weight, %231) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1916:0\n",
            "  %233 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %234 : Long(1, 128, strides=[512, 4], requires_grad=0, device=cpu) = onnx::Gather[axis=2](%input_bbox, %233) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:75:0\n",
            "  %235 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Gather(%bert.embeddings.y_position_embeddings.weight, %234) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1916:0\n",
            "  %236 : Long(device=cpu) = onnx::Constant[value={2}]()\n",
            "  %237 : Long(1, 128, strides=[512, 4], requires_grad=0, device=cpu) = onnx::Gather[axis=2](%input_bbox, %236) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:76:0\n",
            "  %238 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Gather(%bert.embeddings.x_position_embeddings.weight, %237) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1916:0\n",
            "  %239 : Long(device=cpu) = onnx::Constant[value={3}]()\n",
            "  %240 : Long(1, 128, strides=[512, 4], requires_grad=0, device=cpu) = onnx::Gather[axis=2](%input_bbox, %239) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:77:0\n",
            "  %241 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Gather(%bert.embeddings.y_position_embeddings.weight, %240) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1916:0\n",
            "  %242 : Long(device=cpu) = onnx::Constant[value={3}]()\n",
            "  %243 : Long(1, 128, strides=[512, 4], requires_grad=0, device=cpu) = onnx::Gather[axis=2](%input_bbox, %242) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:79:0\n",
            "  %244 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %245 : Long(1, 128, strides=[512, 4], requires_grad=0, device=cpu) = onnx::Gather[axis=2](%input_bbox, %244) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:79:0\n",
            "  %246 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Sub(%243, %245) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:79:0\n",
            "  %247 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Gather(%bert.embeddings.h_position_embeddings.weight, %246) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1916:0\n",
            "  %248 : Long(device=cpu) = onnx::Constant[value={2}]()\n",
            "  %249 : Long(1, 128, strides=[512, 4], requires_grad=0, device=cpu) = onnx::Gather[axis=2](%input_bbox, %248) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:82:0\n",
            "  %250 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %251 : Long(1, 128, strides=[512, 4], requires_grad=0, device=cpu) = onnx::Gather[axis=2](%input_bbox, %250) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:82:0\n",
            "  %252 : Long(1, 128, strides=[128, 1], requires_grad=0, device=cpu) = onnx::Sub(%249, %251) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:82:0\n",
            "  %253 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Gather(%bert.embeddings.w_position_embeddings.weight, %252) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1916:0\n",
            "  %254 : Float(*, *, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Gather(%bert.embeddings.token_type_embeddings.weight, %token_type_ids) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1916:0\n",
            "  %255 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%228, %229) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:95:0\n",
            "  %256 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%255, %232) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:95:0\n",
            "  %257 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%256, %235) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:95:0\n",
            "  %258 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%257, %238) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:95:0\n",
            "  %259 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%258, %241) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:95:0\n",
            "  %260 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%259, %247) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:95:0\n",
            "  %261 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%260, %253) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:95:0\n",
            "  %262 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%261, %254) # /usr/local/lib/python3.7/dist-packages/layoutlm/modeling/layoutlm.py:95:0\n",
            "  %263 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%262)\n",
            "  %264 : Float(*, 128, 768, device=cpu) = onnx::Sub(%262, %263)\n",
            "  %265 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %266 : Float(*, 128, 768, device=cpu) = onnx::Pow(%264, %265)\n",
            "  %267 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%266)\n",
            "  %268 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %269 : Float(*, 128, 1, device=cpu) = onnx::Add(%267, %268)\n",
            "  %270 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%269)\n",
            "  %271 : Float(*, 128, 768, device=cpu) = onnx::Div(%264, %270)\n",
            "  %272 : Float(*, 128, 768, device=cpu) = onnx::Mul(%271, %bert.embeddings.LayerNorm.weight)\n",
            "  %273 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%272, %bert.embeddings.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %275 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%273, %1645) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %276 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%275, %bert.encoder.layer.0.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %278 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%273, %1646) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %279 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%278, %bert.encoder.layer.0.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %281 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%273, %1647) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %282 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%281, %bert.encoder.layer.0.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %283 : Long(3, strides=[1], device=cpu) = onnx::Shape(%276)\n",
            "  %284 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %285 : Long(device=cpu) = onnx::Gather[axis=0](%283, %284) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %286 : Long(3, strides=[1], device=cpu) = onnx::Shape(%276)\n",
            "  %287 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %288 : Long(device=cpu) = onnx::Gather[axis=0](%286, %287) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %291 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%285)\n",
            "  %292 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%288)\n",
            "  %295 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%291, %292, %1648, %1649)\n",
            "  %296 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%276, %295) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %297 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%296) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %298 : Long(3, strides=[1], device=cpu) = onnx::Shape(%279)\n",
            "  %299 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %300 : Long(device=cpu) = onnx::Gather[axis=0](%298, %299) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %301 : Long(3, strides=[1], device=cpu) = onnx::Shape(%279)\n",
            "  %302 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %303 : Long(device=cpu) = onnx::Gather[axis=0](%301, %302) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %306 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%300)\n",
            "  %307 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%303)\n",
            "  %310 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%306, %307, %1650, %1651)\n",
            "  %311 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%279, %310) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %312 : Long(3, strides=[1], device=cpu) = onnx::Shape(%282)\n",
            "  %313 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %314 : Long(device=cpu) = onnx::Gather[axis=0](%312, %313) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %315 : Long(3, strides=[1], device=cpu) = onnx::Shape(%282)\n",
            "  %316 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %317 : Long(device=cpu) = onnx::Gather[axis=0](%315, %316) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %320 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%314)\n",
            "  %321 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%317)\n",
            "  %324 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%320, %321, %1652, %1653)\n",
            "  %325 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%282, %324) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %326 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%325) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %327 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%311) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %328 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%297, %327) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %329 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %330 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%328, %329)\n",
            "  %331 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%330, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %332 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%331) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %333 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%332, %326) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %334 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%333) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %335 : Long(4, strides=[1], device=cpu) = onnx::Shape(%334)\n",
            "  %336 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %337 : Long(device=cpu) = onnx::Gather[axis=0](%335, %336) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %338 : Long(4, strides=[1], device=cpu) = onnx::Shape(%334)\n",
            "  %339 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %340 : Long(device=cpu) = onnx::Gather[axis=0](%338, %339) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %342 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%337)\n",
            "  %343 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%340)\n",
            "  %345 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%342, %343, %1654)\n",
            "  %346 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%334, %345) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %348 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%346, %1655) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %349 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%348, %bert.encoder.layer.0.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %350 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%349, %273) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %351 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%350)\n",
            "  %352 : Float(*, 128, 768, device=cpu) = onnx::Sub(%350, %351)\n",
            "  %353 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %354 : Float(*, 128, 768, device=cpu) = onnx::Pow(%352, %353)\n",
            "  %355 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%354)\n",
            "  %356 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %357 : Float(*, 128, 1, device=cpu) = onnx::Add(%355, %356)\n",
            "  %358 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%357)\n",
            "  %359 : Float(*, 128, 768, device=cpu) = onnx::Div(%352, %358)\n",
            "  %360 : Float(*, 128, 768, device=cpu) = onnx::Mul(%359, %bert.encoder.layer.0.attention.output.LayerNorm.weight)\n",
            "  %361 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%360, %bert.encoder.layer.0.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %363 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%361, %1656) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %364 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%363, %bert.encoder.layer.0.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %365 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %366 : Float(*, 128, 3072, device=cpu) = onnx::Div(%364, %365)\n",
            "  %367 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%366)\n",
            "  %368 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %369 : Float(*, 128, 3072, device=cpu) = onnx::Add(%367, %368)\n",
            "  %370 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%364, %369)\n",
            "  %371 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %372 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%370, %371) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %374 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%372, %1657) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %375 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%374, %bert.encoder.layer.0.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %376 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%375, %361) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %377 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%376)\n",
            "  %378 : Float(*, 128, 768, device=cpu) = onnx::Sub(%376, %377)\n",
            "  %379 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %380 : Float(*, 128, 768, device=cpu) = onnx::Pow(%378, %379)\n",
            "  %381 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%380)\n",
            "  %382 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %383 : Float(*, 128, 1, device=cpu) = onnx::Add(%381, %382)\n",
            "  %384 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%383)\n",
            "  %385 : Float(*, 128, 768, device=cpu) = onnx::Div(%378, %384)\n",
            "  %386 : Float(*, 128, 768, device=cpu) = onnx::Mul(%385, %bert.encoder.layer.0.output.LayerNorm.weight)\n",
            "  %387 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%386, %bert.encoder.layer.0.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %389 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%387, %1658) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %390 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%389, %bert.encoder.layer.1.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %392 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%387, %1659) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %393 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%392, %bert.encoder.layer.1.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %395 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%387, %1660) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %396 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%395, %bert.encoder.layer.1.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %397 : Long(3, strides=[1], device=cpu) = onnx::Shape(%390)\n",
            "  %398 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %399 : Long(device=cpu) = onnx::Gather[axis=0](%397, %398) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %400 : Long(3, strides=[1], device=cpu) = onnx::Shape(%390)\n",
            "  %401 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %402 : Long(device=cpu) = onnx::Gather[axis=0](%400, %401) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %405 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%399)\n",
            "  %406 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%402)\n",
            "  %409 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%405, %406, %1661, %1662)\n",
            "  %410 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%390, %409) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %411 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%410) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %412 : Long(3, strides=[1], device=cpu) = onnx::Shape(%393)\n",
            "  %413 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %414 : Long(device=cpu) = onnx::Gather[axis=0](%412, %413) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %415 : Long(3, strides=[1], device=cpu) = onnx::Shape(%393)\n",
            "  %416 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %417 : Long(device=cpu) = onnx::Gather[axis=0](%415, %416) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %420 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%414)\n",
            "  %421 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%417)\n",
            "  %424 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%420, %421, %1663, %1664)\n",
            "  %425 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%393, %424) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %426 : Long(3, strides=[1], device=cpu) = onnx::Shape(%396)\n",
            "  %427 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %428 : Long(device=cpu) = onnx::Gather[axis=0](%426, %427) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %429 : Long(3, strides=[1], device=cpu) = onnx::Shape(%396)\n",
            "  %430 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %431 : Long(device=cpu) = onnx::Gather[axis=0](%429, %430) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %434 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%428)\n",
            "  %435 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%431)\n",
            "  %438 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%434, %435, %1665, %1666)\n",
            "  %439 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%396, %438) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %440 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%439) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %441 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%425) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %442 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%411, %441) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %443 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %444 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%442, %443)\n",
            "  %445 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%444, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %446 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%445) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %447 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%446, %440) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %448 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%447) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %449 : Long(4, strides=[1], device=cpu) = onnx::Shape(%448)\n",
            "  %450 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %451 : Long(device=cpu) = onnx::Gather[axis=0](%449, %450) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %452 : Long(4, strides=[1], device=cpu) = onnx::Shape(%448)\n",
            "  %453 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %454 : Long(device=cpu) = onnx::Gather[axis=0](%452, %453) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %456 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%451)\n",
            "  %457 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%454)\n",
            "  %459 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%456, %457, %1667)\n",
            "  %460 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%448, %459) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %462 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%460, %1668) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %463 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%462, %bert.encoder.layer.1.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %464 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%463, %387) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %465 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%464)\n",
            "  %466 : Float(*, 128, 768, device=cpu) = onnx::Sub(%464, %465)\n",
            "  %467 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %468 : Float(*, 128, 768, device=cpu) = onnx::Pow(%466, %467)\n",
            "  %469 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%468)\n",
            "  %470 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %471 : Float(*, 128, 1, device=cpu) = onnx::Add(%469, %470)\n",
            "  %472 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%471)\n",
            "  %473 : Float(*, 128, 768, device=cpu) = onnx::Div(%466, %472)\n",
            "  %474 : Float(*, 128, 768, device=cpu) = onnx::Mul(%473, %bert.encoder.layer.1.attention.output.LayerNorm.weight)\n",
            "  %475 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%474, %bert.encoder.layer.1.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %477 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%475, %1669) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %478 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%477, %bert.encoder.layer.1.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %479 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %480 : Float(*, 128, 3072, device=cpu) = onnx::Div(%478, %479)\n",
            "  %481 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%480)\n",
            "  %482 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %483 : Float(*, 128, 3072, device=cpu) = onnx::Add(%481, %482)\n",
            "  %484 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%478, %483)\n",
            "  %485 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %486 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%484, %485) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %488 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%486, %1670) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %489 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%488, %bert.encoder.layer.1.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %490 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%489, %475) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %491 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%490)\n",
            "  %492 : Float(*, 128, 768, device=cpu) = onnx::Sub(%490, %491)\n",
            "  %493 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %494 : Float(*, 128, 768, device=cpu) = onnx::Pow(%492, %493)\n",
            "  %495 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%494)\n",
            "  %496 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %497 : Float(*, 128, 1, device=cpu) = onnx::Add(%495, %496)\n",
            "  %498 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%497)\n",
            "  %499 : Float(*, 128, 768, device=cpu) = onnx::Div(%492, %498)\n",
            "  %500 : Float(*, 128, 768, device=cpu) = onnx::Mul(%499, %bert.encoder.layer.1.output.LayerNorm.weight)\n",
            "  %501 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%500, %bert.encoder.layer.1.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %503 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%501, %1671) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %504 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%503, %bert.encoder.layer.2.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %506 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%501, %1672) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %507 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%506, %bert.encoder.layer.2.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %509 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%501, %1673) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %510 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%509, %bert.encoder.layer.2.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %511 : Long(3, strides=[1], device=cpu) = onnx::Shape(%504)\n",
            "  %512 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %513 : Long(device=cpu) = onnx::Gather[axis=0](%511, %512) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %514 : Long(3, strides=[1], device=cpu) = onnx::Shape(%504)\n",
            "  %515 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %516 : Long(device=cpu) = onnx::Gather[axis=0](%514, %515) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %519 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%513)\n",
            "  %520 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%516)\n",
            "  %523 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%519, %520, %1674, %1675)\n",
            "  %524 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%504, %523) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %525 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%524) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %526 : Long(3, strides=[1], device=cpu) = onnx::Shape(%507)\n",
            "  %527 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %528 : Long(device=cpu) = onnx::Gather[axis=0](%526, %527) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %529 : Long(3, strides=[1], device=cpu) = onnx::Shape(%507)\n",
            "  %530 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %531 : Long(device=cpu) = onnx::Gather[axis=0](%529, %530) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %534 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%528)\n",
            "  %535 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%531)\n",
            "  %538 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%534, %535, %1676, %1677)\n",
            "  %539 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%507, %538) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %540 : Long(3, strides=[1], device=cpu) = onnx::Shape(%510)\n",
            "  %541 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %542 : Long(device=cpu) = onnx::Gather[axis=0](%540, %541) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %543 : Long(3, strides=[1], device=cpu) = onnx::Shape(%510)\n",
            "  %544 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %545 : Long(device=cpu) = onnx::Gather[axis=0](%543, %544) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %548 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%542)\n",
            "  %549 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%545)\n",
            "  %552 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%548, %549, %1678, %1679)\n",
            "  %553 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%510, %552) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %554 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%553) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %555 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%539) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %556 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%525, %555) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %557 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %558 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%556, %557)\n",
            "  %559 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%558, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %560 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%559) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %561 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%560, %554) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %562 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%561) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %563 : Long(4, strides=[1], device=cpu) = onnx::Shape(%562)\n",
            "  %564 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %565 : Long(device=cpu) = onnx::Gather[axis=0](%563, %564) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %566 : Long(4, strides=[1], device=cpu) = onnx::Shape(%562)\n",
            "  %567 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %568 : Long(device=cpu) = onnx::Gather[axis=0](%566, %567) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %570 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%565)\n",
            "  %571 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%568)\n",
            "  %573 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%570, %571, %1680)\n",
            "  %574 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%562, %573) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %576 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%574, %1681) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %577 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%576, %bert.encoder.layer.2.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %578 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%577, %501) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %579 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%578)\n",
            "  %580 : Float(*, 128, 768, device=cpu) = onnx::Sub(%578, %579)\n",
            "  %581 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %582 : Float(*, 128, 768, device=cpu) = onnx::Pow(%580, %581)\n",
            "  %583 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%582)\n",
            "  %584 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %585 : Float(*, 128, 1, device=cpu) = onnx::Add(%583, %584)\n",
            "  %586 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%585)\n",
            "  %587 : Float(*, 128, 768, device=cpu) = onnx::Div(%580, %586)\n",
            "  %588 : Float(*, 128, 768, device=cpu) = onnx::Mul(%587, %bert.encoder.layer.2.attention.output.LayerNorm.weight)\n",
            "  %589 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%588, %bert.encoder.layer.2.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %591 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%589, %1682) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %592 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%591, %bert.encoder.layer.2.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %593 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %594 : Float(*, 128, 3072, device=cpu) = onnx::Div(%592, %593)\n",
            "  %595 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%594)\n",
            "  %596 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %597 : Float(*, 128, 3072, device=cpu) = onnx::Add(%595, %596)\n",
            "  %598 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%592, %597)\n",
            "  %599 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %600 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%598, %599) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %602 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%600, %1683) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %603 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%602, %bert.encoder.layer.2.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %604 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%603, %589) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %605 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%604)\n",
            "  %606 : Float(*, 128, 768, device=cpu) = onnx::Sub(%604, %605)\n",
            "  %607 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %608 : Float(*, 128, 768, device=cpu) = onnx::Pow(%606, %607)\n",
            "  %609 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%608)\n",
            "  %610 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %611 : Float(*, 128, 1, device=cpu) = onnx::Add(%609, %610)\n",
            "  %612 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%611)\n",
            "  %613 : Float(*, 128, 768, device=cpu) = onnx::Div(%606, %612)\n",
            "  %614 : Float(*, 128, 768, device=cpu) = onnx::Mul(%613, %bert.encoder.layer.2.output.LayerNorm.weight)\n",
            "  %615 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%614, %bert.encoder.layer.2.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %617 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%615, %1684) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %618 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%617, %bert.encoder.layer.3.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %620 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%615, %1685) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %621 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%620, %bert.encoder.layer.3.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %623 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%615, %1686) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %624 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%623, %bert.encoder.layer.3.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %625 : Long(3, strides=[1], device=cpu) = onnx::Shape(%618)\n",
            "  %626 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %627 : Long(device=cpu) = onnx::Gather[axis=0](%625, %626) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %628 : Long(3, strides=[1], device=cpu) = onnx::Shape(%618)\n",
            "  %629 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %630 : Long(device=cpu) = onnx::Gather[axis=0](%628, %629) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %633 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%627)\n",
            "  %634 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%630)\n",
            "  %637 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%633, %634, %1687, %1688)\n",
            "  %638 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%618, %637) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %639 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%638) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %640 : Long(3, strides=[1], device=cpu) = onnx::Shape(%621)\n",
            "  %641 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %642 : Long(device=cpu) = onnx::Gather[axis=0](%640, %641) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %643 : Long(3, strides=[1], device=cpu) = onnx::Shape(%621)\n",
            "  %644 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %645 : Long(device=cpu) = onnx::Gather[axis=0](%643, %644) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %648 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%642)\n",
            "  %649 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%645)\n",
            "  %652 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%648, %649, %1689, %1690)\n",
            "  %653 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%621, %652) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %654 : Long(3, strides=[1], device=cpu) = onnx::Shape(%624)\n",
            "  %655 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %656 : Long(device=cpu) = onnx::Gather[axis=0](%654, %655) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %657 : Long(3, strides=[1], device=cpu) = onnx::Shape(%624)\n",
            "  %658 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %659 : Long(device=cpu) = onnx::Gather[axis=0](%657, %658) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %662 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%656)\n",
            "  %663 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%659)\n",
            "  %666 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%662, %663, %1691, %1692)\n",
            "  %667 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%624, %666) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %668 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%667) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %669 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%653) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %670 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%639, %669) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %671 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %672 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%670, %671)\n",
            "  %673 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%672, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %674 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%673) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %675 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%674, %668) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %676 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%675) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %677 : Long(4, strides=[1], device=cpu) = onnx::Shape(%676)\n",
            "  %678 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %679 : Long(device=cpu) = onnx::Gather[axis=0](%677, %678) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %680 : Long(4, strides=[1], device=cpu) = onnx::Shape(%676)\n",
            "  %681 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %682 : Long(device=cpu) = onnx::Gather[axis=0](%680, %681) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %684 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%679)\n",
            "  %685 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%682)\n",
            "  %687 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%684, %685, %1693)\n",
            "  %688 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%676, %687) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %690 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%688, %1694) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %691 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%690, %bert.encoder.layer.3.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %692 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%691, %615) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %693 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%692)\n",
            "  %694 : Float(*, 128, 768, device=cpu) = onnx::Sub(%692, %693)\n",
            "  %695 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %696 : Float(*, 128, 768, device=cpu) = onnx::Pow(%694, %695)\n",
            "  %697 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%696)\n",
            "  %698 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %699 : Float(*, 128, 1, device=cpu) = onnx::Add(%697, %698)\n",
            "  %700 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%699)\n",
            "  %701 : Float(*, 128, 768, device=cpu) = onnx::Div(%694, %700)\n",
            "  %702 : Float(*, 128, 768, device=cpu) = onnx::Mul(%701, %bert.encoder.layer.3.attention.output.LayerNorm.weight)\n",
            "  %703 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%702, %bert.encoder.layer.3.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %705 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%703, %1695) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %706 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%705, %bert.encoder.layer.3.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %707 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %708 : Float(*, 128, 3072, device=cpu) = onnx::Div(%706, %707)\n",
            "  %709 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%708)\n",
            "  %710 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %711 : Float(*, 128, 3072, device=cpu) = onnx::Add(%709, %710)\n",
            "  %712 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%706, %711)\n",
            "  %713 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %714 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%712, %713) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %716 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%714, %1696) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %717 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%716, %bert.encoder.layer.3.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %718 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%717, %703) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %719 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%718)\n",
            "  %720 : Float(*, 128, 768, device=cpu) = onnx::Sub(%718, %719)\n",
            "  %721 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %722 : Float(*, 128, 768, device=cpu) = onnx::Pow(%720, %721)\n",
            "  %723 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%722)\n",
            "  %724 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %725 : Float(*, 128, 1, device=cpu) = onnx::Add(%723, %724)\n",
            "  %726 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%725)\n",
            "  %727 : Float(*, 128, 768, device=cpu) = onnx::Div(%720, %726)\n",
            "  %728 : Float(*, 128, 768, device=cpu) = onnx::Mul(%727, %bert.encoder.layer.3.output.LayerNorm.weight)\n",
            "  %729 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%728, %bert.encoder.layer.3.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %731 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%729, %1697) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %732 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%731, %bert.encoder.layer.4.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %734 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%729, %1698) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %735 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%734, %bert.encoder.layer.4.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %737 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%729, %1699) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %738 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%737, %bert.encoder.layer.4.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %739 : Long(3, strides=[1], device=cpu) = onnx::Shape(%732)\n",
            "  %740 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %741 : Long(device=cpu) = onnx::Gather[axis=0](%739, %740) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %742 : Long(3, strides=[1], device=cpu) = onnx::Shape(%732)\n",
            "  %743 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %744 : Long(device=cpu) = onnx::Gather[axis=0](%742, %743) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %747 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%741)\n",
            "  %748 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%744)\n",
            "  %751 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%747, %748, %1700, %1701)\n",
            "  %752 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%732, %751) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %753 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%752) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %754 : Long(3, strides=[1], device=cpu) = onnx::Shape(%735)\n",
            "  %755 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %756 : Long(device=cpu) = onnx::Gather[axis=0](%754, %755) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %757 : Long(3, strides=[1], device=cpu) = onnx::Shape(%735)\n",
            "  %758 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %759 : Long(device=cpu) = onnx::Gather[axis=0](%757, %758) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %762 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%756)\n",
            "  %763 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%759)\n",
            "  %766 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%762, %763, %1702, %1703)\n",
            "  %767 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%735, %766) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %768 : Long(3, strides=[1], device=cpu) = onnx::Shape(%738)\n",
            "  %769 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %770 : Long(device=cpu) = onnx::Gather[axis=0](%768, %769) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %771 : Long(3, strides=[1], device=cpu) = onnx::Shape(%738)\n",
            "  %772 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %773 : Long(device=cpu) = onnx::Gather[axis=0](%771, %772) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %776 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%770)\n",
            "  %777 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%773)\n",
            "  %780 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%776, %777, %1704, %1705)\n",
            "  %781 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%738, %780) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %782 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%781) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %783 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%767) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %784 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%753, %783) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %785 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %786 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%784, %785)\n",
            "  %787 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%786, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %788 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%787) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %789 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%788, %782) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %790 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%789) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %791 : Long(4, strides=[1], device=cpu) = onnx::Shape(%790)\n",
            "  %792 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %793 : Long(device=cpu) = onnx::Gather[axis=0](%791, %792) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %794 : Long(4, strides=[1], device=cpu) = onnx::Shape(%790)\n",
            "  %795 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %796 : Long(device=cpu) = onnx::Gather[axis=0](%794, %795) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %798 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%793)\n",
            "  %799 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%796)\n",
            "  %801 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%798, %799, %1706)\n",
            "  %802 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%790, %801) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %804 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%802, %1707) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %805 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%804, %bert.encoder.layer.4.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %806 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%805, %729) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %807 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%806)\n",
            "  %808 : Float(*, 128, 768, device=cpu) = onnx::Sub(%806, %807)\n",
            "  %809 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %810 : Float(*, 128, 768, device=cpu) = onnx::Pow(%808, %809)\n",
            "  %811 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%810)\n",
            "  %812 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %813 : Float(*, 128, 1, device=cpu) = onnx::Add(%811, %812)\n",
            "  %814 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%813)\n",
            "  %815 : Float(*, 128, 768, device=cpu) = onnx::Div(%808, %814)\n",
            "  %816 : Float(*, 128, 768, device=cpu) = onnx::Mul(%815, %bert.encoder.layer.4.attention.output.LayerNorm.weight)\n",
            "  %817 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%816, %bert.encoder.layer.4.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %819 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%817, %1708) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %820 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%819, %bert.encoder.layer.4.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %821 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %822 : Float(*, 128, 3072, device=cpu) = onnx::Div(%820, %821)\n",
            "  %823 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%822)\n",
            "  %824 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %825 : Float(*, 128, 3072, device=cpu) = onnx::Add(%823, %824)\n",
            "  %826 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%820, %825)\n",
            "  %827 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %828 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%826, %827) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %830 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%828, %1709) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %831 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%830, %bert.encoder.layer.4.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %832 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%831, %817) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %833 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%832)\n",
            "  %834 : Float(*, 128, 768, device=cpu) = onnx::Sub(%832, %833)\n",
            "  %835 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %836 : Float(*, 128, 768, device=cpu) = onnx::Pow(%834, %835)\n",
            "  %837 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%836)\n",
            "  %838 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %839 : Float(*, 128, 1, device=cpu) = onnx::Add(%837, %838)\n",
            "  %840 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%839)\n",
            "  %841 : Float(*, 128, 768, device=cpu) = onnx::Div(%834, %840)\n",
            "  %842 : Float(*, 128, 768, device=cpu) = onnx::Mul(%841, %bert.encoder.layer.4.output.LayerNorm.weight)\n",
            "  %843 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%842, %bert.encoder.layer.4.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %845 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%843, %1710) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %846 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%845, %bert.encoder.layer.5.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %848 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%843, %1711) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %849 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%848, %bert.encoder.layer.5.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %851 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%843, %1712) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %852 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%851, %bert.encoder.layer.5.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %853 : Long(3, strides=[1], device=cpu) = onnx::Shape(%846)\n",
            "  %854 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %855 : Long(device=cpu) = onnx::Gather[axis=0](%853, %854) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %856 : Long(3, strides=[1], device=cpu) = onnx::Shape(%846)\n",
            "  %857 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %858 : Long(device=cpu) = onnx::Gather[axis=0](%856, %857) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %861 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%855)\n",
            "  %862 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%858)\n",
            "  %865 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%861, %862, %1713, %1714)\n",
            "  %866 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%846, %865) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %867 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%866) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %868 : Long(3, strides=[1], device=cpu) = onnx::Shape(%849)\n",
            "  %869 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %870 : Long(device=cpu) = onnx::Gather[axis=0](%868, %869) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %871 : Long(3, strides=[1], device=cpu) = onnx::Shape(%849)\n",
            "  %872 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %873 : Long(device=cpu) = onnx::Gather[axis=0](%871, %872) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %876 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%870)\n",
            "  %877 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%873)\n",
            "  %880 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%876, %877, %1715, %1716)\n",
            "  %881 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%849, %880) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %882 : Long(3, strides=[1], device=cpu) = onnx::Shape(%852)\n",
            "  %883 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %884 : Long(device=cpu) = onnx::Gather[axis=0](%882, %883) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %885 : Long(3, strides=[1], device=cpu) = onnx::Shape(%852)\n",
            "  %886 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %887 : Long(device=cpu) = onnx::Gather[axis=0](%885, %886) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %890 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%884)\n",
            "  %891 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%887)\n",
            "  %894 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%890, %891, %1717, %1718)\n",
            "  %895 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%852, %894) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %896 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%895) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %897 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%881) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %898 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%867, %897) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %899 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %900 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%898, %899)\n",
            "  %901 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%900, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %902 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%901) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %903 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%902, %896) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %904 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%903) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %905 : Long(4, strides=[1], device=cpu) = onnx::Shape(%904)\n",
            "  %906 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %907 : Long(device=cpu) = onnx::Gather[axis=0](%905, %906) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %908 : Long(4, strides=[1], device=cpu) = onnx::Shape(%904)\n",
            "  %909 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %910 : Long(device=cpu) = onnx::Gather[axis=0](%908, %909) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %912 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%907)\n",
            "  %913 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%910)\n",
            "  %915 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%912, %913, %1719)\n",
            "  %916 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%904, %915) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %918 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%916, %1720) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %919 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%918, %bert.encoder.layer.5.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %920 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%919, %843) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %921 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%920)\n",
            "  %922 : Float(*, 128, 768, device=cpu) = onnx::Sub(%920, %921)\n",
            "  %923 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %924 : Float(*, 128, 768, device=cpu) = onnx::Pow(%922, %923)\n",
            "  %925 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%924)\n",
            "  %926 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %927 : Float(*, 128, 1, device=cpu) = onnx::Add(%925, %926)\n",
            "  %928 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%927)\n",
            "  %929 : Float(*, 128, 768, device=cpu) = onnx::Div(%922, %928)\n",
            "  %930 : Float(*, 128, 768, device=cpu) = onnx::Mul(%929, %bert.encoder.layer.5.attention.output.LayerNorm.weight)\n",
            "  %931 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%930, %bert.encoder.layer.5.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %933 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%931, %1721) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %934 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%933, %bert.encoder.layer.5.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %935 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %936 : Float(*, 128, 3072, device=cpu) = onnx::Div(%934, %935)\n",
            "  %937 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%936)\n",
            "  %938 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %939 : Float(*, 128, 3072, device=cpu) = onnx::Add(%937, %938)\n",
            "  %940 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%934, %939)\n",
            "  %941 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %942 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%940, %941) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %944 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%942, %1722) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %945 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%944, %bert.encoder.layer.5.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %946 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%945, %931) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %947 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%946)\n",
            "  %948 : Float(*, 128, 768, device=cpu) = onnx::Sub(%946, %947)\n",
            "  %949 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %950 : Float(*, 128, 768, device=cpu) = onnx::Pow(%948, %949)\n",
            "  %951 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%950)\n",
            "  %952 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %953 : Float(*, 128, 1, device=cpu) = onnx::Add(%951, %952)\n",
            "  %954 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%953)\n",
            "  %955 : Float(*, 128, 768, device=cpu) = onnx::Div(%948, %954)\n",
            "  %956 : Float(*, 128, 768, device=cpu) = onnx::Mul(%955, %bert.encoder.layer.5.output.LayerNorm.weight)\n",
            "  %957 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%956, %bert.encoder.layer.5.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %959 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%957, %1723) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %960 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%959, %bert.encoder.layer.6.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %962 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%957, %1724) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %963 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%962, %bert.encoder.layer.6.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %965 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%957, %1725) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %966 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%965, %bert.encoder.layer.6.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %967 : Long(3, strides=[1], device=cpu) = onnx::Shape(%960)\n",
            "  %968 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %969 : Long(device=cpu) = onnx::Gather[axis=0](%967, %968) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %970 : Long(3, strides=[1], device=cpu) = onnx::Shape(%960)\n",
            "  %971 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %972 : Long(device=cpu) = onnx::Gather[axis=0](%970, %971) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %975 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%969)\n",
            "  %976 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%972)\n",
            "  %979 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%975, %976, %1726, %1727)\n",
            "  %980 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%960, %979) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %981 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%980) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %982 : Long(3, strides=[1], device=cpu) = onnx::Shape(%963)\n",
            "  %983 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %984 : Long(device=cpu) = onnx::Gather[axis=0](%982, %983) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %985 : Long(3, strides=[1], device=cpu) = onnx::Shape(%963)\n",
            "  %986 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %987 : Long(device=cpu) = onnx::Gather[axis=0](%985, %986) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %990 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%984)\n",
            "  %991 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%987)\n",
            "  %994 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%990, %991, %1728, %1729)\n",
            "  %995 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%963, %994) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %996 : Long(3, strides=[1], device=cpu) = onnx::Shape(%966)\n",
            "  %997 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %998 : Long(device=cpu) = onnx::Gather[axis=0](%996, %997) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %999 : Long(3, strides=[1], device=cpu) = onnx::Shape(%966)\n",
            "  %1000 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1001 : Long(device=cpu) = onnx::Gather[axis=0](%999, %1000) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1004 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%998)\n",
            "  %1005 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1001)\n",
            "  %1008 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1004, %1005, %1730, %1731)\n",
            "  %1009 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%966, %1008) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1010 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1009) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1011 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%995) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1012 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%981, %1011) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1013 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %1014 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%1012, %1013)\n",
            "  %1015 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%1014, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %1016 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%1015) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1017 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1016, %1010) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %1018 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1017) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %1019 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1018)\n",
            "  %1020 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1021 : Long(device=cpu) = onnx::Gather[axis=0](%1019, %1020) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1022 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1018)\n",
            "  %1023 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1024 : Long(device=cpu) = onnx::Gather[axis=0](%1022, %1023) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1026 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1021)\n",
            "  %1027 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1024)\n",
            "  %1029 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1026, %1027, %1732)\n",
            "  %1030 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1018, %1029) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %1032 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1030, %1733) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1033 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1032, %bert.encoder.layer.6.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1034 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1033, %957) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %1035 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1034)\n",
            "  %1036 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1034, %1035)\n",
            "  %1037 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1038 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1036, %1037)\n",
            "  %1039 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1038)\n",
            "  %1040 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1041 : Float(*, 128, 1, device=cpu) = onnx::Add(%1039, %1040)\n",
            "  %1042 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1041)\n",
            "  %1043 : Float(*, 128, 768, device=cpu) = onnx::Div(%1036, %1042)\n",
            "  %1044 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1043, %bert.encoder.layer.6.attention.output.LayerNorm.weight)\n",
            "  %1045 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1044, %bert.encoder.layer.6.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1047 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1045, %1734) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1048 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%1047, %bert.encoder.layer.6.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1049 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1050 : Float(*, 128, 3072, device=cpu) = onnx::Div(%1048, %1049)\n",
            "  %1051 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%1050)\n",
            "  %1052 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1053 : Float(*, 128, 3072, device=cpu) = onnx::Add(%1051, %1052)\n",
            "  %1054 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%1048, %1053)\n",
            "  %1055 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1056 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%1054, %1055) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %1058 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1056, %1735) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1059 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1058, %bert.encoder.layer.6.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1060 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1059, %1045) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %1061 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1060)\n",
            "  %1062 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1060, %1061)\n",
            "  %1063 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1064 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1062, %1063)\n",
            "  %1065 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1064)\n",
            "  %1066 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1067 : Float(*, 128, 1, device=cpu) = onnx::Add(%1065, %1066)\n",
            "  %1068 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1067)\n",
            "  %1069 : Float(*, 128, 768, device=cpu) = onnx::Div(%1062, %1068)\n",
            "  %1070 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1069, %bert.encoder.layer.6.output.LayerNorm.weight)\n",
            "  %1071 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1070, %bert.encoder.layer.6.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1073 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1071, %1736) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1074 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1073, %bert.encoder.layer.7.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1076 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1071, %1737) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1077 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1076, %bert.encoder.layer.7.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1079 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1071, %1738) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1080 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1079, %bert.encoder.layer.7.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1081 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1074)\n",
            "  %1082 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1083 : Long(device=cpu) = onnx::Gather[axis=0](%1081, %1082) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1084 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1074)\n",
            "  %1085 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1086 : Long(device=cpu) = onnx::Gather[axis=0](%1084, %1085) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1089 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1083)\n",
            "  %1090 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1086)\n",
            "  %1093 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1089, %1090, %1739, %1740)\n",
            "  %1094 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1074, %1093) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1095 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1094) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1096 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1077)\n",
            "  %1097 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1098 : Long(device=cpu) = onnx::Gather[axis=0](%1096, %1097) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1099 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1077)\n",
            "  %1100 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1101 : Long(device=cpu) = onnx::Gather[axis=0](%1099, %1100) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1104 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1098)\n",
            "  %1105 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1101)\n",
            "  %1108 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1104, %1105, %1741, %1742)\n",
            "  %1109 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1077, %1108) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1110 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1080)\n",
            "  %1111 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1112 : Long(device=cpu) = onnx::Gather[axis=0](%1110, %1111) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1113 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1080)\n",
            "  %1114 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1115 : Long(device=cpu) = onnx::Gather[axis=0](%1113, %1114) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1118 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1112)\n",
            "  %1119 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1115)\n",
            "  %1122 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1118, %1119, %1743, %1744)\n",
            "  %1123 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1080, %1122) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1124 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1123) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1125 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1109) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1126 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1095, %1125) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1127 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %1128 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%1126, %1127)\n",
            "  %1129 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%1128, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %1130 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%1129) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1131 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1130, %1124) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %1132 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1131) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %1133 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1132)\n",
            "  %1134 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1135 : Long(device=cpu) = onnx::Gather[axis=0](%1133, %1134) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1136 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1132)\n",
            "  %1137 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1138 : Long(device=cpu) = onnx::Gather[axis=0](%1136, %1137) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1140 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1135)\n",
            "  %1141 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1138)\n",
            "  %1143 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1140, %1141, %1745)\n",
            "  %1144 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1132, %1143) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %1146 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1144, %1746) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1147 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1146, %bert.encoder.layer.7.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1148 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1147, %1071) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %1149 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1148)\n",
            "  %1150 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1148, %1149)\n",
            "  %1151 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1152 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1150, %1151)\n",
            "  %1153 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1152)\n",
            "  %1154 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1155 : Float(*, 128, 1, device=cpu) = onnx::Add(%1153, %1154)\n",
            "  %1156 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1155)\n",
            "  %1157 : Float(*, 128, 768, device=cpu) = onnx::Div(%1150, %1156)\n",
            "  %1158 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1157, %bert.encoder.layer.7.attention.output.LayerNorm.weight)\n",
            "  %1159 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1158, %bert.encoder.layer.7.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1161 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1159, %1747) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1162 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%1161, %bert.encoder.layer.7.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1163 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1164 : Float(*, 128, 3072, device=cpu) = onnx::Div(%1162, %1163)\n",
            "  %1165 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%1164)\n",
            "  %1166 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1167 : Float(*, 128, 3072, device=cpu) = onnx::Add(%1165, %1166)\n",
            "  %1168 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%1162, %1167)\n",
            "  %1169 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1170 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%1168, %1169) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %1172 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1170, %1748) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1173 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1172, %bert.encoder.layer.7.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1174 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1173, %1159) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %1175 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1174)\n",
            "  %1176 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1174, %1175)\n",
            "  %1177 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1178 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1176, %1177)\n",
            "  %1179 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1178)\n",
            "  %1180 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1181 : Float(*, 128, 1, device=cpu) = onnx::Add(%1179, %1180)\n",
            "  %1182 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1181)\n",
            "  %1183 : Float(*, 128, 768, device=cpu) = onnx::Div(%1176, %1182)\n",
            "  %1184 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1183, %bert.encoder.layer.7.output.LayerNorm.weight)\n",
            "  %1185 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1184, %bert.encoder.layer.7.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1187 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1185, %1749) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1188 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1187, %bert.encoder.layer.8.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1190 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1185, %1750) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1191 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1190, %bert.encoder.layer.8.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1193 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1185, %1751) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1194 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1193, %bert.encoder.layer.8.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1195 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1188)\n",
            "  %1196 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1197 : Long(device=cpu) = onnx::Gather[axis=0](%1195, %1196) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1198 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1188)\n",
            "  %1199 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1200 : Long(device=cpu) = onnx::Gather[axis=0](%1198, %1199) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1203 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1197)\n",
            "  %1204 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1200)\n",
            "  %1207 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1203, %1204, %1752, %1753)\n",
            "  %1208 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1188, %1207) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1209 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1208) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1210 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1191)\n",
            "  %1211 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1212 : Long(device=cpu) = onnx::Gather[axis=0](%1210, %1211) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1213 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1191)\n",
            "  %1214 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1215 : Long(device=cpu) = onnx::Gather[axis=0](%1213, %1214) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1218 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1212)\n",
            "  %1219 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1215)\n",
            "  %1222 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1218, %1219, %1754, %1755)\n",
            "  %1223 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1191, %1222) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1224 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1194)\n",
            "  %1225 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1226 : Long(device=cpu) = onnx::Gather[axis=0](%1224, %1225) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1227 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1194)\n",
            "  %1228 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1229 : Long(device=cpu) = onnx::Gather[axis=0](%1227, %1228) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1232 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1226)\n",
            "  %1233 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1229)\n",
            "  %1236 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1232, %1233, %1756, %1757)\n",
            "  %1237 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1194, %1236) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1238 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1237) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1239 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1223) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1240 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1209, %1239) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1241 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %1242 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%1240, %1241)\n",
            "  %1243 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%1242, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %1244 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%1243) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1245 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1244, %1238) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %1246 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1245) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %1247 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1246)\n",
            "  %1248 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1249 : Long(device=cpu) = onnx::Gather[axis=0](%1247, %1248) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1250 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1246)\n",
            "  %1251 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1252 : Long(device=cpu) = onnx::Gather[axis=0](%1250, %1251) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1254 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1249)\n",
            "  %1255 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1252)\n",
            "  %1257 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1254, %1255, %1758)\n",
            "  %1258 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1246, %1257) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %1260 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1258, %1759) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1261 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1260, %bert.encoder.layer.8.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1262 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1261, %1185) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %1263 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1262)\n",
            "  %1264 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1262, %1263)\n",
            "  %1265 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1266 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1264, %1265)\n",
            "  %1267 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1266)\n",
            "  %1268 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1269 : Float(*, 128, 1, device=cpu) = onnx::Add(%1267, %1268)\n",
            "  %1270 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1269)\n",
            "  %1271 : Float(*, 128, 768, device=cpu) = onnx::Div(%1264, %1270)\n",
            "  %1272 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1271, %bert.encoder.layer.8.attention.output.LayerNorm.weight)\n",
            "  %1273 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1272, %bert.encoder.layer.8.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1275 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1273, %1760) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1276 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%1275, %bert.encoder.layer.8.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1277 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1278 : Float(*, 128, 3072, device=cpu) = onnx::Div(%1276, %1277)\n",
            "  %1279 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%1278)\n",
            "  %1280 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1281 : Float(*, 128, 3072, device=cpu) = onnx::Add(%1279, %1280)\n",
            "  %1282 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%1276, %1281)\n",
            "  %1283 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1284 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%1282, %1283) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %1286 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1284, %1761) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1287 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1286, %bert.encoder.layer.8.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1288 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1287, %1273) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %1289 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1288)\n",
            "  %1290 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1288, %1289)\n",
            "  %1291 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1292 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1290, %1291)\n",
            "  %1293 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1292)\n",
            "  %1294 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1295 : Float(*, 128, 1, device=cpu) = onnx::Add(%1293, %1294)\n",
            "  %1296 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1295)\n",
            "  %1297 : Float(*, 128, 768, device=cpu) = onnx::Div(%1290, %1296)\n",
            "  %1298 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1297, %bert.encoder.layer.8.output.LayerNorm.weight)\n",
            "  %1299 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1298, %bert.encoder.layer.8.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1301 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1299, %1762) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1302 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1301, %bert.encoder.layer.9.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1304 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1299, %1763) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1305 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1304, %bert.encoder.layer.9.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1307 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1299, %1764) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1308 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1307, %bert.encoder.layer.9.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1309 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1302)\n",
            "  %1310 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1311 : Long(device=cpu) = onnx::Gather[axis=0](%1309, %1310) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1312 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1302)\n",
            "  %1313 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1314 : Long(device=cpu) = onnx::Gather[axis=0](%1312, %1313) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1317 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1311)\n",
            "  %1318 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1314)\n",
            "  %1321 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1317, %1318, %1765, %1766)\n",
            "  %1322 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1302, %1321) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1323 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1322) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1324 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1305)\n",
            "  %1325 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1326 : Long(device=cpu) = onnx::Gather[axis=0](%1324, %1325) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1327 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1305)\n",
            "  %1328 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1329 : Long(device=cpu) = onnx::Gather[axis=0](%1327, %1328) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1332 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1326)\n",
            "  %1333 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1329)\n",
            "  %1336 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1332, %1333, %1767, %1768)\n",
            "  %1337 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1305, %1336) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1338 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1308)\n",
            "  %1339 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1340 : Long(device=cpu) = onnx::Gather[axis=0](%1338, %1339) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1341 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1308)\n",
            "  %1342 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1343 : Long(device=cpu) = onnx::Gather[axis=0](%1341, %1342) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1346 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1340)\n",
            "  %1347 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1343)\n",
            "  %1350 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1346, %1347, %1769, %1770)\n",
            "  %1351 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1308, %1350) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1352 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1351) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1353 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1337) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1354 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1323, %1353) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1355 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %1356 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%1354, %1355)\n",
            "  %1357 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%1356, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %1358 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%1357) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1359 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1358, %1352) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %1360 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1359) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %1361 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1360)\n",
            "  %1362 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1363 : Long(device=cpu) = onnx::Gather[axis=0](%1361, %1362) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1364 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1360)\n",
            "  %1365 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1366 : Long(device=cpu) = onnx::Gather[axis=0](%1364, %1365) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1368 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1363)\n",
            "  %1369 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1366)\n",
            "  %1371 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1368, %1369, %1771)\n",
            "  %1372 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1360, %1371) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %1374 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1372, %1772) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1375 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1374, %bert.encoder.layer.9.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1376 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1375, %1299) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %1377 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1376)\n",
            "  %1378 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1376, %1377)\n",
            "  %1379 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1380 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1378, %1379)\n",
            "  %1381 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1380)\n",
            "  %1382 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1383 : Float(*, 128, 1, device=cpu) = onnx::Add(%1381, %1382)\n",
            "  %1384 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1383)\n",
            "  %1385 : Float(*, 128, 768, device=cpu) = onnx::Div(%1378, %1384)\n",
            "  %1386 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1385, %bert.encoder.layer.9.attention.output.LayerNorm.weight)\n",
            "  %1387 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1386, %bert.encoder.layer.9.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1389 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1387, %1773) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1390 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%1389, %bert.encoder.layer.9.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1391 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1392 : Float(*, 128, 3072, device=cpu) = onnx::Div(%1390, %1391)\n",
            "  %1393 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%1392)\n",
            "  %1394 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1395 : Float(*, 128, 3072, device=cpu) = onnx::Add(%1393, %1394)\n",
            "  %1396 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%1390, %1395)\n",
            "  %1397 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1398 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%1396, %1397) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %1400 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1398, %1774) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1401 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1400, %bert.encoder.layer.9.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1402 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1401, %1387) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %1403 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1402)\n",
            "  %1404 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1402, %1403)\n",
            "  %1405 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1406 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1404, %1405)\n",
            "  %1407 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1406)\n",
            "  %1408 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1409 : Float(*, 128, 1, device=cpu) = onnx::Add(%1407, %1408)\n",
            "  %1410 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1409)\n",
            "  %1411 : Float(*, 128, 768, device=cpu) = onnx::Div(%1404, %1410)\n",
            "  %1412 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1411, %bert.encoder.layer.9.output.LayerNorm.weight)\n",
            "  %1413 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1412, %bert.encoder.layer.9.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1415 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1413, %1775) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1416 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1415, %bert.encoder.layer.10.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1418 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1413, %1776) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1419 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1418, %bert.encoder.layer.10.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1421 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1413, %1777) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1422 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1421, %bert.encoder.layer.10.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1423 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1416)\n",
            "  %1424 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1425 : Long(device=cpu) = onnx::Gather[axis=0](%1423, %1424) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1426 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1416)\n",
            "  %1427 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1428 : Long(device=cpu) = onnx::Gather[axis=0](%1426, %1427) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1431 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1425)\n",
            "  %1432 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1428)\n",
            "  %1435 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1431, %1432, %1778, %1779)\n",
            "  %1436 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1416, %1435) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1437 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1436) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1438 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1419)\n",
            "  %1439 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1440 : Long(device=cpu) = onnx::Gather[axis=0](%1438, %1439) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1441 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1419)\n",
            "  %1442 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1443 : Long(device=cpu) = onnx::Gather[axis=0](%1441, %1442) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1446 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1440)\n",
            "  %1447 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1443)\n",
            "  %1450 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1446, %1447, %1780, %1781)\n",
            "  %1451 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1419, %1450) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1452 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1422)\n",
            "  %1453 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1454 : Long(device=cpu) = onnx::Gather[axis=0](%1452, %1453) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1455 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1422)\n",
            "  %1456 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1457 : Long(device=cpu) = onnx::Gather[axis=0](%1455, %1456) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1460 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1454)\n",
            "  %1461 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1457)\n",
            "  %1464 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1460, %1461, %1782, %1783)\n",
            "  %1465 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1422, %1464) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1466 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1465) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1467 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1451) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1468 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1437, %1467) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1469 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %1470 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%1468, %1469)\n",
            "  %1471 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%1470, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %1472 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%1471) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1473 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1472, %1466) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %1474 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1473) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %1475 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1474)\n",
            "  %1476 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1477 : Long(device=cpu) = onnx::Gather[axis=0](%1475, %1476) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1478 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1474)\n",
            "  %1479 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1480 : Long(device=cpu) = onnx::Gather[axis=0](%1478, %1479) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1482 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1477)\n",
            "  %1483 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1480)\n",
            "  %1485 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1482, %1483, %1784)\n",
            "  %1486 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1474, %1485) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %1488 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1486, %1785) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1489 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1488, %bert.encoder.layer.10.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1490 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1489, %1413) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %1491 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1490)\n",
            "  %1492 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1490, %1491)\n",
            "  %1493 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1494 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1492, %1493)\n",
            "  %1495 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1494)\n",
            "  %1496 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1497 : Float(*, 128, 1, device=cpu) = onnx::Add(%1495, %1496)\n",
            "  %1498 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1497)\n",
            "  %1499 : Float(*, 128, 768, device=cpu) = onnx::Div(%1492, %1498)\n",
            "  %1500 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1499, %bert.encoder.layer.10.attention.output.LayerNorm.weight)\n",
            "  %1501 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1500, %bert.encoder.layer.10.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1503 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1501, %1786) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1504 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%1503, %bert.encoder.layer.10.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1505 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1506 : Float(*, 128, 3072, device=cpu) = onnx::Div(%1504, %1505)\n",
            "  %1507 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%1506)\n",
            "  %1508 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1509 : Float(*, 128, 3072, device=cpu) = onnx::Add(%1507, %1508)\n",
            "  %1510 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%1504, %1509)\n",
            "  %1511 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1512 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%1510, %1511) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %1514 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1512, %1787) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1515 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1514, %bert.encoder.layer.10.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1516 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1515, %1501) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %1517 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1516)\n",
            "  %1518 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1516, %1517)\n",
            "  %1519 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1520 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1518, %1519)\n",
            "  %1521 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1520)\n",
            "  %1522 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1523 : Float(*, 128, 1, device=cpu) = onnx::Add(%1521, %1522)\n",
            "  %1524 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1523)\n",
            "  %1525 : Float(*, 128, 768, device=cpu) = onnx::Div(%1518, %1524)\n",
            "  %1526 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1525, %bert.encoder.layer.10.output.LayerNorm.weight)\n",
            "  %1527 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1526, %bert.encoder.layer.10.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1529 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1527, %1788) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1530 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1529, %bert.encoder.layer.11.attention.self.query.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1532 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1527, %1789) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1533 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1532, %bert.encoder.layer.11.attention.self.key.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1535 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1527, %1790) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1536 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1535, %bert.encoder.layer.11.attention.self.value.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1537 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1530)\n",
            "  %1538 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1539 : Long(device=cpu) = onnx::Gather[axis=0](%1537, %1538) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1540 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1530)\n",
            "  %1541 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1542 : Long(device=cpu) = onnx::Gather[axis=0](%1540, %1541) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1545 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1539)\n",
            "  %1546 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1542)\n",
            "  %1549 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1545, %1546, %1791, %1792)\n",
            "  %1550 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1530, %1549) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1551 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1550) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1552 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1533)\n",
            "  %1553 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1554 : Long(device=cpu) = onnx::Gather[axis=0](%1552, %1553) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1555 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1533)\n",
            "  %1556 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1557 : Long(device=cpu) = onnx::Gather[axis=0](%1555, %1556) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1560 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1554)\n",
            "  %1561 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1557)\n",
            "  %1564 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1560, %1561, %1793, %1794)\n",
            "  %1565 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1533, %1564) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1566 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1536)\n",
            "  %1567 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1568 : Long(device=cpu) = onnx::Gather[axis=0](%1566, %1567) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1569 : Long(3, strides=[1], device=cpu) = onnx::Shape(%1536)\n",
            "  %1570 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1571 : Long(device=cpu) = onnx::Gather[axis=0](%1569, %1570) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:204:0\n",
            "  %1574 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1568)\n",
            "  %1575 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1571)\n",
            "  %1578 : Long(4, strides=[1], device=cpu) = onnx::Concat[axis=0](%1574, %1575, %1795, %1796)\n",
            "  %1579 : Float(1, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1536, %1578) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:205:0\n",
            "  %1580 : Float(1, 8, 128, 96, strides=[98304, 96, 768, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1579) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:206:0\n",
            "  %1581 : Float(1, 8, 96, 128, strides=[98304, 96, 1, 768], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 3, 1]](%1565) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1582 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1551, %1581) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:234:0\n",
            "  %1583 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={9.79796}]()\n",
            "  %1584 : Float(1, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Div(%1582, %1583)\n",
            "  %1585 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Add(%1584, %215) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:238:0\n",
            "  %1586 : Float(*, 8, 128, 128, strides=[131072, 16384, 128, 1], requires_grad=1, device=cpu) = onnx::Softmax[axis=3](%1585) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1587 : Float(*, 8, 128, 96, strides=[98304, 12288, 96, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1586, %1580) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:251:0\n",
            "  %1588 : Float(*, 128, 8, 96, strides=[98304, 768, 96, 1], requires_grad=1, device=cpu) = onnx::Transpose[perm=[0, 2, 1, 3]](%1587) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:253:0\n",
            "  %1589 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1588)\n",
            "  %1590 : Long(device=cpu) = onnx::Constant[value={0}]()\n",
            "  %1591 : Long(device=cpu) = onnx::Gather[axis=0](%1589, %1590) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1592 : Long(4, strides=[1], device=cpu) = onnx::Shape(%1588)\n",
            "  %1593 : Long(device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1594 : Long(device=cpu) = onnx::Gather[axis=0](%1592, %1593) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:254:0\n",
            "  %1596 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1591)\n",
            "  %1597 : Long(1, strides=[1], device=cpu) = onnx::Unsqueeze[axes=[0]](%1594)\n",
            "  %1599 : Long(3, strides=[1], device=cpu) = onnx::Concat[axis=0](%1596, %1597, %1797)\n",
            "  %1600 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Reshape(%1588, %1599) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:255:0\n",
            "  %1602 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1600, %1798) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1603 : Float(1, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1602, %bert.encoder.layer.11.attention.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1604 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1603, %1527) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:271:0\n",
            "  %1605 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1604)\n",
            "  %1606 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1604, %1605)\n",
            "  %1607 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1608 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1606, %1607)\n",
            "  %1609 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1608)\n",
            "  %1610 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1611 : Float(*, 128, 1, device=cpu) = onnx::Add(%1609, %1610)\n",
            "  %1612 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1611)\n",
            "  %1613 : Float(*, 128, 768, device=cpu) = onnx::Div(%1606, %1612)\n",
            "  %1614 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1613, %bert.encoder.layer.11.attention.output.LayerNorm.weight)\n",
            "  %1615 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1614, %bert.encoder.layer.11.attention.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:2205:0\n",
            "  %1617 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1615, %1799) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1618 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Add(%1617, %bert.encoder.layer.11.intermediate.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1619 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1.41421}]()\n",
            "  %1620 : Float(*, 128, 3072, device=cpu) = onnx::Div(%1618, %1619)\n",
            "  %1621 : Float(*, 128, 3072, device=cpu) = onnx::Erf(%1620)\n",
            "  %1622 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1}]()\n",
            "  %1623 : Float(*, 128, 3072, device=cpu) = onnx::Add(%1621, %1622)\n",
            "  %1624 : Float(*, 128, 3072, device=cpu) = onnx::Mul(%1618, %1623)\n",
            "  %1625 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={0.5}]()\n",
            "  %1626 : Float(*, 128, 3072, strides=[393216, 3072, 1], requires_grad=1, device=cpu) = onnx::Mul(%1624, %1625) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1459:0\n",
            "  %1628 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1626, %1800) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %1629 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1628, %bert.encoder.layer.11.output.dense.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1630 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1629, %1615) # /usr/local/lib/python3.7/dist-packages/transformers/modeling_bert.py:346:0\n",
            "  %1631 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1630)\n",
            "  %1632 : Float(*, 128, 768, device=cpu) = onnx::Sub(%1630, %1631)\n",
            "  %1633 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={2}]()\n",
            "  %1634 : Float(*, 128, 768, device=cpu) = onnx::Pow(%1632, %1633)\n",
            "  %1635 : Float(*, 128, 1, device=cpu) = onnx::ReduceMean[axes=[-1]](%1634)\n",
            "  %1636 : Float(requires_grad=0, device=cpu) = onnx::Constant[value={1e-12}]()\n",
            "  %1637 : Float(*, 128, 1, device=cpu) = onnx::Add(%1635, %1636)\n",
            "  %1638 : Float(*, 128, 1, device=cpu) = onnx::Sqrt(%1637)\n",
            "  %1639 : Float(*, 128, 768, device=cpu) = onnx::Div(%1632, %1638)\n",
            "  %1640 : Float(*, 128, 768, device=cpu) = onnx::Mul(%1639, %bert.encoder.layer.11.output.LayerNorm.weight)\n",
            "  %1641 : Float(*, 128, 768, strides=[98304, 768, 1], requires_grad=1, device=cpu) = onnx::Add(%1640, %bert.encoder.layer.11.output.LayerNorm.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1076:0\n",
            "  %1643 : Float(*, 128, 4, strides=[512, 4, 1], requires_grad=1, device=cpu) = onnx::MatMul(%1641, %1801) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  %outputs : Float(*, 128, 4, strides=[512, 4, 1], requires_grad=1, device=cpu) = onnx::Add(%1643, %classifier.bias) # /usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1753:0\n",
            "  return (%outputs)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SHO79NQS6Ydh",
        "outputId": "a44fb6f9-f8e4-4acb-f8dd-54cf49c24c99"
      },
      "source": [
        "import onnx_tf\n",
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(f\"{ONNX_MODEL_PATH}/{MODEL_NAME}\")\n",
        "tf_rep = onnx_tf.backend.prepare(onnx_model)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/ceil.py:10: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/depth_to_space.py:12: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/erf.py:9: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
            "\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/is_nan.py:9: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/log.py:10: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/random_normal.py:9: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/random_uniform.py:9: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/reciprocal.py:10: The name tf.reciprocal is deprecated. Please use tf.math.reciprocal instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/space_to_depth.py:12: The name tf.space_to_depth is deprecated. Please use tf.compat.v1.space_to_depth instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/upsample.py:16: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/xor.py:10: The name tf.logical_xor is deprecated. Please use tf.math.logical_xor instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/content/onnx-tensorflow/onnx_tf/common/__init__.py:96: UserWarning: onnx_tf.common.get_outputs_names is deprecated. It will be removed in future release. Use TensorflowGraph.get_outputs_names instead.\n",
            "  warnings.warn(message)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/backend.py:124: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/non_zero.py:14: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend_handler.py:188: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /content/onnx-tensorflow/onnx_tf/handlers/backend/reshape.py:31: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xB-mtS3_Iq5q",
        "outputId": "e1403fb3-0c47-4770-ae3a-0a03b74cccce"
      },
      "source": [
        "!pip install tensorflow-addons\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 696
        },
        "id": "mfyuFeL_Itci",
        "outputId": "db4dd114-5aa3-4b14-b683-21dc354dd5a5"
      },
      "source": [
        "import onnx_tf\n",
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(f\"{ONNX_MODEL_PATH}/{MODEL_NAME}\")\n",
        "tf_rep = onnx_tf.backend.prepare(onnx_model)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.6.0 (nightly versions are not supported). \n",
            " The versions of TensorFlow you are currently using is 1.15.0 and is not supported. \n",
            "Some things might work, some things might not.\n",
            "If you were to encounter a bug, do not file an issue.\n",
            "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
            "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
            "https://github.com/tensorflow/addons\n",
            "  UserWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-622c0749c450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0monnx_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{ONNX_MODEL_PATH}/{MODEL_NAME}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtf_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/onnx-tensorflow/onnx_tf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/onnx-tensorflow/onnx_tf/backend.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_unique_suffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msupports_device\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcommon_supports_device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandler_helper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_all_backend_handlers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpb_wrapper\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOnnxNode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_tf_module\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackendTFModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTFModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/onnx-tensorflow/onnx_tf/common/handler_helper.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdefs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_handler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackendHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommon\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcommon\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/onnx-tensorflow/onnx_tf/handlers/backend/hardmax.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend_handler\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBackendHandler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Local project imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Additional activation functions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhardshrink\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhardshrink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisht\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlisht\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/activations/gelu.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtypes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTensorLike\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow_addons/utils/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'keras_tensor' from 'tensorflow.python.keras.engine' (/usr/local/lib/python3.7/dist-packages/tensorflow_core/python/keras/engine/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "cLHXq7YxByUy",
        "outputId": "c6feb164-611a-49f5-f1a1-11e7ccc57482"
      },
      "source": [
        "\n",
        "onnx.checker.check_model(onnx_model, full_check=True)\n",
        "onnx.helper.printable_graph(onnx_model.graph)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'graph torch-jit-export (\\n  %input_ids[INT64, batchxmax_seq]\\n  %input_bbox[INT64, 1x128x4]\\n  %attention_mask[INT64, batchxmax_seq]\\n  %token_type_ids[INT64, batchxmax_seq]\\n) initializers (\\n  %bert.embeddings.word_embeddings.weight[FLOAT, 30522x768]\\n  %bert.embeddings.position_embeddings.weight[FLOAT, 512x768]\\n  %bert.embeddings.x_position_embeddings.weight[FLOAT, 1024x768]\\n  %bert.embeddings.y_position_embeddings.weight[FLOAT, 1024x768]\\n  %bert.embeddings.h_position_embeddings.weight[FLOAT, 1024x768]\\n  %bert.embeddings.w_position_embeddings.weight[FLOAT, 1024x768]\\n  %bert.embeddings.token_type_embeddings.weight[FLOAT, 2x768]\\n  %bert.embeddings.LayerNorm.weight[FLOAT, 768]\\n  %bert.embeddings.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.0.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.0.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.0.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.0.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.0.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.0.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.0.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.0.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.0.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.0.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.1.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.1.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.1.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.1.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.1.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.1.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.1.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.1.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.1.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.1.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.2.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.2.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.2.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.2.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.2.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.2.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.2.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.2.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.2.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.2.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.3.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.3.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.3.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.3.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.3.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.3.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.3.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.3.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.3.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.3.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.4.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.4.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.4.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.4.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.4.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.4.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.4.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.4.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.4.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.4.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.5.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.5.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.5.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.5.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.5.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.5.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.5.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.5.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.5.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.5.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.6.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.6.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.6.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.6.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.6.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.6.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.6.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.6.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.6.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.6.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.7.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.7.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.7.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.7.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.7.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.7.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.7.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.7.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.7.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.7.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.8.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.8.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.8.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.8.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.8.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.8.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.8.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.8.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.8.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.8.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.9.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.9.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.9.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.9.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.9.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.9.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.9.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.9.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.9.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.9.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.10.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.10.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.10.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.10.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.10.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.10.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.10.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.10.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.10.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.10.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.11.attention.self.query.bias[FLOAT, 768]\\n  %bert.encoder.layer.11.attention.self.key.bias[FLOAT, 768]\\n  %bert.encoder.layer.11.attention.self.value.bias[FLOAT, 768]\\n  %bert.encoder.layer.11.attention.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.11.attention.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.11.attention.output.LayerNorm.bias[FLOAT, 768]\\n  %bert.encoder.layer.11.intermediate.dense.bias[FLOAT, 3072]\\n  %bert.encoder.layer.11.output.dense.bias[FLOAT, 768]\\n  %bert.encoder.layer.11.output.LayerNorm.weight[FLOAT, 768]\\n  %bert.encoder.layer.11.output.LayerNorm.bias[FLOAT, 768]\\n  %classifier.bias[FLOAT, 4]\\n  %1645[FLOAT, 768x768]\\n  %1646[FLOAT, 768x768]\\n  %1647[FLOAT, 768x768]\\n  %1648[INT64, 1]\\n  %1649[INT64, 1]\\n  %1650[INT64, 1]\\n  %1651[INT64, 1]\\n  %1652[INT64, 1]\\n  %1653[INT64, 1]\\n  %1654[INT64, 1]\\n  %1655[FLOAT, 768x768]\\n  %1656[FLOAT, 768x3072]\\n  %1657[FLOAT, 3072x768]\\n  %1658[FLOAT, 768x768]\\n  %1659[FLOAT, 768x768]\\n  %1660[FLOAT, 768x768]\\n  %1661[INT64, 1]\\n  %1662[INT64, 1]\\n  %1663[INT64, 1]\\n  %1664[INT64, 1]\\n  %1665[INT64, 1]\\n  %1666[INT64, 1]\\n  %1667[INT64, 1]\\n  %1668[FLOAT, 768x768]\\n  %1669[FLOAT, 768x3072]\\n  %1670[FLOAT, 3072x768]\\n  %1671[FLOAT, 768x768]\\n  %1672[FLOAT, 768x768]\\n  %1673[FLOAT, 768x768]\\n  %1674[INT64, 1]\\n  %1675[INT64, 1]\\n  %1676[INT64, 1]\\n  %1677[INT64, 1]\\n  %1678[INT64, 1]\\n  %1679[INT64, 1]\\n  %1680[INT64, 1]\\n  %1681[FLOAT, 768x768]\\n  %1682[FLOAT, 768x3072]\\n  %1683[FLOAT, 3072x768]\\n  %1684[FLOAT, 768x768]\\n  %1685[FLOAT, 768x768]\\n  %1686[FLOAT, 768x768]\\n  %1687[INT64, 1]\\n  %1688[INT64, 1]\\n  %1689[INT64, 1]\\n  %1690[INT64, 1]\\n  %1691[INT64, 1]\\n  %1692[INT64, 1]\\n  %1693[INT64, 1]\\n  %1694[FLOAT, 768x768]\\n  %1695[FLOAT, 768x3072]\\n  %1696[FLOAT, 3072x768]\\n  %1697[FLOAT, 768x768]\\n  %1698[FLOAT, 768x768]\\n  %1699[FLOAT, 768x768]\\n  %1700[INT64, 1]\\n  %1701[INT64, 1]\\n  %1702[INT64, 1]\\n  %1703[INT64, 1]\\n  %1704[INT64, 1]\\n  %1705[INT64, 1]\\n  %1706[INT64, 1]\\n  %1707[FLOAT, 768x768]\\n  %1708[FLOAT, 768x3072]\\n  %1709[FLOAT, 3072x768]\\n  %1710[FLOAT, 768x768]\\n  %1711[FLOAT, 768x768]\\n  %1712[FLOAT, 768x768]\\n  %1713[INT64, 1]\\n  %1714[INT64, 1]\\n  %1715[INT64, 1]\\n  %1716[INT64, 1]\\n  %1717[INT64, 1]\\n  %1718[INT64, 1]\\n  %1719[INT64, 1]\\n  %1720[FLOAT, 768x768]\\n  %1721[FLOAT, 768x3072]\\n  %1722[FLOAT, 3072x768]\\n  %1723[FLOAT, 768x768]\\n  %1724[FLOAT, 768x768]\\n  %1725[FLOAT, 768x768]\\n  %1726[INT64, 1]\\n  %1727[INT64, 1]\\n  %1728[INT64, 1]\\n  %1729[INT64, 1]\\n  %1730[INT64, 1]\\n  %1731[INT64, 1]\\n  %1732[INT64, 1]\\n  %1733[FLOAT, 768x768]\\n  %1734[FLOAT, 768x3072]\\n  %1735[FLOAT, 3072x768]\\n  %1736[FLOAT, 768x768]\\n  %1737[FLOAT, 768x768]\\n  %1738[FLOAT, 768x768]\\n  %1739[INT64, 1]\\n  %1740[INT64, 1]\\n  %1741[INT64, 1]\\n  %1742[INT64, 1]\\n  %1743[INT64, 1]\\n  %1744[INT64, 1]\\n  %1745[INT64, 1]\\n  %1746[FLOAT, 768x768]\\n  %1747[FLOAT, 768x3072]\\n  %1748[FLOAT, 3072x768]\\n  %1749[FLOAT, 768x768]\\n  %1750[FLOAT, 768x768]\\n  %1751[FLOAT, 768x768]\\n  %1752[INT64, 1]\\n  %1753[INT64, 1]\\n  %1754[INT64, 1]\\n  %1755[INT64, 1]\\n  %1756[INT64, 1]\\n  %1757[INT64, 1]\\n  %1758[INT64, 1]\\n  %1759[FLOAT, 768x768]\\n  %1760[FLOAT, 768x3072]\\n  %1761[FLOAT, 3072x768]\\n  %1762[FLOAT, 768x768]\\n  %1763[FLOAT, 768x768]\\n  %1764[FLOAT, 768x768]\\n  %1765[INT64, 1]\\n  %1766[INT64, 1]\\n  %1767[INT64, 1]\\n  %1768[INT64, 1]\\n  %1769[INT64, 1]\\n  %1770[INT64, 1]\\n  %1771[INT64, 1]\\n  %1772[FLOAT, 768x768]\\n  %1773[FLOAT, 768x3072]\\n  %1774[FLOAT, 3072x768]\\n  %1775[FLOAT, 768x768]\\n  %1776[FLOAT, 768x768]\\n  %1777[FLOAT, 768x768]\\n  %1778[INT64, 1]\\n  %1779[INT64, 1]\\n  %1780[INT64, 1]\\n  %1781[INT64, 1]\\n  %1782[INT64, 1]\\n  %1783[INT64, 1]\\n  %1784[INT64, 1]\\n  %1785[FLOAT, 768x768]\\n  %1786[FLOAT, 768x3072]\\n  %1787[FLOAT, 3072x768]\\n  %1788[FLOAT, 768x768]\\n  %1789[FLOAT, 768x768]\\n  %1790[FLOAT, 768x768]\\n  %1791[INT64, 1]\\n  %1792[INT64, 1]\\n  %1793[INT64, 1]\\n  %1794[INT64, 1]\\n  %1795[INT64, 1]\\n  %1796[INT64, 1]\\n  %1797[INT64, 1]\\n  %1798[FLOAT, 768x768]\\n  %1799[FLOAT, 768x3072]\\n  %1800[FLOAT, 3072x768]\\n  %1801[FLOAT, 768x4]\\n) {\\n  %209 = Unsqueeze[axes = [1]](%attention_mask)\\n  %210 = Unsqueeze[axes = [2]](%209)\\n  %211 = Cast[to = 1](%210)\\n  %212 = Constant[value = <Scalar Tensor []>]()\\n  %213 = Sub(%212, %211)\\n  %214 = Constant[value = <Scalar Tensor []>]()\\n  %215 = Mul(%213, %214)\\n  %216 = Shape(%input_ids)\\n  %217 = Constant[value = <Scalar Tensor []>]()\\n  %218 = Gather[axis = 0](%216, %217)\\n  %219 = Unsqueeze[axes = [0]](%218)\\n  %220 = ConstantOfShape[value = <Tensor>](%219)\\n  %221 = NonZero(%220)\\n  %222 = Transpose[perm = [1, 0]](%221)\\n  %223 = Squeeze[axes = [1]](%222)\\n  %224 = Cast[to = 7](%223)\\n  %225 = Unsqueeze[axes = [0]](%224)\\n  %226 = Shape(%input_ids)\\n  %227 = Expand(%225, %226)\\n  %228 = Gather(%bert.embeddings.word_embeddings.weight, %input_ids)\\n  %229 = Gather(%bert.embeddings.position_embeddings.weight, %227)\\n  %230 = Constant[value = <Scalar Tensor []>]()\\n  %231 = Gather[axis = 2](%input_bbox, %230)\\n  %232 = Gather(%bert.embeddings.x_position_embeddings.weight, %231)\\n  %233 = Constant[value = <Scalar Tensor []>]()\\n  %234 = Gather[axis = 2](%input_bbox, %233)\\n  %235 = Gather(%bert.embeddings.y_position_embeddings.weight, %234)\\n  %236 = Constant[value = <Scalar Tensor []>]()\\n  %237 = Gather[axis = 2](%input_bbox, %236)\\n  %238 = Gather(%bert.embeddings.x_position_embeddings.weight, %237)\\n  %239 = Constant[value = <Scalar Tensor []>]()\\n  %240 = Gather[axis = 2](%input_bbox, %239)\\n  %241 = Gather(%bert.embeddings.y_position_embeddings.weight, %240)\\n  %242 = Constant[value = <Scalar Tensor []>]()\\n  %243 = Gather[axis = 2](%input_bbox, %242)\\n  %244 = Constant[value = <Scalar Tensor []>]()\\n  %245 = Gather[axis = 2](%input_bbox, %244)\\n  %246 = Sub(%243, %245)\\n  %247 = Gather(%bert.embeddings.h_position_embeddings.weight, %246)\\n  %248 = Constant[value = <Scalar Tensor []>]()\\n  %249 = Gather[axis = 2](%input_bbox, %248)\\n  %250 = Constant[value = <Scalar Tensor []>]()\\n  %251 = Gather[axis = 2](%input_bbox, %250)\\n  %252 = Sub(%249, %251)\\n  %253 = Gather(%bert.embeddings.w_position_embeddings.weight, %252)\\n  %254 = Gather(%bert.embeddings.token_type_embeddings.weight, %token_type_ids)\\n  %255 = Add(%228, %229)\\n  %256 = Add(%255, %232)\\n  %257 = Add(%256, %235)\\n  %258 = Add(%257, %238)\\n  %259 = Add(%258, %241)\\n  %260 = Add(%259, %247)\\n  %261 = Add(%260, %253)\\n  %262 = Add(%261, %254)\\n  %263 = ReduceMean[axes = [-1]](%262)\\n  %264 = Sub(%262, %263)\\n  %265 = Constant[value = <Scalar Tensor []>]()\\n  %266 = Pow(%264, %265)\\n  %267 = ReduceMean[axes = [-1]](%266)\\n  %268 = Constant[value = <Scalar Tensor []>]()\\n  %269 = Add(%267, %268)\\n  %270 = Sqrt(%269)\\n  %271 = Div(%264, %270)\\n  %272 = Mul(%271, %bert.embeddings.LayerNorm.weight)\\n  %273 = Add(%272, %bert.embeddings.LayerNorm.bias)\\n  %275 = MatMul(%273, %1645)\\n  %276 = Add(%275, %bert.encoder.layer.0.attention.self.query.bias)\\n  %278 = MatMul(%273, %1646)\\n  %279 = Add(%278, %bert.encoder.layer.0.attention.self.key.bias)\\n  %281 = MatMul(%273, %1647)\\n  %282 = Add(%281, %bert.encoder.layer.0.attention.self.value.bias)\\n  %283 = Shape(%276)\\n  %284 = Constant[value = <Scalar Tensor []>]()\\n  %285 = Gather[axis = 0](%283, %284)\\n  %286 = Shape(%276)\\n  %287 = Constant[value = <Scalar Tensor []>]()\\n  %288 = Gather[axis = 0](%286, %287)\\n  %291 = Unsqueeze[axes = [0]](%285)\\n  %292 = Unsqueeze[axes = [0]](%288)\\n  %295 = Concat[axis = 0](%291, %292, %1648, %1649)\\n  %296 = Reshape(%276, %295)\\n  %297 = Transpose[perm = [0, 2, 1, 3]](%296)\\n  %298 = Shape(%279)\\n  %299 = Constant[value = <Scalar Tensor []>]()\\n  %300 = Gather[axis = 0](%298, %299)\\n  %301 = Shape(%279)\\n  %302 = Constant[value = <Scalar Tensor []>]()\\n  %303 = Gather[axis = 0](%301, %302)\\n  %306 = Unsqueeze[axes = [0]](%300)\\n  %307 = Unsqueeze[axes = [0]](%303)\\n  %310 = Concat[axis = 0](%306, %307, %1650, %1651)\\n  %311 = Reshape(%279, %310)\\n  %312 = Shape(%282)\\n  %313 = Constant[value = <Scalar Tensor []>]()\\n  %314 = Gather[axis = 0](%312, %313)\\n  %315 = Shape(%282)\\n  %316 = Constant[value = <Scalar Tensor []>]()\\n  %317 = Gather[axis = 0](%315, %316)\\n  %320 = Unsqueeze[axes = [0]](%314)\\n  %321 = Unsqueeze[axes = [0]](%317)\\n  %324 = Concat[axis = 0](%320, %321, %1652, %1653)\\n  %325 = Reshape(%282, %324)\\n  %326 = Transpose[perm = [0, 2, 1, 3]](%325)\\n  %327 = Transpose[perm = [0, 2, 3, 1]](%311)\\n  %328 = MatMul(%297, %327)\\n  %329 = Constant[value = <Scalar Tensor []>]()\\n  %330 = Div(%328, %329)\\n  %331 = Add(%330, %215)\\n  %332 = Softmax[axis = 3](%331)\\n  %333 = MatMul(%332, %326)\\n  %334 = Transpose[perm = [0, 2, 1, 3]](%333)\\n  %335 = Shape(%334)\\n  %336 = Constant[value = <Scalar Tensor []>]()\\n  %337 = Gather[axis = 0](%335, %336)\\n  %338 = Shape(%334)\\n  %339 = Constant[value = <Scalar Tensor []>]()\\n  %340 = Gather[axis = 0](%338, %339)\\n  %342 = Unsqueeze[axes = [0]](%337)\\n  %343 = Unsqueeze[axes = [0]](%340)\\n  %345 = Concat[axis = 0](%342, %343, %1654)\\n  %346 = Reshape(%334, %345)\\n  %348 = MatMul(%346, %1655)\\n  %349 = Add(%348, %bert.encoder.layer.0.attention.output.dense.bias)\\n  %350 = Add(%349, %273)\\n  %351 = ReduceMean[axes = [-1]](%350)\\n  %352 = Sub(%350, %351)\\n  %353 = Constant[value = <Scalar Tensor []>]()\\n  %354 = Pow(%352, %353)\\n  %355 = ReduceMean[axes = [-1]](%354)\\n  %356 = Constant[value = <Scalar Tensor []>]()\\n  %357 = Add(%355, %356)\\n  %358 = Sqrt(%357)\\n  %359 = Div(%352, %358)\\n  %360 = Mul(%359, %bert.encoder.layer.0.attention.output.LayerNorm.weight)\\n  %361 = Add(%360, %bert.encoder.layer.0.attention.output.LayerNorm.bias)\\n  %363 = MatMul(%361, %1656)\\n  %364 = Add(%363, %bert.encoder.layer.0.intermediate.dense.bias)\\n  %365 = Constant[value = <Scalar Tensor []>]()\\n  %366 = Div(%364, %365)\\n  %367 = Erf(%366)\\n  %368 = Constant[value = <Scalar Tensor []>]()\\n  %369 = Add(%367, %368)\\n  %370 = Mul(%364, %369)\\n  %371 = Constant[value = <Scalar Tensor []>]()\\n  %372 = Mul(%370, %371)\\n  %374 = MatMul(%372, %1657)\\n  %375 = Add(%374, %bert.encoder.layer.0.output.dense.bias)\\n  %376 = Add(%375, %361)\\n  %377 = ReduceMean[axes = [-1]](%376)\\n  %378 = Sub(%376, %377)\\n  %379 = Constant[value = <Scalar Tensor []>]()\\n  %380 = Pow(%378, %379)\\n  %381 = ReduceMean[axes = [-1]](%380)\\n  %382 = Constant[value = <Scalar Tensor []>]()\\n  %383 = Add(%381, %382)\\n  %384 = Sqrt(%383)\\n  %385 = Div(%378, %384)\\n  %386 = Mul(%385, %bert.encoder.layer.0.output.LayerNorm.weight)\\n  %387 = Add(%386, %bert.encoder.layer.0.output.LayerNorm.bias)\\n  %389 = MatMul(%387, %1658)\\n  %390 = Add(%389, %bert.encoder.layer.1.attention.self.query.bias)\\n  %392 = MatMul(%387, %1659)\\n  %393 = Add(%392, %bert.encoder.layer.1.attention.self.key.bias)\\n  %395 = MatMul(%387, %1660)\\n  %396 = Add(%395, %bert.encoder.layer.1.attention.self.value.bias)\\n  %397 = Shape(%390)\\n  %398 = Constant[value = <Scalar Tensor []>]()\\n  %399 = Gather[axis = 0](%397, %398)\\n  %400 = Shape(%390)\\n  %401 = Constant[value = <Scalar Tensor []>]()\\n  %402 = Gather[axis = 0](%400, %401)\\n  %405 = Unsqueeze[axes = [0]](%399)\\n  %406 = Unsqueeze[axes = [0]](%402)\\n  %409 = Concat[axis = 0](%405, %406, %1661, %1662)\\n  %410 = Reshape(%390, %409)\\n  %411 = Transpose[perm = [0, 2, 1, 3]](%410)\\n  %412 = Shape(%393)\\n  %413 = Constant[value = <Scalar Tensor []>]()\\n  %414 = Gather[axis = 0](%412, %413)\\n  %415 = Shape(%393)\\n  %416 = Constant[value = <Scalar Tensor []>]()\\n  %417 = Gather[axis = 0](%415, %416)\\n  %420 = Unsqueeze[axes = [0]](%414)\\n  %421 = Unsqueeze[axes = [0]](%417)\\n  %424 = Concat[axis = 0](%420, %421, %1663, %1664)\\n  %425 = Reshape(%393, %424)\\n  %426 = Shape(%396)\\n  %427 = Constant[value = <Scalar Tensor []>]()\\n  %428 = Gather[axis = 0](%426, %427)\\n  %429 = Shape(%396)\\n  %430 = Constant[value = <Scalar Tensor []>]()\\n  %431 = Gather[axis = 0](%429, %430)\\n  %434 = Unsqueeze[axes = [0]](%428)\\n  %435 = Unsqueeze[axes = [0]](%431)\\n  %438 = Concat[axis = 0](%434, %435, %1665, %1666)\\n  %439 = Reshape(%396, %438)\\n  %440 = Transpose[perm = [0, 2, 1, 3]](%439)\\n  %441 = Transpose[perm = [0, 2, 3, 1]](%425)\\n  %442 = MatMul(%411, %441)\\n  %443 = Constant[value = <Scalar Tensor []>]()\\n  %444 = Div(%442, %443)\\n  %445 = Add(%444, %215)\\n  %446 = Softmax[axis = 3](%445)\\n  %447 = MatMul(%446, %440)\\n  %448 = Transpose[perm = [0, 2, 1, 3]](%447)\\n  %449 = Shape(%448)\\n  %450 = Constant[value = <Scalar Tensor []>]()\\n  %451 = Gather[axis = 0](%449, %450)\\n  %452 = Shape(%448)\\n  %453 = Constant[value = <Scalar Tensor []>]()\\n  %454 = Gather[axis = 0](%452, %453)\\n  %456 = Unsqueeze[axes = [0]](%451)\\n  %457 = Unsqueeze[axes = [0]](%454)\\n  %459 = Concat[axis = 0](%456, %457, %1667)\\n  %460 = Reshape(%448, %459)\\n  %462 = MatMul(%460, %1668)\\n  %463 = Add(%462, %bert.encoder.layer.1.attention.output.dense.bias)\\n  %464 = Add(%463, %387)\\n  %465 = ReduceMean[axes = [-1]](%464)\\n  %466 = Sub(%464, %465)\\n  %467 = Constant[value = <Scalar Tensor []>]()\\n  %468 = Pow(%466, %467)\\n  %469 = ReduceMean[axes = [-1]](%468)\\n  %470 = Constant[value = <Scalar Tensor []>]()\\n  %471 = Add(%469, %470)\\n  %472 = Sqrt(%471)\\n  %473 = Div(%466, %472)\\n  %474 = Mul(%473, %bert.encoder.layer.1.attention.output.LayerNorm.weight)\\n  %475 = Add(%474, %bert.encoder.layer.1.attention.output.LayerNorm.bias)\\n  %477 = MatMul(%475, %1669)\\n  %478 = Add(%477, %bert.encoder.layer.1.intermediate.dense.bias)\\n  %479 = Constant[value = <Scalar Tensor []>]()\\n  %480 = Div(%478, %479)\\n  %481 = Erf(%480)\\n  %482 = Constant[value = <Scalar Tensor []>]()\\n  %483 = Add(%481, %482)\\n  %484 = Mul(%478, %483)\\n  %485 = Constant[value = <Scalar Tensor []>]()\\n  %486 = Mul(%484, %485)\\n  %488 = MatMul(%486, %1670)\\n  %489 = Add(%488, %bert.encoder.layer.1.output.dense.bias)\\n  %490 = Add(%489, %475)\\n  %491 = ReduceMean[axes = [-1]](%490)\\n  %492 = Sub(%490, %491)\\n  %493 = Constant[value = <Scalar Tensor []>]()\\n  %494 = Pow(%492, %493)\\n  %495 = ReduceMean[axes = [-1]](%494)\\n  %496 = Constant[value = <Scalar Tensor []>]()\\n  %497 = Add(%495, %496)\\n  %498 = Sqrt(%497)\\n  %499 = Div(%492, %498)\\n  %500 = Mul(%499, %bert.encoder.layer.1.output.LayerNorm.weight)\\n  %501 = Add(%500, %bert.encoder.layer.1.output.LayerNorm.bias)\\n  %503 = MatMul(%501, %1671)\\n  %504 = Add(%503, %bert.encoder.layer.2.attention.self.query.bias)\\n  %506 = MatMul(%501, %1672)\\n  %507 = Add(%506, %bert.encoder.layer.2.attention.self.key.bias)\\n  %509 = MatMul(%501, %1673)\\n  %510 = Add(%509, %bert.encoder.layer.2.attention.self.value.bias)\\n  %511 = Shape(%504)\\n  %512 = Constant[value = <Scalar Tensor []>]()\\n  %513 = Gather[axis = 0](%511, %512)\\n  %514 = Shape(%504)\\n  %515 = Constant[value = <Scalar Tensor []>]()\\n  %516 = Gather[axis = 0](%514, %515)\\n  %519 = Unsqueeze[axes = [0]](%513)\\n  %520 = Unsqueeze[axes = [0]](%516)\\n  %523 = Concat[axis = 0](%519, %520, %1674, %1675)\\n  %524 = Reshape(%504, %523)\\n  %525 = Transpose[perm = [0, 2, 1, 3]](%524)\\n  %526 = Shape(%507)\\n  %527 = Constant[value = <Scalar Tensor []>]()\\n  %528 = Gather[axis = 0](%526, %527)\\n  %529 = Shape(%507)\\n  %530 = Constant[value = <Scalar Tensor []>]()\\n  %531 = Gather[axis = 0](%529, %530)\\n  %534 = Unsqueeze[axes = [0]](%528)\\n  %535 = Unsqueeze[axes = [0]](%531)\\n  %538 = Concat[axis = 0](%534, %535, %1676, %1677)\\n  %539 = Reshape(%507, %538)\\n  %540 = Shape(%510)\\n  %541 = Constant[value = <Scalar Tensor []>]()\\n  %542 = Gather[axis = 0](%540, %541)\\n  %543 = Shape(%510)\\n  %544 = Constant[value = <Scalar Tensor []>]()\\n  %545 = Gather[axis = 0](%543, %544)\\n  %548 = Unsqueeze[axes = [0]](%542)\\n  %549 = Unsqueeze[axes = [0]](%545)\\n  %552 = Concat[axis = 0](%548, %549, %1678, %1679)\\n  %553 = Reshape(%510, %552)\\n  %554 = Transpose[perm = [0, 2, 1, 3]](%553)\\n  %555 = Transpose[perm = [0, 2, 3, 1]](%539)\\n  %556 = MatMul(%525, %555)\\n  %557 = Constant[value = <Scalar Tensor []>]()\\n  %558 = Div(%556, %557)\\n  %559 = Add(%558, %215)\\n  %560 = Softmax[axis = 3](%559)\\n  %561 = MatMul(%560, %554)\\n  %562 = Transpose[perm = [0, 2, 1, 3]](%561)\\n  %563 = Shape(%562)\\n  %564 = Constant[value = <Scalar Tensor []>]()\\n  %565 = Gather[axis = 0](%563, %564)\\n  %566 = Shape(%562)\\n  %567 = Constant[value = <Scalar Tensor []>]()\\n  %568 = Gather[axis = 0](%566, %567)\\n  %570 = Unsqueeze[axes = [0]](%565)\\n  %571 = Unsqueeze[axes = [0]](%568)\\n  %573 = Concat[axis = 0](%570, %571, %1680)\\n  %574 = Reshape(%562, %573)\\n  %576 = MatMul(%574, %1681)\\n  %577 = Add(%576, %bert.encoder.layer.2.attention.output.dense.bias)\\n  %578 = Add(%577, %501)\\n  %579 = ReduceMean[axes = [-1]](%578)\\n  %580 = Sub(%578, %579)\\n  %581 = Constant[value = <Scalar Tensor []>]()\\n  %582 = Pow(%580, %581)\\n  %583 = ReduceMean[axes = [-1]](%582)\\n  %584 = Constant[value = <Scalar Tensor []>]()\\n  %585 = Add(%583, %584)\\n  %586 = Sqrt(%585)\\n  %587 = Div(%580, %586)\\n  %588 = Mul(%587, %bert.encoder.layer.2.attention.output.LayerNorm.weight)\\n  %589 = Add(%588, %bert.encoder.layer.2.attention.output.LayerNorm.bias)\\n  %591 = MatMul(%589, %1682)\\n  %592 = Add(%591, %bert.encoder.layer.2.intermediate.dense.bias)\\n  %593 = Constant[value = <Scalar Tensor []>]()\\n  %594 = Div(%592, %593)\\n  %595 = Erf(%594)\\n  %596 = Constant[value = <Scalar Tensor []>]()\\n  %597 = Add(%595, %596)\\n  %598 = Mul(%592, %597)\\n  %599 = Constant[value = <Scalar Tensor []>]()\\n  %600 = Mul(%598, %599)\\n  %602 = MatMul(%600, %1683)\\n  %603 = Add(%602, %bert.encoder.layer.2.output.dense.bias)\\n  %604 = Add(%603, %589)\\n  %605 = ReduceMean[axes = [-1]](%604)\\n  %606 = Sub(%604, %605)\\n  %607 = Constant[value = <Scalar Tensor []>]()\\n  %608 = Pow(%606, %607)\\n  %609 = ReduceMean[axes = [-1]](%608)\\n  %610 = Constant[value = <Scalar Tensor []>]()\\n  %611 = Add(%609, %610)\\n  %612 = Sqrt(%611)\\n  %613 = Div(%606, %612)\\n  %614 = Mul(%613, %bert.encoder.layer.2.output.LayerNorm.weight)\\n  %615 = Add(%614, %bert.encoder.layer.2.output.LayerNorm.bias)\\n  %617 = MatMul(%615, %1684)\\n  %618 = Add(%617, %bert.encoder.layer.3.attention.self.query.bias)\\n  %620 = MatMul(%615, %1685)\\n  %621 = Add(%620, %bert.encoder.layer.3.attention.self.key.bias)\\n  %623 = MatMul(%615, %1686)\\n  %624 = Add(%623, %bert.encoder.layer.3.attention.self.value.bias)\\n  %625 = Shape(%618)\\n  %626 = Constant[value = <Scalar Tensor []>]()\\n  %627 = Gather[axis = 0](%625, %626)\\n  %628 = Shape(%618)\\n  %629 = Constant[value = <Scalar Tensor []>]()\\n  %630 = Gather[axis = 0](%628, %629)\\n  %633 = Unsqueeze[axes = [0]](%627)\\n  %634 = Unsqueeze[axes = [0]](%630)\\n  %637 = Concat[axis = 0](%633, %634, %1687, %1688)\\n  %638 = Reshape(%618, %637)\\n  %639 = Transpose[perm = [0, 2, 1, 3]](%638)\\n  %640 = Shape(%621)\\n  %641 = Constant[value = <Scalar Tensor []>]()\\n  %642 = Gather[axis = 0](%640, %641)\\n  %643 = Shape(%621)\\n  %644 = Constant[value = <Scalar Tensor []>]()\\n  %645 = Gather[axis = 0](%643, %644)\\n  %648 = Unsqueeze[axes = [0]](%642)\\n  %649 = Unsqueeze[axes = [0]](%645)\\n  %652 = Concat[axis = 0](%648, %649, %1689, %1690)\\n  %653 = Reshape(%621, %652)\\n  %654 = Shape(%624)\\n  %655 = Constant[value = <Scalar Tensor []>]()\\n  %656 = Gather[axis = 0](%654, %655)\\n  %657 = Shape(%624)\\n  %658 = Constant[value = <Scalar Tensor []>]()\\n  %659 = Gather[axis = 0](%657, %658)\\n  %662 = Unsqueeze[axes = [0]](%656)\\n  %663 = Unsqueeze[axes = [0]](%659)\\n  %666 = Concat[axis = 0](%662, %663, %1691, %1692)\\n  %667 = Reshape(%624, %666)\\n  %668 = Transpose[perm = [0, 2, 1, 3]](%667)\\n  %669 = Transpose[perm = [0, 2, 3, 1]](%653)\\n  %670 = MatMul(%639, %669)\\n  %671 = Constant[value = <Scalar Tensor []>]()\\n  %672 = Div(%670, %671)\\n  %673 = Add(%672, %215)\\n  %674 = Softmax[axis = 3](%673)\\n  %675 = MatMul(%674, %668)\\n  %676 = Transpose[perm = [0, 2, 1, 3]](%675)\\n  %677 = Shape(%676)\\n  %678 = Constant[value = <Scalar Tensor []>]()\\n  %679 = Gather[axis = 0](%677, %678)\\n  %680 = Shape(%676)\\n  %681 = Constant[value = <Scalar Tensor []>]()\\n  %682 = Gather[axis = 0](%680, %681)\\n  %684 = Unsqueeze[axes = [0]](%679)\\n  %685 = Unsqueeze[axes = [0]](%682)\\n  %687 = Concat[axis = 0](%684, %685, %1693)\\n  %688 = Reshape(%676, %687)\\n  %690 = MatMul(%688, %1694)\\n  %691 = Add(%690, %bert.encoder.layer.3.attention.output.dense.bias)\\n  %692 = Add(%691, %615)\\n  %693 = ReduceMean[axes = [-1]](%692)\\n  %694 = Sub(%692, %693)\\n  %695 = Constant[value = <Scalar Tensor []>]()\\n  %696 = Pow(%694, %695)\\n  %697 = ReduceMean[axes = [-1]](%696)\\n  %698 = Constant[value = <Scalar Tensor []>]()\\n  %699 = Add(%697, %698)\\n  %700 = Sqrt(%699)\\n  %701 = Div(%694, %700)\\n  %702 = Mul(%701, %bert.encoder.layer.3.attention.output.LayerNorm.weight)\\n  %703 = Add(%702, %bert.encoder.layer.3.attention.output.LayerNorm.bias)\\n  %705 = MatMul(%703, %1695)\\n  %706 = Add(%705, %bert.encoder.layer.3.intermediate.dense.bias)\\n  %707 = Constant[value = <Scalar Tensor []>]()\\n  %708 = Div(%706, %707)\\n  %709 = Erf(%708)\\n  %710 = Constant[value = <Scalar Tensor []>]()\\n  %711 = Add(%709, %710)\\n  %712 = Mul(%706, %711)\\n  %713 = Constant[value = <Scalar Tensor []>]()\\n  %714 = Mul(%712, %713)\\n  %716 = MatMul(%714, %1696)\\n  %717 = Add(%716, %bert.encoder.layer.3.output.dense.bias)\\n  %718 = Add(%717, %703)\\n  %719 = ReduceMean[axes = [-1]](%718)\\n  %720 = Sub(%718, %719)\\n  %721 = Constant[value = <Scalar Tensor []>]()\\n  %722 = Pow(%720, %721)\\n  %723 = ReduceMean[axes = [-1]](%722)\\n  %724 = Constant[value = <Scalar Tensor []>]()\\n  %725 = Add(%723, %724)\\n  %726 = Sqrt(%725)\\n  %727 = Div(%720, %726)\\n  %728 = Mul(%727, %bert.encoder.layer.3.output.LayerNorm.weight)\\n  %729 = Add(%728, %bert.encoder.layer.3.output.LayerNorm.bias)\\n  %731 = MatMul(%729, %1697)\\n  %732 = Add(%731, %bert.encoder.layer.4.attention.self.query.bias)\\n  %734 = MatMul(%729, %1698)\\n  %735 = Add(%734, %bert.encoder.layer.4.attention.self.key.bias)\\n  %737 = MatMul(%729, %1699)\\n  %738 = Add(%737, %bert.encoder.layer.4.attention.self.value.bias)\\n  %739 = Shape(%732)\\n  %740 = Constant[value = <Scalar Tensor []>]()\\n  %741 = Gather[axis = 0](%739, %740)\\n  %742 = Shape(%732)\\n  %743 = Constant[value = <Scalar Tensor []>]()\\n  %744 = Gather[axis = 0](%742, %743)\\n  %747 = Unsqueeze[axes = [0]](%741)\\n  %748 = Unsqueeze[axes = [0]](%744)\\n  %751 = Concat[axis = 0](%747, %748, %1700, %1701)\\n  %752 = Reshape(%732, %751)\\n  %753 = Transpose[perm = [0, 2, 1, 3]](%752)\\n  %754 = Shape(%735)\\n  %755 = Constant[value = <Scalar Tensor []>]()\\n  %756 = Gather[axis = 0](%754, %755)\\n  %757 = Shape(%735)\\n  %758 = Constant[value = <Scalar Tensor []>]()\\n  %759 = Gather[axis = 0](%757, %758)\\n  %762 = Unsqueeze[axes = [0]](%756)\\n  %763 = Unsqueeze[axes = [0]](%759)\\n  %766 = Concat[axis = 0](%762, %763, %1702, %1703)\\n  %767 = Reshape(%735, %766)\\n  %768 = Shape(%738)\\n  %769 = Constant[value = <Scalar Tensor []>]()\\n  %770 = Gather[axis = 0](%768, %769)\\n  %771 = Shape(%738)\\n  %772 = Constant[value = <Scalar Tensor []>]()\\n  %773 = Gather[axis = 0](%771, %772)\\n  %776 = Unsqueeze[axes = [0]](%770)\\n  %777 = Unsqueeze[axes = [0]](%773)\\n  %780 = Concat[axis = 0](%776, %777, %1704, %1705)\\n  %781 = Reshape(%738, %780)\\n  %782 = Transpose[perm = [0, 2, 1, 3]](%781)\\n  %783 = Transpose[perm = [0, 2, 3, 1]](%767)\\n  %784 = MatMul(%753, %783)\\n  %785 = Constant[value = <Scalar Tensor []>]()\\n  %786 = Div(%784, %785)\\n  %787 = Add(%786, %215)\\n  %788 = Softmax[axis = 3](%787)\\n  %789 = MatMul(%788, %782)\\n  %790 = Transpose[perm = [0, 2, 1, 3]](%789)\\n  %791 = Shape(%790)\\n  %792 = Constant[value = <Scalar Tensor []>]()\\n  %793 = Gather[axis = 0](%791, %792)\\n  %794 = Shape(%790)\\n  %795 = Constant[value = <Scalar Tensor []>]()\\n  %796 = Gather[axis = 0](%794, %795)\\n  %798 = Unsqueeze[axes = [0]](%793)\\n  %799 = Unsqueeze[axes = [0]](%796)\\n  %801 = Concat[axis = 0](%798, %799, %1706)\\n  %802 = Reshape(%790, %801)\\n  %804 = MatMul(%802, %1707)\\n  %805 = Add(%804, %bert.encoder.layer.4.attention.output.dense.bias)\\n  %806 = Add(%805, %729)\\n  %807 = ReduceMean[axes = [-1]](%806)\\n  %808 = Sub(%806, %807)\\n  %809 = Constant[value = <Scalar Tensor []>]()\\n  %810 = Pow(%808, %809)\\n  %811 = ReduceMean[axes = [-1]](%810)\\n  %812 = Constant[value = <Scalar Tensor []>]()\\n  %813 = Add(%811, %812)\\n  %814 = Sqrt(%813)\\n  %815 = Div(%808, %814)\\n  %816 = Mul(%815, %bert.encoder.layer.4.attention.output.LayerNorm.weight)\\n  %817 = Add(%816, %bert.encoder.layer.4.attention.output.LayerNorm.bias)\\n  %819 = MatMul(%817, %1708)\\n  %820 = Add(%819, %bert.encoder.layer.4.intermediate.dense.bias)\\n  %821 = Constant[value = <Scalar Tensor []>]()\\n  %822 = Div(%820, %821)\\n  %823 = Erf(%822)\\n  %824 = Constant[value = <Scalar Tensor []>]()\\n  %825 = Add(%823, %824)\\n  %826 = Mul(%820, %825)\\n  %827 = Constant[value = <Scalar Tensor []>]()\\n  %828 = Mul(%826, %827)\\n  %830 = MatMul(%828, %1709)\\n  %831 = Add(%830, %bert.encoder.layer.4.output.dense.bias)\\n  %832 = Add(%831, %817)\\n  %833 = ReduceMean[axes = [-1]](%832)\\n  %834 = Sub(%832, %833)\\n  %835 = Constant[value = <Scalar Tensor []>]()\\n  %836 = Pow(%834, %835)\\n  %837 = ReduceMean[axes = [-1]](%836)\\n  %838 = Constant[value = <Scalar Tensor []>]()\\n  %839 = Add(%837, %838)\\n  %840 = Sqrt(%839)\\n  %841 = Div(%834, %840)\\n  %842 = Mul(%841, %bert.encoder.layer.4.output.LayerNorm.weight)\\n  %843 = Add(%842, %bert.encoder.layer.4.output.LayerNorm.bias)\\n  %845 = MatMul(%843, %1710)\\n  %846 = Add(%845, %bert.encoder.layer.5.attention.self.query.bias)\\n  %848 = MatMul(%843, %1711)\\n  %849 = Add(%848, %bert.encoder.layer.5.attention.self.key.bias)\\n  %851 = MatMul(%843, %1712)\\n  %852 = Add(%851, %bert.encoder.layer.5.attention.self.value.bias)\\n  %853 = Shape(%846)\\n  %854 = Constant[value = <Scalar Tensor []>]()\\n  %855 = Gather[axis = 0](%853, %854)\\n  %856 = Shape(%846)\\n  %857 = Constant[value = <Scalar Tensor []>]()\\n  %858 = Gather[axis = 0](%856, %857)\\n  %861 = Unsqueeze[axes = [0]](%855)\\n  %862 = Unsqueeze[axes = [0]](%858)\\n  %865 = Concat[axis = 0](%861, %862, %1713, %1714)\\n  %866 = Reshape(%846, %865)\\n  %867 = Transpose[perm = [0, 2, 1, 3]](%866)\\n  %868 = Shape(%849)\\n  %869 = Constant[value = <Scalar Tensor []>]()\\n  %870 = Gather[axis = 0](%868, %869)\\n  %871 = Shape(%849)\\n  %872 = Constant[value = <Scalar Tensor []>]()\\n  %873 = Gather[axis = 0](%871, %872)\\n  %876 = Unsqueeze[axes = [0]](%870)\\n  %877 = Unsqueeze[axes = [0]](%873)\\n  %880 = Concat[axis = 0](%876, %877, %1715, %1716)\\n  %881 = Reshape(%849, %880)\\n  %882 = Shape(%852)\\n  %883 = Constant[value = <Scalar Tensor []>]()\\n  %884 = Gather[axis = 0](%882, %883)\\n  %885 = Shape(%852)\\n  %886 = Constant[value = <Scalar Tensor []>]()\\n  %887 = Gather[axis = 0](%885, %886)\\n  %890 = Unsqueeze[axes = [0]](%884)\\n  %891 = Unsqueeze[axes = [0]](%887)\\n  %894 = Concat[axis = 0](%890, %891, %1717, %1718)\\n  %895 = Reshape(%852, %894)\\n  %896 = Transpose[perm = [0, 2, 1, 3]](%895)\\n  %897 = Transpose[perm = [0, 2, 3, 1]](%881)\\n  %898 = MatMul(%867, %897)\\n  %899 = Constant[value = <Scalar Tensor []>]()\\n  %900 = Div(%898, %899)\\n  %901 = Add(%900, %215)\\n  %902 = Softmax[axis = 3](%901)\\n  %903 = MatMul(%902, %896)\\n  %904 = Transpose[perm = [0, 2, 1, 3]](%903)\\n  %905 = Shape(%904)\\n  %906 = Constant[value = <Scalar Tensor []>]()\\n  %907 = Gather[axis = 0](%905, %906)\\n  %908 = Shape(%904)\\n  %909 = Constant[value = <Scalar Tensor []>]()\\n  %910 = Gather[axis = 0](%908, %909)\\n  %912 = Unsqueeze[axes = [0]](%907)\\n  %913 = Unsqueeze[axes = [0]](%910)\\n  %915 = Concat[axis = 0](%912, %913, %1719)\\n  %916 = Reshape(%904, %915)\\n  %918 = MatMul(%916, %1720)\\n  %919 = Add(%918, %bert.encoder.layer.5.attention.output.dense.bias)\\n  %920 = Add(%919, %843)\\n  %921 = ReduceMean[axes = [-1]](%920)\\n  %922 = Sub(%920, %921)\\n  %923 = Constant[value = <Scalar Tensor []>]()\\n  %924 = Pow(%922, %923)\\n  %925 = ReduceMean[axes = [-1]](%924)\\n  %926 = Constant[value = <Scalar Tensor []>]()\\n  %927 = Add(%925, %926)\\n  %928 = Sqrt(%927)\\n  %929 = Div(%922, %928)\\n  %930 = Mul(%929, %bert.encoder.layer.5.attention.output.LayerNorm.weight)\\n  %931 = Add(%930, %bert.encoder.layer.5.attention.output.LayerNorm.bias)\\n  %933 = MatMul(%931, %1721)\\n  %934 = Add(%933, %bert.encoder.layer.5.intermediate.dense.bias)\\n  %935 = Constant[value = <Scalar Tensor []>]()\\n  %936 = Div(%934, %935)\\n  %937 = Erf(%936)\\n  %938 = Constant[value = <Scalar Tensor []>]()\\n  %939 = Add(%937, %938)\\n  %940 = Mul(%934, %939)\\n  %941 = Constant[value = <Scalar Tensor []>]()\\n  %942 = Mul(%940, %941)\\n  %944 = MatMul(%942, %1722)\\n  %945 = Add(%944, %bert.encoder.layer.5.output.dense.bias)\\n  %946 = Add(%945, %931)\\n  %947 = ReduceMean[axes = [-1]](%946)\\n  %948 = Sub(%946, %947)\\n  %949 = Constant[value = <Scalar Tensor []>]()\\n  %950 = Pow(%948, %949)\\n  %951 = ReduceMean[axes = [-1]](%950)\\n  %952 = Constant[value = <Scalar Tensor []>]()\\n  %953 = Add(%951, %952)\\n  %954 = Sqrt(%953)\\n  %955 = Div(%948, %954)\\n  %956 = Mul(%955, %bert.encoder.layer.5.output.LayerNorm.weight)\\n  %957 = Add(%956, %bert.encoder.layer.5.output.LayerNorm.bias)\\n  %959 = MatMul(%957, %1723)\\n  %960 = Add(%959, %bert.encoder.layer.6.attention.self.query.bias)\\n  %962 = MatMul(%957, %1724)\\n  %963 = Add(%962, %bert.encoder.layer.6.attention.self.key.bias)\\n  %965 = MatMul(%957, %1725)\\n  %966 = Add(%965, %bert.encoder.layer.6.attention.self.value.bias)\\n  %967 = Shape(%960)\\n  %968 = Constant[value = <Scalar Tensor []>]()\\n  %969 = Gather[axis = 0](%967, %968)\\n  %970 = Shape(%960)\\n  %971 = Constant[value = <Scalar Tensor []>]()\\n  %972 = Gather[axis = 0](%970, %971)\\n  %975 = Unsqueeze[axes = [0]](%969)\\n  %976 = Unsqueeze[axes = [0]](%972)\\n  %979 = Concat[axis = 0](%975, %976, %1726, %1727)\\n  %980 = Reshape(%960, %979)\\n  %981 = Transpose[perm = [0, 2, 1, 3]](%980)\\n  %982 = Shape(%963)\\n  %983 = Constant[value = <Scalar Tensor []>]()\\n  %984 = Gather[axis = 0](%982, %983)\\n  %985 = Shape(%963)\\n  %986 = Constant[value = <Scalar Tensor []>]()\\n  %987 = Gather[axis = 0](%985, %986)\\n  %990 = Unsqueeze[axes = [0]](%984)\\n  %991 = Unsqueeze[axes = [0]](%987)\\n  %994 = Concat[axis = 0](%990, %991, %1728, %1729)\\n  %995 = Reshape(%963, %994)\\n  %996 = Shape(%966)\\n  %997 = Constant[value = <Scalar Tensor []>]()\\n  %998 = Gather[axis = 0](%996, %997)\\n  %999 = Shape(%966)\\n  %1000 = Constant[value = <Scalar Tensor []>]()\\n  %1001 = Gather[axis = 0](%999, %1000)\\n  %1004 = Unsqueeze[axes = [0]](%998)\\n  %1005 = Unsqueeze[axes = [0]](%1001)\\n  %1008 = Concat[axis = 0](%1004, %1005, %1730, %1731)\\n  %1009 = Reshape(%966, %1008)\\n  %1010 = Transpose[perm = [0, 2, 1, 3]](%1009)\\n  %1011 = Transpose[perm = [0, 2, 3, 1]](%995)\\n  %1012 = MatMul(%981, %1011)\\n  %1013 = Constant[value = <Scalar Tensor []>]()\\n  %1014 = Div(%1012, %1013)\\n  %1015 = Add(%1014, %215)\\n  %1016 = Softmax[axis = 3](%1015)\\n  %1017 = MatMul(%1016, %1010)\\n  %1018 = Transpose[perm = [0, 2, 1, 3]](%1017)\\n  %1019 = Shape(%1018)\\n  %1020 = Constant[value = <Scalar Tensor []>]()\\n  %1021 = Gather[axis = 0](%1019, %1020)\\n  %1022 = Shape(%1018)\\n  %1023 = Constant[value = <Scalar Tensor []>]()\\n  %1024 = Gather[axis = 0](%1022, %1023)\\n  %1026 = Unsqueeze[axes = [0]](%1021)\\n  %1027 = Unsqueeze[axes = [0]](%1024)\\n  %1029 = Concat[axis = 0](%1026, %1027, %1732)\\n  %1030 = Reshape(%1018, %1029)\\n  %1032 = MatMul(%1030, %1733)\\n  %1033 = Add(%1032, %bert.encoder.layer.6.attention.output.dense.bias)\\n  %1034 = Add(%1033, %957)\\n  %1035 = ReduceMean[axes = [-1]](%1034)\\n  %1036 = Sub(%1034, %1035)\\n  %1037 = Constant[value = <Scalar Tensor []>]()\\n  %1038 = Pow(%1036, %1037)\\n  %1039 = ReduceMean[axes = [-1]](%1038)\\n  %1040 = Constant[value = <Scalar Tensor []>]()\\n  %1041 = Add(%1039, %1040)\\n  %1042 = Sqrt(%1041)\\n  %1043 = Div(%1036, %1042)\\n  %1044 = Mul(%1043, %bert.encoder.layer.6.attention.output.LayerNorm.weight)\\n  %1045 = Add(%1044, %bert.encoder.layer.6.attention.output.LayerNorm.bias)\\n  %1047 = MatMul(%1045, %1734)\\n  %1048 = Add(%1047, %bert.encoder.layer.6.intermediate.dense.bias)\\n  %1049 = Constant[value = <Scalar Tensor []>]()\\n  %1050 = Div(%1048, %1049)\\n  %1051 = Erf(%1050)\\n  %1052 = Constant[value = <Scalar Tensor []>]()\\n  %1053 = Add(%1051, %1052)\\n  %1054 = Mul(%1048, %1053)\\n  %1055 = Constant[value = <Scalar Tensor []>]()\\n  %1056 = Mul(%1054, %1055)\\n  %1058 = MatMul(%1056, %1735)\\n  %1059 = Add(%1058, %bert.encoder.layer.6.output.dense.bias)\\n  %1060 = Add(%1059, %1045)\\n  %1061 = ReduceMean[axes = [-1]](%1060)\\n  %1062 = Sub(%1060, %1061)\\n  %1063 = Constant[value = <Scalar Tensor []>]()\\n  %1064 = Pow(%1062, %1063)\\n  %1065 = ReduceMean[axes = [-1]](%1064)\\n  %1066 = Constant[value = <Scalar Tensor []>]()\\n  %1067 = Add(%1065, %1066)\\n  %1068 = Sqrt(%1067)\\n  %1069 = Div(%1062, %1068)\\n  %1070 = Mul(%1069, %bert.encoder.layer.6.output.LayerNorm.weight)\\n  %1071 = Add(%1070, %bert.encoder.layer.6.output.LayerNorm.bias)\\n  %1073 = MatMul(%1071, %1736)\\n  %1074 = Add(%1073, %bert.encoder.layer.7.attention.self.query.bias)\\n  %1076 = MatMul(%1071, %1737)\\n  %1077 = Add(%1076, %bert.encoder.layer.7.attention.self.key.bias)\\n  %1079 = MatMul(%1071, %1738)\\n  %1080 = Add(%1079, %bert.encoder.layer.7.attention.self.value.bias)\\n  %1081 = Shape(%1074)\\n  %1082 = Constant[value = <Scalar Tensor []>]()\\n  %1083 = Gather[axis = 0](%1081, %1082)\\n  %1084 = Shape(%1074)\\n  %1085 = Constant[value = <Scalar Tensor []>]()\\n  %1086 = Gather[axis = 0](%1084, %1085)\\n  %1089 = Unsqueeze[axes = [0]](%1083)\\n  %1090 = Unsqueeze[axes = [0]](%1086)\\n  %1093 = Concat[axis = 0](%1089, %1090, %1739, %1740)\\n  %1094 = Reshape(%1074, %1093)\\n  %1095 = Transpose[perm = [0, 2, 1, 3]](%1094)\\n  %1096 = Shape(%1077)\\n  %1097 = Constant[value = <Scalar Tensor []>]()\\n  %1098 = Gather[axis = 0](%1096, %1097)\\n  %1099 = Shape(%1077)\\n  %1100 = Constant[value = <Scalar Tensor []>]()\\n  %1101 = Gather[axis = 0](%1099, %1100)\\n  %1104 = Unsqueeze[axes = [0]](%1098)\\n  %1105 = Unsqueeze[axes = [0]](%1101)\\n  %1108 = Concat[axis = 0](%1104, %1105, %1741, %1742)\\n  %1109 = Reshape(%1077, %1108)\\n  %1110 = Shape(%1080)\\n  %1111 = Constant[value = <Scalar Tensor []>]()\\n  %1112 = Gather[axis = 0](%1110, %1111)\\n  %1113 = Shape(%1080)\\n  %1114 = Constant[value = <Scalar Tensor []>]()\\n  %1115 = Gather[axis = 0](%1113, %1114)\\n  %1118 = Unsqueeze[axes = [0]](%1112)\\n  %1119 = Unsqueeze[axes = [0]](%1115)\\n  %1122 = Concat[axis = 0](%1118, %1119, %1743, %1744)\\n  %1123 = Reshape(%1080, %1122)\\n  %1124 = Transpose[perm = [0, 2, 1, 3]](%1123)\\n  %1125 = Transpose[perm = [0, 2, 3, 1]](%1109)\\n  %1126 = MatMul(%1095, %1125)\\n  %1127 = Constant[value = <Scalar Tensor []>]()\\n  %1128 = Div(%1126, %1127)\\n  %1129 = Add(%1128, %215)\\n  %1130 = Softmax[axis = 3](%1129)\\n  %1131 = MatMul(%1130, %1124)\\n  %1132 = Transpose[perm = [0, 2, 1, 3]](%1131)\\n  %1133 = Shape(%1132)\\n  %1134 = Constant[value = <Scalar Tensor []>]()\\n  %1135 = Gather[axis = 0](%1133, %1134)\\n  %1136 = Shape(%1132)\\n  %1137 = Constant[value = <Scalar Tensor []>]()\\n  %1138 = Gather[axis = 0](%1136, %1137)\\n  %1140 = Unsqueeze[axes = [0]](%1135)\\n  %1141 = Unsqueeze[axes = [0]](%1138)\\n  %1143 = Concat[axis = 0](%1140, %1141, %1745)\\n  %1144 = Reshape(%1132, %1143)\\n  %1146 = MatMul(%1144, %1746)\\n  %1147 = Add(%1146, %bert.encoder.layer.7.attention.output.dense.bias)\\n  %1148 = Add(%1147, %1071)\\n  %1149 = ReduceMean[axes = [-1]](%1148)\\n  %1150 = Sub(%1148, %1149)\\n  %1151 = Constant[value = <Scalar Tensor []>]()\\n  %1152 = Pow(%1150, %1151)\\n  %1153 = ReduceMean[axes = [-1]](%1152)\\n  %1154 = Constant[value = <Scalar Tensor []>]()\\n  %1155 = Add(%1153, %1154)\\n  %1156 = Sqrt(%1155)\\n  %1157 = Div(%1150, %1156)\\n  %1158 = Mul(%1157, %bert.encoder.layer.7.attention.output.LayerNorm.weight)\\n  %1159 = Add(%1158, %bert.encoder.layer.7.attention.output.LayerNorm.bias)\\n  %1161 = MatMul(%1159, %1747)\\n  %1162 = Add(%1161, %bert.encoder.layer.7.intermediate.dense.bias)\\n  %1163 = Constant[value = <Scalar Tensor []>]()\\n  %1164 = Div(%1162, %1163)\\n  %1165 = Erf(%1164)\\n  %1166 = Constant[value = <Scalar Tensor []>]()\\n  %1167 = Add(%1165, %1166)\\n  %1168 = Mul(%1162, %1167)\\n  %1169 = Constant[value = <Scalar Tensor []>]()\\n  %1170 = Mul(%1168, %1169)\\n  %1172 = MatMul(%1170, %1748)\\n  %1173 = Add(%1172, %bert.encoder.layer.7.output.dense.bias)\\n  %1174 = Add(%1173, %1159)\\n  %1175 = ReduceMean[axes = [-1]](%1174)\\n  %1176 = Sub(%1174, %1175)\\n  %1177 = Constant[value = <Scalar Tensor []>]()\\n  %1178 = Pow(%1176, %1177)\\n  %1179 = ReduceMean[axes = [-1]](%1178)\\n  %1180 = Constant[value = <Scalar Tensor []>]()\\n  %1181 = Add(%1179, %1180)\\n  %1182 = Sqrt(%1181)\\n  %1183 = Div(%1176, %1182)\\n  %1184 = Mul(%1183, %bert.encoder.layer.7.output.LayerNorm.weight)\\n  %1185 = Add(%1184, %bert.encoder.layer.7.output.LayerNorm.bias)\\n  %1187 = MatMul(%1185, %1749)\\n  %1188 = Add(%1187, %bert.encoder.layer.8.attention.self.query.bias)\\n  %1190 = MatMul(%1185, %1750)\\n  %1191 = Add(%1190, %bert.encoder.layer.8.attention.self.key.bias)\\n  %1193 = MatMul(%1185, %1751)\\n  %1194 = Add(%1193, %bert.encoder.layer.8.attention.self.value.bias)\\n  %1195 = Shape(%1188)\\n  %1196 = Constant[value = <Scalar Tensor []>]()\\n  %1197 = Gather[axis = 0](%1195, %1196)\\n  %1198 = Shape(%1188)\\n  %1199 = Constant[value = <Scalar Tensor []>]()\\n  %1200 = Gather[axis = 0](%1198, %1199)\\n  %1203 = Unsqueeze[axes = [0]](%1197)\\n  %1204 = Unsqueeze[axes = [0]](%1200)\\n  %1207 = Concat[axis = 0](%1203, %1204, %1752, %1753)\\n  %1208 = Reshape(%1188, %1207)\\n  %1209 = Transpose[perm = [0, 2, 1, 3]](%1208)\\n  %1210 = Shape(%1191)\\n  %1211 = Constant[value = <Scalar Tensor []>]()\\n  %1212 = Gather[axis = 0](%1210, %1211)\\n  %1213 = Shape(%1191)\\n  %1214 = Constant[value = <Scalar Tensor []>]()\\n  %1215 = Gather[axis = 0](%1213, %1214)\\n  %1218 = Unsqueeze[axes = [0]](%1212)\\n  %1219 = Unsqueeze[axes = [0]](%1215)\\n  %1222 = Concat[axis = 0](%1218, %1219, %1754, %1755)\\n  %1223 = Reshape(%1191, %1222)\\n  %1224 = Shape(%1194)\\n  %1225 = Constant[value = <Scalar Tensor []>]()\\n  %1226 = Gather[axis = 0](%1224, %1225)\\n  %1227 = Shape(%1194)\\n  %1228 = Constant[value = <Scalar Tensor []>]()\\n  %1229 = Gather[axis = 0](%1227, %1228)\\n  %1232 = Unsqueeze[axes = [0]](%1226)\\n  %1233 = Unsqueeze[axes = [0]](%1229)\\n  %1236 = Concat[axis = 0](%1232, %1233, %1756, %1757)\\n  %1237 = Reshape(%1194, %1236)\\n  %1238 = Transpose[perm = [0, 2, 1, 3]](%1237)\\n  %1239 = Transpose[perm = [0, 2, 3, 1]](%1223)\\n  %1240 = MatMul(%1209, %1239)\\n  %1241 = Constant[value = <Scalar Tensor []>]()\\n  %1242 = Div(%1240, %1241)\\n  %1243 = Add(%1242, %215)\\n  %1244 = Softmax[axis = 3](%1243)\\n  %1245 = MatMul(%1244, %1238)\\n  %1246 = Transpose[perm = [0, 2, 1, 3]](%1245)\\n  %1247 = Shape(%1246)\\n  %1248 = Constant[value = <Scalar Tensor []>]()\\n  %1249 = Gather[axis = 0](%1247, %1248)\\n  %1250 = Shape(%1246)\\n  %1251 = Constant[value = <Scalar Tensor []>]()\\n  %1252 = Gather[axis = 0](%1250, %1251)\\n  %1254 = Unsqueeze[axes = [0]](%1249)\\n  %1255 = Unsqueeze[axes = [0]](%1252)\\n  %1257 = Concat[axis = 0](%1254, %1255, %1758)\\n  %1258 = Reshape(%1246, %1257)\\n  %1260 = MatMul(%1258, %1759)\\n  %1261 = Add(%1260, %bert.encoder.layer.8.attention.output.dense.bias)\\n  %1262 = Add(%1261, %1185)\\n  %1263 = ReduceMean[axes = [-1]](%1262)\\n  %1264 = Sub(%1262, %1263)\\n  %1265 = Constant[value = <Scalar Tensor []>]()\\n  %1266 = Pow(%1264, %1265)\\n  %1267 = ReduceMean[axes = [-1]](%1266)\\n  %1268 = Constant[value = <Scalar Tensor []>]()\\n  %1269 = Add(%1267, %1268)\\n  %1270 = Sqrt(%1269)\\n  %1271 = Div(%1264, %1270)\\n  %1272 = Mul(%1271, %bert.encoder.layer.8.attention.output.LayerNorm.weight)\\n  %1273 = Add(%1272, %bert.encoder.layer.8.attention.output.LayerNorm.bias)\\n  %1275 = MatMul(%1273, %1760)\\n  %1276 = Add(%1275, %bert.encoder.layer.8.intermediate.dense.bias)\\n  %1277 = Constant[value = <Scalar Tensor []>]()\\n  %1278 = Div(%1276, %1277)\\n  %1279 = Erf(%1278)\\n  %1280 = Constant[value = <Scalar Tensor []>]()\\n  %1281 = Add(%1279, %1280)\\n  %1282 = Mul(%1276, %1281)\\n  %1283 = Constant[value = <Scalar Tensor []>]()\\n  %1284 = Mul(%1282, %1283)\\n  %1286 = MatMul(%1284, %1761)\\n  %1287 = Add(%1286, %bert.encoder.layer.8.output.dense.bias)\\n  %1288 = Add(%1287, %1273)\\n  %1289 = ReduceMean[axes = [-1]](%1288)\\n  %1290 = Sub(%1288, %1289)\\n  %1291 = Constant[value = <Scalar Tensor []>]()\\n  %1292 = Pow(%1290, %1291)\\n  %1293 = ReduceMean[axes = [-1]](%1292)\\n  %1294 = Constant[value = <Scalar Tensor []>]()\\n  %1295 = Add(%1293, %1294)\\n  %1296 = Sqrt(%1295)\\n  %1297 = Div(%1290, %1296)\\n  %1298 = Mul(%1297, %bert.encoder.layer.8.output.LayerNorm.weight)\\n  %1299 = Add(%1298, %bert.encoder.layer.8.output.LayerNorm.bias)\\n  %1301 = MatMul(%1299, %1762)\\n  %1302 = Add(%1301, %bert.encoder.layer.9.attention.self.query.bias)\\n  %1304 = MatMul(%1299, %1763)\\n  %1305 = Add(%1304, %bert.encoder.layer.9.attention.self.key.bias)\\n  %1307 = MatMul(%1299, %1764)\\n  %1308 = Add(%1307, %bert.encoder.layer.9.attention.self.value.bias)\\n  %1309 = Shape(%1302)\\n  %1310 = Constant[value = <Scalar Tensor []>]()\\n  %1311 = Gather[axis = 0](%1309, %1310)\\n  %1312 = Shape(%1302)\\n  %1313 = Constant[value = <Scalar Tensor []>]()\\n  %1314 = Gather[axis = 0](%1312, %1313)\\n  %1317 = Unsqueeze[axes = [0]](%1311)\\n  %1318 = Unsqueeze[axes = [0]](%1314)\\n  %1321 = Concat[axis = 0](%1317, %1318, %1765, %1766)\\n  %1322 = Reshape(%1302, %1321)\\n  %1323 = Transpose[perm = [0, 2, 1, 3]](%1322)\\n  %1324 = Shape(%1305)\\n  %1325 = Constant[value = <Scalar Tensor []>]()\\n  %1326 = Gather[axis = 0](%1324, %1325)\\n  %1327 = Shape(%1305)\\n  %1328 = Constant[value = <Scalar Tensor []>]()\\n  %1329 = Gather[axis = 0](%1327, %1328)\\n  %1332 = Unsqueeze[axes = [0]](%1326)\\n  %1333 = Unsqueeze[axes = [0]](%1329)\\n  %1336 = Concat[axis = 0](%1332, %1333, %1767, %1768)\\n  %1337 = Reshape(%1305, %1336)\\n  %1338 = Shape(%1308)\\n  %1339 = Constant[value = <Scalar Tensor []>]()\\n  %1340 = Gather[axis = 0](%1338, %1339)\\n  %1341 = Shape(%1308)\\n  %1342 = Constant[value = <Scalar Tensor []>]()\\n  %1343 = Gather[axis = 0](%1341, %1342)\\n  %1346 = Unsqueeze[axes = [0]](%1340)\\n  %1347 = Unsqueeze[axes = [0]](%1343)\\n  %1350 = Concat[axis = 0](%1346, %1347, %1769, %1770)\\n  %1351 = Reshape(%1308, %1350)\\n  %1352 = Transpose[perm = [0, 2, 1, 3]](%1351)\\n  %1353 = Transpose[perm = [0, 2, 3, 1]](%1337)\\n  %1354 = MatMul(%1323, %1353)\\n  %1355 = Constant[value = <Scalar Tensor []>]()\\n  %1356 = Div(%1354, %1355)\\n  %1357 = Add(%1356, %215)\\n  %1358 = Softmax[axis = 3](%1357)\\n  %1359 = MatMul(%1358, %1352)\\n  %1360 = Transpose[perm = [0, 2, 1, 3]](%1359)\\n  %1361 = Shape(%1360)\\n  %1362 = Constant[value = <Scalar Tensor []>]()\\n  %1363 = Gather[axis = 0](%1361, %1362)\\n  %1364 = Shape(%1360)\\n  %1365 = Constant[value = <Scalar Tensor []>]()\\n  %1366 = Gather[axis = 0](%1364, %1365)\\n  %1368 = Unsqueeze[axes = [0]](%1363)\\n  %1369 = Unsqueeze[axes = [0]](%1366)\\n  %1371 = Concat[axis = 0](%1368, %1369, %1771)\\n  %1372 = Reshape(%1360, %1371)\\n  %1374 = MatMul(%1372, %1772)\\n  %1375 = Add(%1374, %bert.encoder.layer.9.attention.output.dense.bias)\\n  %1376 = Add(%1375, %1299)\\n  %1377 = ReduceMean[axes = [-1]](%1376)\\n  %1378 = Sub(%1376, %1377)\\n  %1379 = Constant[value = <Scalar Tensor []>]()\\n  %1380 = Pow(%1378, %1379)\\n  %1381 = ReduceMean[axes = [-1]](%1380)\\n  %1382 = Constant[value = <Scalar Tensor []>]()\\n  %1383 = Add(%1381, %1382)\\n  %1384 = Sqrt(%1383)\\n  %1385 = Div(%1378, %1384)\\n  %1386 = Mul(%1385, %bert.encoder.layer.9.attention.output.LayerNorm.weight)\\n  %1387 = Add(%1386, %bert.encoder.layer.9.attention.output.LayerNorm.bias)\\n  %1389 = MatMul(%1387, %1773)\\n  %1390 = Add(%1389, %bert.encoder.layer.9.intermediate.dense.bias)\\n  %1391 = Constant[value = <Scalar Tensor []>]()\\n  %1392 = Div(%1390, %1391)\\n  %1393 = Erf(%1392)\\n  %1394 = Constant[value = <Scalar Tensor []>]()\\n  %1395 = Add(%1393, %1394)\\n  %1396 = Mul(%1390, %1395)\\n  %1397 = Constant[value = <Scalar Tensor []>]()\\n  %1398 = Mul(%1396, %1397)\\n  %1400 = MatMul(%1398, %1774)\\n  %1401 = Add(%1400, %bert.encoder.layer.9.output.dense.bias)\\n  %1402 = Add(%1401, %1387)\\n  %1403 = ReduceMean[axes = [-1]](%1402)\\n  %1404 = Sub(%1402, %1403)\\n  %1405 = Constant[value = <Scalar Tensor []>]()\\n  %1406 = Pow(%1404, %1405)\\n  %1407 = ReduceMean[axes = [-1]](%1406)\\n  %1408 = Constant[value = <Scalar Tensor []>]()\\n  %1409 = Add(%1407, %1408)\\n  %1410 = Sqrt(%1409)\\n  %1411 = Div(%1404, %1410)\\n  %1412 = Mul(%1411, %bert.encoder.layer.9.output.LayerNorm.weight)\\n  %1413 = Add(%1412, %bert.encoder.layer.9.output.LayerNorm.bias)\\n  %1415 = MatMul(%1413, %1775)\\n  %1416 = Add(%1415, %bert.encoder.layer.10.attention.self.query.bias)\\n  %1418 = MatMul(%1413, %1776)\\n  %1419 = Add(%1418, %bert.encoder.layer.10.attention.self.key.bias)\\n  %1421 = MatMul(%1413, %1777)\\n  %1422 = Add(%1421, %bert.encoder.layer.10.attention.self.value.bias)\\n  %1423 = Shape(%1416)\\n  %1424 = Constant[value = <Scalar Tensor []>]()\\n  %1425 = Gather[axis = 0](%1423, %1424)\\n  %1426 = Shape(%1416)\\n  %1427 = Constant[value = <Scalar Tensor []>]()\\n  %1428 = Gather[axis = 0](%1426, %1427)\\n  %1431 = Unsqueeze[axes = [0]](%1425)\\n  %1432 = Unsqueeze[axes = [0]](%1428)\\n  %1435 = Concat[axis = 0](%1431, %1432, %1778, %1779)\\n  %1436 = Reshape(%1416, %1435)\\n  %1437 = Transpose[perm = [0, 2, 1, 3]](%1436)\\n  %1438 = Shape(%1419)\\n  %1439 = Constant[value = <Scalar Tensor []>]()\\n  %1440 = Gather[axis = 0](%1438, %1439)\\n  %1441 = Shape(%1419)\\n  %1442 = Constant[value = <Scalar Tensor []>]()\\n  %1443 = Gather[axis = 0](%1441, %1442)\\n  %1446 = Unsqueeze[axes = [0]](%1440)\\n  %1447 = Unsqueeze[axes = [0]](%1443)\\n  %1450 = Concat[axis = 0](%1446, %1447, %1780, %1781)\\n  %1451 = Reshape(%1419, %1450)\\n  %1452 = Shape(%1422)\\n  %1453 = Constant[value = <Scalar Tensor []>]()\\n  %1454 = Gather[axis = 0](%1452, %1453)\\n  %1455 = Shape(%1422)\\n  %1456 = Constant[value = <Scalar Tensor []>]()\\n  %1457 = Gather[axis = 0](%1455, %1456)\\n  %1460 = Unsqueeze[axes = [0]](%1454)\\n  %1461 = Unsqueeze[axes = [0]](%1457)\\n  %1464 = Concat[axis = 0](%1460, %1461, %1782, %1783)\\n  %1465 = Reshape(%1422, %1464)\\n  %1466 = Transpose[perm = [0, 2, 1, 3]](%1465)\\n  %1467 = Transpose[perm = [0, 2, 3, 1]](%1451)\\n  %1468 = MatMul(%1437, %1467)\\n  %1469 = Constant[value = <Scalar Tensor []>]()\\n  %1470 = Div(%1468, %1469)\\n  %1471 = Add(%1470, %215)\\n  %1472 = Softmax[axis = 3](%1471)\\n  %1473 = MatMul(%1472, %1466)\\n  %1474 = Transpose[perm = [0, 2, 1, 3]](%1473)\\n  %1475 = Shape(%1474)\\n  %1476 = Constant[value = <Scalar Tensor []>]()\\n  %1477 = Gather[axis = 0](%1475, %1476)\\n  %1478 = Shape(%1474)\\n  %1479 = Constant[value = <Scalar Tensor []>]()\\n  %1480 = Gather[axis = 0](%1478, %1479)\\n  %1482 = Unsqueeze[axes = [0]](%1477)\\n  %1483 = Unsqueeze[axes = [0]](%1480)\\n  %1485 = Concat[axis = 0](%1482, %1483, %1784)\\n  %1486 = Reshape(%1474, %1485)\\n  %1488 = MatMul(%1486, %1785)\\n  %1489 = Add(%1488, %bert.encoder.layer.10.attention.output.dense.bias)\\n  %1490 = Add(%1489, %1413)\\n  %1491 = ReduceMean[axes = [-1]](%1490)\\n  %1492 = Sub(%1490, %1491)\\n  %1493 = Constant[value = <Scalar Tensor []>]()\\n  %1494 = Pow(%1492, %1493)\\n  %1495 = ReduceMean[axes = [-1]](%1494)\\n  %1496 = Constant[value = <Scalar Tensor []>]()\\n  %1497 = Add(%1495, %1496)\\n  %1498 = Sqrt(%1497)\\n  %1499 = Div(%1492, %1498)\\n  %1500 = Mul(%1499, %bert.encoder.layer.10.attention.output.LayerNorm.weight)\\n  %1501 = Add(%1500, %bert.encoder.layer.10.attention.output.LayerNorm.bias)\\n  %1503 = MatMul(%1501, %1786)\\n  %1504 = Add(%1503, %bert.encoder.layer.10.intermediate.dense.bias)\\n  %1505 = Constant[value = <Scalar Tensor []>]()\\n  %1506 = Div(%1504, %1505)\\n  %1507 = Erf(%1506)\\n  %1508 = Constant[value = <Scalar Tensor []>]()\\n  %1509 = Add(%1507, %1508)\\n  %1510 = Mul(%1504, %1509)\\n  %1511 = Constant[value = <Scalar Tensor []>]()\\n  %1512 = Mul(%1510, %1511)\\n  %1514 = MatMul(%1512, %1787)\\n  %1515 = Add(%1514, %bert.encoder.layer.10.output.dense.bias)\\n  %1516 = Add(%1515, %1501)\\n  %1517 = ReduceMean[axes = [-1]](%1516)\\n  %1518 = Sub(%1516, %1517)\\n  %1519 = Constant[value = <Scalar Tensor []>]()\\n  %1520 = Pow(%1518, %1519)\\n  %1521 = ReduceMean[axes = [-1]](%1520)\\n  %1522 = Constant[value = <Scalar Tensor []>]()\\n  %1523 = Add(%1521, %1522)\\n  %1524 = Sqrt(%1523)\\n  %1525 = Div(%1518, %1524)\\n  %1526 = Mul(%1525, %bert.encoder.layer.10.output.LayerNorm.weight)\\n  %1527 = Add(%1526, %bert.encoder.layer.10.output.LayerNorm.bias)\\n  %1529 = MatMul(%1527, %1788)\\n  %1530 = Add(%1529, %bert.encoder.layer.11.attention.self.query.bias)\\n  %1532 = MatMul(%1527, %1789)\\n  %1533 = Add(%1532, %bert.encoder.layer.11.attention.self.key.bias)\\n  %1535 = MatMul(%1527, %1790)\\n  %1536 = Add(%1535, %bert.encoder.layer.11.attention.self.value.bias)\\n  %1537 = Shape(%1530)\\n  %1538 = Constant[value = <Scalar Tensor []>]()\\n  %1539 = Gather[axis = 0](%1537, %1538)\\n  %1540 = Shape(%1530)\\n  %1541 = Constant[value = <Scalar Tensor []>]()\\n  %1542 = Gather[axis = 0](%1540, %1541)\\n  %1545 = Unsqueeze[axes = [0]](%1539)\\n  %1546 = Unsqueeze[axes = [0]](%1542)\\n  %1549 = Concat[axis = 0](%1545, %1546, %1791, %1792)\\n  %1550 = Reshape(%1530, %1549)\\n  %1551 = Transpose[perm = [0, 2, 1, 3]](%1550)\\n  %1552 = Shape(%1533)\\n  %1553 = Constant[value = <Scalar Tensor []>]()\\n  %1554 = Gather[axis = 0](%1552, %1553)\\n  %1555 = Shape(%1533)\\n  %1556 = Constant[value = <Scalar Tensor []>]()\\n  %1557 = Gather[axis = 0](%1555, %1556)\\n  %1560 = Unsqueeze[axes = [0]](%1554)\\n  %1561 = Unsqueeze[axes = [0]](%1557)\\n  %1564 = Concat[axis = 0](%1560, %1561, %1793, %1794)\\n  %1565 = Reshape(%1533, %1564)\\n  %1566 = Shape(%1536)\\n  %1567 = Constant[value = <Scalar Tensor []>]()\\n  %1568 = Gather[axis = 0](%1566, %1567)\\n  %1569 = Shape(%1536)\\n  %1570 = Constant[value = <Scalar Tensor []>]()\\n  %1571 = Gather[axis = 0](%1569, %1570)\\n  %1574 = Unsqueeze[axes = [0]](%1568)\\n  %1575 = Unsqueeze[axes = [0]](%1571)\\n  %1578 = Concat[axis = 0](%1574, %1575, %1795, %1796)\\n  %1579 = Reshape(%1536, %1578)\\n  %1580 = Transpose[perm = [0, 2, 1, 3]](%1579)\\n  %1581 = Transpose[perm = [0, 2, 3, 1]](%1565)\\n  %1582 = MatMul(%1551, %1581)\\n  %1583 = Constant[value = <Scalar Tensor []>]()\\n  %1584 = Div(%1582, %1583)\\n  %1585 = Add(%1584, %215)\\n  %1586 = Softmax[axis = 3](%1585)\\n  %1587 = MatMul(%1586, %1580)\\n  %1588 = Transpose[perm = [0, 2, 1, 3]](%1587)\\n  %1589 = Shape(%1588)\\n  %1590 = Constant[value = <Scalar Tensor []>]()\\n  %1591 = Gather[axis = 0](%1589, %1590)\\n  %1592 = Shape(%1588)\\n  %1593 = Constant[value = <Scalar Tensor []>]()\\n  %1594 = Gather[axis = 0](%1592, %1593)\\n  %1596 = Unsqueeze[axes = [0]](%1591)\\n  %1597 = Unsqueeze[axes = [0]](%1594)\\n  %1599 = Concat[axis = 0](%1596, %1597, %1797)\\n  %1600 = Reshape(%1588, %1599)\\n  %1602 = MatMul(%1600, %1798)\\n  %1603 = Add(%1602, %bert.encoder.layer.11.attention.output.dense.bias)\\n  %1604 = Add(%1603, %1527)\\n  %1605 = ReduceMean[axes = [-1]](%1604)\\n  %1606 = Sub(%1604, %1605)\\n  %1607 = Constant[value = <Scalar Tensor []>]()\\n  %1608 = Pow(%1606, %1607)\\n  %1609 = ReduceMean[axes = [-1]](%1608)\\n  %1610 = Constant[value = <Scalar Tensor []>]()\\n  %1611 = Add(%1609, %1610)\\n  %1612 = Sqrt(%1611)\\n  %1613 = Div(%1606, %1612)\\n  %1614 = Mul(%1613, %bert.encoder.layer.11.attention.output.LayerNorm.weight)\\n  %1615 = Add(%1614, %bert.encoder.layer.11.attention.output.LayerNorm.bias)\\n  %1617 = MatMul(%1615, %1799)\\n  %1618 = Add(%1617, %bert.encoder.layer.11.intermediate.dense.bias)\\n  %1619 = Constant[value = <Scalar Tensor []>]()\\n  %1620 = Div(%1618, %1619)\\n  %1621 = Erf(%1620)\\n  %1622 = Constant[value = <Scalar Tensor []>]()\\n  %1623 = Add(%1621, %1622)\\n  %1624 = Mul(%1618, %1623)\\n  %1625 = Constant[value = <Scalar Tensor []>]()\\n  %1626 = Mul(%1624, %1625)\\n  %1628 = MatMul(%1626, %1800)\\n  %1629 = Add(%1628, %bert.encoder.layer.11.output.dense.bias)\\n  %1630 = Add(%1629, %1615)\\n  %1631 = ReduceMean[axes = [-1]](%1630)\\n  %1632 = Sub(%1630, %1631)\\n  %1633 = Constant[value = <Scalar Tensor []>]()\\n  %1634 = Pow(%1632, %1633)\\n  %1635 = ReduceMean[axes = [-1]](%1634)\\n  %1636 = Constant[value = <Scalar Tensor []>]()\\n  %1637 = Add(%1635, %1636)\\n  %1638 = Sqrt(%1637)\\n  %1639 = Div(%1632, %1638)\\n  %1640 = Mul(%1639, %bert.encoder.layer.11.output.LayerNorm.weight)\\n  %1641 = Add(%1640, %bert.encoder.layer.11.output.LayerNorm.bias)\\n  %1643 = MatMul(%1641, %1801)\\n  %outputs = Add(%1643, %classifier.bias)\\n  return %outputs\\n}'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "-i4GPX3QFBYK",
        "outputId": "7fced331-7d28-46d0-f98e-1ed4c7969a23"
      },
      "source": [
        "tf_rep = onnx_tf.backend.prepare(onnx_model)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SchemaError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mSchemaError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-ab860cf60c25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf_rep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0monnx_tf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0monnx_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/onnx-tensorflow/onnx_tf/backend.py\u001b[0m in \u001b[0;36mprepare\u001b[0;34m(cls, model, device, strict, logging_level, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0mcommon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandlers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetLevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogging_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_model_to_tensorflow_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/onnx-tensorflow/onnx_tf/backend.py\u001b[0m in \u001b[0;36monnx_model_to_tensorflow_rep\u001b[0;34m(cls, model, strict)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m       \u001b[0mopset_import\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopset_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_onnx_graph_to_tensorflow_rep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopset_import\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/onnx-tensorflow/onnx_tf/backend.py\u001b[0m in \u001b[0;36m_onnx_graph_to_tensorflow_rep\u001b[0;34m(cls, graph_def, opset, strict)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensorflowRep\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     \"\"\"\n\u001b[0;32m---> 98\u001b[0;31m     \u001b[0mhandlers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_handlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mtf_rep_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/onnx-tensorflow/onnx_tf/backend.py\u001b[0m in \u001b[0;36m_get_handlers\u001b[0;34m(cls, opset)\u001b[0m\n\u001b[1;32m    264\u001b[0m     \u001b[0mopset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopset\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmake_opsetid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX_DOMAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0monnx_opset_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0mopset_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mopset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mget_all_backend_handlers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopset_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/onnx-tensorflow/onnx_tf/common/handler_helper.py\u001b[0m in \u001b[0;36mget_all_backend_handlers\u001b[0;34m(opset_dict)\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mONNX_OP\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mdomain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDOMAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m             max_inclusive_version=version).since_version\n\u001b[0m\u001b[1;32m     31\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m         common.logger.debug(\"Fail to get since_version of {} in domain `{}` \"\n",
            "\u001b[0;31mSchemaError\u001b[0m: No schema registered for 'BitShift'!"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4xSr1cWDNXu",
        "outputId": "756af778-037d-46a5-d690-bf6a01c1c67b"
      },
      "source": [
        "tf_rep.inputs"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['input_ids', 'input_bbox', 'attention_mask', 'token_type_ids']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUW2XfVnDPWs",
        "outputId": "e8ad1c92-b15e-46f9-83be-8cb8de63577d"
      },
      "source": [
        "tf_rep.tf_module"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<onnx_tf.backend_tf_module.BackendTFModule at 0x7f14377eded0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0GCHE7y8cAX",
        "outputId": "ddb020cf-9fb5-46c2-d7c0-182c207e5e83"
      },
      "source": [
        "tf_rep.tensor_dict"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bert.embeddings.word_embeddings.weight': <tf.Tensor 'bert.embeddings.word_embeddings.weight:0' shape=(30522, 768) dtype=float32>,\n",
              " 'bert.embeddings.position_embeddings.weight': <tf.Tensor 'bert.embeddings.position_embeddings.weight:0' shape=(512, 768) dtype=float32>,\n",
              " 'bert.embeddings.x_position_embeddings.weight': <tf.Tensor 'bert.embeddings.x_position_embeddings.weight:0' shape=(1024, 768) dtype=float32>,\n",
              " 'bert.embeddings.y_position_embeddings.weight': <tf.Tensor 'bert.embeddings.y_position_embeddings.weight:0' shape=(1024, 768) dtype=float32>,\n",
              " 'bert.embeddings.h_position_embeddings.weight': <tf.Tensor 'bert.embeddings.h_position_embeddings.weight:0' shape=(1024, 768) dtype=float32>,\n",
              " 'bert.embeddings.w_position_embeddings.weight': <tf.Tensor 'bert.embeddings.w_position_embeddings.weight:0' shape=(1024, 768) dtype=float32>,\n",
              " 'bert.embeddings.token_type_embeddings.weight': <tf.Tensor 'bert.embeddings.token_type_embeddings.weight:0' shape=(2, 768) dtype=float32>,\n",
              " 'bert.embeddings.LayerNorm.weight': <tf.Tensor 'bert.embeddings.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.embeddings.LayerNorm.bias': <tf.Tensor 'bert.embeddings.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.0.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.0.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.0.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.0.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.0.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.0.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.0.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.output.dense.bias': <tf.Tensor 'bert.encoder.layer.0.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.0.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.0.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.0.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.1.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.1.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.1.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.1.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.1.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.1.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.1.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.output.dense.bias': <tf.Tensor 'bert.encoder.layer.1.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.1.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.1.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.1.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.2.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.2.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.2.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.2.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.2.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.2.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.2.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.output.dense.bias': <tf.Tensor 'bert.encoder.layer.2.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.2.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.2.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.2.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.3.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.3.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.3.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.3.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.3.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.3.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.3.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.output.dense.bias': <tf.Tensor 'bert.encoder.layer.3.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.3.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.3.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.3.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.4.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.4.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.4.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.4.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.4.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.4.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.4.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.output.dense.bias': <tf.Tensor 'bert.encoder.layer.4.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.4.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.4.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.4.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.5.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.5.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.5.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.5.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.5.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.5.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.5.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.output.dense.bias': <tf.Tensor 'bert.encoder.layer.5.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.5.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.5.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.5.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.6.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.6.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.6.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.6.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.6.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.6.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.6.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.output.dense.bias': <tf.Tensor 'bert.encoder.layer.6.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.6.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.6.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.6.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.7.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.7.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.7.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.7.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.7.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.7.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.7.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.output.dense.bias': <tf.Tensor 'bert.encoder.layer.7.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.7.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.7.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.7.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.8.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.8.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.8.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.8.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.8.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.8.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.8.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.output.dense.bias': <tf.Tensor 'bert.encoder.layer.8.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.8.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.8.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.8.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.9.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.9.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.9.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.9.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.9.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.9.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.9.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.output.dense.bias': <tf.Tensor 'bert.encoder.layer.9.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.9.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.9.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.9.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.10.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.10.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.10.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.10.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.10.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.10.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.10.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.output.dense.bias': <tf.Tensor 'bert.encoder.layer.10.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.10.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.10.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.10.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.attention.self.query.bias': <tf.Tensor 'bert.encoder.layer.11.attention.self.query.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.attention.self.key.bias': <tf.Tensor 'bert.encoder.layer.11.attention.self.key.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.attention.self.value.bias': <tf.Tensor 'bert.encoder.layer.11.attention.self.value.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.attention.output.dense.bias': <tf.Tensor 'bert.encoder.layer.11.attention.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.attention.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.11.attention.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.attention.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.11.attention.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.intermediate.dense.bias': <tf.Tensor 'bert.encoder.layer.11.intermediate.dense.bias:0' shape=(3072,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.output.dense.bias': <tf.Tensor 'bert.encoder.layer.11.output.dense.bias:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.output.LayerNorm.weight': <tf.Tensor 'bert.encoder.layer.11.output.LayerNorm.weight:0' shape=(768,) dtype=float32>,\n",
              " 'bert.encoder.layer.11.output.LayerNorm.bias': <tf.Tensor 'bert.encoder.layer.11.output.LayerNorm.bias:0' shape=(768,) dtype=float32>,\n",
              " 'classifier.bias': <tf.Tensor 'classifier.bias:0' shape=(4,) dtype=float32>,\n",
              " '1645': <tf.Tensor '1645:0' shape=(768, 768) dtype=float32>,\n",
              " '1646': <tf.Tensor '1646:0' shape=(768, 768) dtype=float32>,\n",
              " '1647': <tf.Tensor '1647:0' shape=(768, 768) dtype=float32>,\n",
              " '1648': <tf.Tensor '1648:0' shape=(1,) dtype=int64>,\n",
              " '1649': <tf.Tensor '1649:0' shape=(1,) dtype=int64>,\n",
              " '1650': <tf.Tensor '1650:0' shape=(1,) dtype=int64>,\n",
              " '1651': <tf.Tensor '1651:0' shape=(1,) dtype=int64>,\n",
              " '1652': <tf.Tensor '1652:0' shape=(1,) dtype=int64>,\n",
              " '1653': <tf.Tensor '1653:0' shape=(1,) dtype=int64>,\n",
              " '1654': <tf.Tensor '1654:0' shape=(1,) dtype=int64>,\n",
              " '1655': <tf.Tensor '1655:0' shape=(768, 768) dtype=float32>,\n",
              " '1656': <tf.Tensor '1656:0' shape=(768, 3072) dtype=float32>,\n",
              " '1657': <tf.Tensor '1657:0' shape=(3072, 768) dtype=float32>,\n",
              " '1658': <tf.Tensor '1658:0' shape=(768, 768) dtype=float32>,\n",
              " '1659': <tf.Tensor '1659:0' shape=(768, 768) dtype=float32>,\n",
              " '1660': <tf.Tensor '1660:0' shape=(768, 768) dtype=float32>,\n",
              " '1661': <tf.Tensor '1661:0' shape=(1,) dtype=int64>,\n",
              " '1662': <tf.Tensor '1662:0' shape=(1,) dtype=int64>,\n",
              " '1663': <tf.Tensor '1663:0' shape=(1,) dtype=int64>,\n",
              " '1664': <tf.Tensor '1664:0' shape=(1,) dtype=int64>,\n",
              " '1665': <tf.Tensor '1665:0' shape=(1,) dtype=int64>,\n",
              " '1666': <tf.Tensor '1666:0' shape=(1,) dtype=int64>,\n",
              " '1667': <tf.Tensor '1667:0' shape=(1,) dtype=int64>,\n",
              " '1668': <tf.Tensor '1668:0' shape=(768, 768) dtype=float32>,\n",
              " '1669': <tf.Tensor '1669:0' shape=(768, 3072) dtype=float32>,\n",
              " '1670': <tf.Tensor '1670:0' shape=(3072, 768) dtype=float32>,\n",
              " '1671': <tf.Tensor '1671:0' shape=(768, 768) dtype=float32>,\n",
              " '1672': <tf.Tensor '1672:0' shape=(768, 768) dtype=float32>,\n",
              " '1673': <tf.Tensor '1673:0' shape=(768, 768) dtype=float32>,\n",
              " '1674': <tf.Tensor '1674:0' shape=(1,) dtype=int64>,\n",
              " '1675': <tf.Tensor '1675:0' shape=(1,) dtype=int64>,\n",
              " '1676': <tf.Tensor '1676:0' shape=(1,) dtype=int64>,\n",
              " '1677': <tf.Tensor '1677:0' shape=(1,) dtype=int64>,\n",
              " '1678': <tf.Tensor '1678:0' shape=(1,) dtype=int64>,\n",
              " '1679': <tf.Tensor '1679:0' shape=(1,) dtype=int64>,\n",
              " '1680': <tf.Tensor '1680:0' shape=(1,) dtype=int64>,\n",
              " '1681': <tf.Tensor '1681:0' shape=(768, 768) dtype=float32>,\n",
              " '1682': <tf.Tensor '1682:0' shape=(768, 3072) dtype=float32>,\n",
              " '1683': <tf.Tensor '1683:0' shape=(3072, 768) dtype=float32>,\n",
              " '1684': <tf.Tensor '1684:0' shape=(768, 768) dtype=float32>,\n",
              " '1685': <tf.Tensor '1685:0' shape=(768, 768) dtype=float32>,\n",
              " '1686': <tf.Tensor '1686:0' shape=(768, 768) dtype=float32>,\n",
              " '1687': <tf.Tensor '1687:0' shape=(1,) dtype=int64>,\n",
              " '1688': <tf.Tensor '1688:0' shape=(1,) dtype=int64>,\n",
              " '1689': <tf.Tensor '1689:0' shape=(1,) dtype=int64>,\n",
              " '1690': <tf.Tensor '1690:0' shape=(1,) dtype=int64>,\n",
              " '1691': <tf.Tensor '1691:0' shape=(1,) dtype=int64>,\n",
              " '1692': <tf.Tensor '1692:0' shape=(1,) dtype=int64>,\n",
              " '1693': <tf.Tensor '1693:0' shape=(1,) dtype=int64>,\n",
              " '1694': <tf.Tensor '1694:0' shape=(768, 768) dtype=float32>,\n",
              " '1695': <tf.Tensor '1695:0' shape=(768, 3072) dtype=float32>,\n",
              " '1696': <tf.Tensor '1696:0' shape=(3072, 768) dtype=float32>,\n",
              " '1697': <tf.Tensor '1697:0' shape=(768, 768) dtype=float32>,\n",
              " '1698': <tf.Tensor '1698:0' shape=(768, 768) dtype=float32>,\n",
              " '1699': <tf.Tensor '1699:0' shape=(768, 768) dtype=float32>,\n",
              " '1700': <tf.Tensor '1700:0' shape=(1,) dtype=int64>,\n",
              " '1701': <tf.Tensor '1701:0' shape=(1,) dtype=int64>,\n",
              " '1702': <tf.Tensor '1702:0' shape=(1,) dtype=int64>,\n",
              " '1703': <tf.Tensor '1703:0' shape=(1,) dtype=int64>,\n",
              " '1704': <tf.Tensor '1704:0' shape=(1,) dtype=int64>,\n",
              " '1705': <tf.Tensor '1705:0' shape=(1,) dtype=int64>,\n",
              " '1706': <tf.Tensor '1706:0' shape=(1,) dtype=int64>,\n",
              " '1707': <tf.Tensor '1707:0' shape=(768, 768) dtype=float32>,\n",
              " '1708': <tf.Tensor '1708:0' shape=(768, 3072) dtype=float32>,\n",
              " '1709': <tf.Tensor '1709:0' shape=(3072, 768) dtype=float32>,\n",
              " '1710': <tf.Tensor '1710:0' shape=(768, 768) dtype=float32>,\n",
              " '1711': <tf.Tensor '1711:0' shape=(768, 768) dtype=float32>,\n",
              " '1712': <tf.Tensor '1712:0' shape=(768, 768) dtype=float32>,\n",
              " '1713': <tf.Tensor '1713:0' shape=(1,) dtype=int64>,\n",
              " '1714': <tf.Tensor '1714:0' shape=(1,) dtype=int64>,\n",
              " '1715': <tf.Tensor '1715:0' shape=(1,) dtype=int64>,\n",
              " '1716': <tf.Tensor '1716:0' shape=(1,) dtype=int64>,\n",
              " '1717': <tf.Tensor '1717:0' shape=(1,) dtype=int64>,\n",
              " '1718': <tf.Tensor '1718:0' shape=(1,) dtype=int64>,\n",
              " '1719': <tf.Tensor '1719:0' shape=(1,) dtype=int64>,\n",
              " '1720': <tf.Tensor '1720:0' shape=(768, 768) dtype=float32>,\n",
              " '1721': <tf.Tensor '1721:0' shape=(768, 3072) dtype=float32>,\n",
              " '1722': <tf.Tensor '1722:0' shape=(3072, 768) dtype=float32>,\n",
              " '1723': <tf.Tensor '1723:0' shape=(768, 768) dtype=float32>,\n",
              " '1724': <tf.Tensor '1724:0' shape=(768, 768) dtype=float32>,\n",
              " '1725': <tf.Tensor '1725:0' shape=(768, 768) dtype=float32>,\n",
              " '1726': <tf.Tensor '1726:0' shape=(1,) dtype=int64>,\n",
              " '1727': <tf.Tensor '1727:0' shape=(1,) dtype=int64>,\n",
              " '1728': <tf.Tensor '1728:0' shape=(1,) dtype=int64>,\n",
              " '1729': <tf.Tensor '1729:0' shape=(1,) dtype=int64>,\n",
              " '1730': <tf.Tensor '1730:0' shape=(1,) dtype=int64>,\n",
              " '1731': <tf.Tensor '1731:0' shape=(1,) dtype=int64>,\n",
              " '1732': <tf.Tensor '1732:0' shape=(1,) dtype=int64>,\n",
              " '1733': <tf.Tensor '1733:0' shape=(768, 768) dtype=float32>,\n",
              " '1734': <tf.Tensor '1734:0' shape=(768, 3072) dtype=float32>,\n",
              " '1735': <tf.Tensor '1735:0' shape=(3072, 768) dtype=float32>,\n",
              " '1736': <tf.Tensor '1736:0' shape=(768, 768) dtype=float32>,\n",
              " '1737': <tf.Tensor '1737:0' shape=(768, 768) dtype=float32>,\n",
              " '1738': <tf.Tensor '1738:0' shape=(768, 768) dtype=float32>,\n",
              " '1739': <tf.Tensor '1739:0' shape=(1,) dtype=int64>,\n",
              " '1740': <tf.Tensor '1740:0' shape=(1,) dtype=int64>,\n",
              " '1741': <tf.Tensor '1741:0' shape=(1,) dtype=int64>,\n",
              " '1742': <tf.Tensor '1742:0' shape=(1,) dtype=int64>,\n",
              " '1743': <tf.Tensor '1743:0' shape=(1,) dtype=int64>,\n",
              " '1744': <tf.Tensor '1744:0' shape=(1,) dtype=int64>,\n",
              " '1745': <tf.Tensor '1745:0' shape=(1,) dtype=int64>,\n",
              " '1746': <tf.Tensor '1746:0' shape=(768, 768) dtype=float32>,\n",
              " '1747': <tf.Tensor '1747:0' shape=(768, 3072) dtype=float32>,\n",
              " '1748': <tf.Tensor '1748:0' shape=(3072, 768) dtype=float32>,\n",
              " '1749': <tf.Tensor '1749:0' shape=(768, 768) dtype=float32>,\n",
              " '1750': <tf.Tensor '1750:0' shape=(768, 768) dtype=float32>,\n",
              " '1751': <tf.Tensor '1751:0' shape=(768, 768) dtype=float32>,\n",
              " '1752': <tf.Tensor '1752:0' shape=(1,) dtype=int64>,\n",
              " '1753': <tf.Tensor '1753:0' shape=(1,) dtype=int64>,\n",
              " '1754': <tf.Tensor '1754:0' shape=(1,) dtype=int64>,\n",
              " '1755': <tf.Tensor '1755:0' shape=(1,) dtype=int64>,\n",
              " '1756': <tf.Tensor '1756:0' shape=(1,) dtype=int64>,\n",
              " '1757': <tf.Tensor '1757:0' shape=(1,) dtype=int64>,\n",
              " '1758': <tf.Tensor '1758:0' shape=(1,) dtype=int64>,\n",
              " '1759': <tf.Tensor '1759:0' shape=(768, 768) dtype=float32>,\n",
              " '1760': <tf.Tensor '1760:0' shape=(768, 3072) dtype=float32>,\n",
              " '1761': <tf.Tensor '1761:0' shape=(3072, 768) dtype=float32>,\n",
              " '1762': <tf.Tensor '1762:0' shape=(768, 768) dtype=float32>,\n",
              " '1763': <tf.Tensor '1763:0' shape=(768, 768) dtype=float32>,\n",
              " '1764': <tf.Tensor '1764:0' shape=(768, 768) dtype=float32>,\n",
              " '1765': <tf.Tensor '1765:0' shape=(1,) dtype=int64>,\n",
              " '1766': <tf.Tensor '1766:0' shape=(1,) dtype=int64>,\n",
              " '1767': <tf.Tensor '1767:0' shape=(1,) dtype=int64>,\n",
              " '1768': <tf.Tensor '1768:0' shape=(1,) dtype=int64>,\n",
              " '1769': <tf.Tensor '1769:0' shape=(1,) dtype=int64>,\n",
              " '1770': <tf.Tensor '1770:0' shape=(1,) dtype=int64>,\n",
              " '1771': <tf.Tensor '1771:0' shape=(1,) dtype=int64>,\n",
              " '1772': <tf.Tensor '1772:0' shape=(768, 768) dtype=float32>,\n",
              " '1773': <tf.Tensor '1773:0' shape=(768, 3072) dtype=float32>,\n",
              " '1774': <tf.Tensor '1774:0' shape=(3072, 768) dtype=float32>,\n",
              " '1775': <tf.Tensor '1775:0' shape=(768, 768) dtype=float32>,\n",
              " '1776': <tf.Tensor '1776:0' shape=(768, 768) dtype=float32>,\n",
              " '1777': <tf.Tensor '1777:0' shape=(768, 768) dtype=float32>,\n",
              " '1778': <tf.Tensor '1778:0' shape=(1,) dtype=int64>,\n",
              " '1779': <tf.Tensor '1779:0' shape=(1,) dtype=int64>,\n",
              " '1780': <tf.Tensor '1780:0' shape=(1,) dtype=int64>,\n",
              " '1781': <tf.Tensor '1781:0' shape=(1,) dtype=int64>,\n",
              " '1782': <tf.Tensor '1782:0' shape=(1,) dtype=int64>,\n",
              " '1783': <tf.Tensor '1783:0' shape=(1,) dtype=int64>,\n",
              " '1784': <tf.Tensor '1784:0' shape=(1,) dtype=int64>,\n",
              " '1785': <tf.Tensor '1785:0' shape=(768, 768) dtype=float32>,\n",
              " '1786': <tf.Tensor '1786:0' shape=(768, 3072) dtype=float32>,\n",
              " '1787': <tf.Tensor '1787:0' shape=(3072, 768) dtype=float32>,\n",
              " '1788': <tf.Tensor '1788:0' shape=(768, 768) dtype=float32>,\n",
              " '1789': <tf.Tensor '1789:0' shape=(768, 768) dtype=float32>,\n",
              " '1790': <tf.Tensor '1790:0' shape=(768, 768) dtype=float32>,\n",
              " '1791': <tf.Tensor '1791:0' shape=(1,) dtype=int64>,\n",
              " '1792': <tf.Tensor '1792:0' shape=(1,) dtype=int64>,\n",
              " '1793': <tf.Tensor '1793:0' shape=(1,) dtype=int64>,\n",
              " '1794': <tf.Tensor '1794:0' shape=(1,) dtype=int64>,\n",
              " '1795': <tf.Tensor '1795:0' shape=(1,) dtype=int64>,\n",
              " '1796': <tf.Tensor '1796:0' shape=(1,) dtype=int64>,\n",
              " '1797': <tf.Tensor '1797:0' shape=(1,) dtype=int64>,\n",
              " '1798': <tf.Tensor '1798:0' shape=(768, 768) dtype=float32>,\n",
              " '1799': <tf.Tensor '1799:0' shape=(768, 3072) dtype=float32>,\n",
              " '1800': <tf.Tensor '1800:0' shape=(3072, 768) dtype=float32>,\n",
              " '1801': <tf.Tensor '1801:0' shape=(768, 4) dtype=float32>,\n",
              " 'input_ids': <tf.Tensor 'input_ids:0' shape=(?, ?) dtype=int64>,\n",
              " 'input_bbox': <tf.Tensor 'input_bbox:0' shape=(1, 128, 4) dtype=int64>,\n",
              " 'attention_mask': <tf.Tensor 'attention_mask:0' shape=(?, ?) dtype=int64>,\n",
              " 'token_type_ids': <tf.Tensor 'token_type_ids:0' shape=(?, ?) dtype=int64>,\n",
              " '209': <tf.Tensor 'Unsqueeze_0:0' shape=(?, 1, ?) dtype=int64>,\n",
              " '210': <tf.Tensor 'Unsqueeze_1:0' shape=(?, 1, 1, ?) dtype=int64>,\n",
              " '211': <tf.Tensor 'Cast_2:0' shape=(?, 1, 1, ?) dtype=float32>,\n",
              " '212': <tf.Tensor 'Constant_3:0' shape=() dtype=float32>,\n",
              " '213': <tf.Tensor 'Sub_4:0' shape=(?, 1, 1, ?) dtype=float32>,\n",
              " '214': <tf.Tensor 'Constant_5:0' shape=() dtype=float32>,\n",
              " '215': <tf.Tensor 'Mul_6:0' shape=(?, 1, 1, ?) dtype=float32>,\n",
              " '216': <tf.Tensor 'Shape_7:0' shape=(2,) dtype=int64>,\n",
              " '217': <tf.Tensor 'Constant_8:0' shape=() dtype=int64>,\n",
              " '218': <tf.Tensor 'Gather_9:0' shape=() dtype=int64>,\n",
              " '219': <tf.Tensor 'Unsqueeze_10:0' shape=(1,) dtype=int64>,\n",
              " '220': <tf.Tensor 'ConstantOfShape_11:0' shape=(?,) dtype=int64>,\n",
              " '221': <tf.Tensor 'transpose:0' shape=(1, ?) dtype=int64>,\n",
              " '222': <tf.Tensor 'Transpose_13:0' shape=(?, 1) dtype=int64>,\n",
              " '223': <tf.Tensor 'Squeeze_14:0' shape=(?,) dtype=int64>,\n",
              " '224': <tf.Tensor 'Squeeze_14:0' shape=(?,) dtype=int64>,\n",
              " '225': <tf.Tensor 'Unsqueeze_16:0' shape=(1, ?) dtype=int64>,\n",
              " '226': <tf.Tensor 'Shape_17:0' shape=(2,) dtype=int64>,\n",
              " '227': <tf.Tensor 'mul:0' shape=(?, ?) dtype=int64>,\n",
              " '228': <tf.Tensor 'Gather_19:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '229': <tf.Tensor 'Gather_20:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '230': <tf.Tensor 'Constant_21:0' shape=() dtype=int64>,\n",
              " '231': <tf.Tensor 'Gather_22:0' shape=(1, 128) dtype=int64>,\n",
              " '232': <tf.Tensor 'Gather_23:0' shape=(1, 128, 768) dtype=float32>,\n",
              " '233': <tf.Tensor 'Constant_24:0' shape=() dtype=int64>,\n",
              " '234': <tf.Tensor 'Gather_25:0' shape=(1, 128) dtype=int64>,\n",
              " '235': <tf.Tensor 'Gather_26:0' shape=(1, 128, 768) dtype=float32>,\n",
              " '236': <tf.Tensor 'Constant_27:0' shape=() dtype=int64>,\n",
              " '237': <tf.Tensor 'Gather_28:0' shape=(1, 128) dtype=int64>,\n",
              " '238': <tf.Tensor 'Gather_29:0' shape=(1, 128, 768) dtype=float32>,\n",
              " '239': <tf.Tensor 'Constant_30:0' shape=() dtype=int64>,\n",
              " '240': <tf.Tensor 'Gather_31:0' shape=(1, 128) dtype=int64>,\n",
              " '241': <tf.Tensor 'Gather_32:0' shape=(1, 128, 768) dtype=float32>,\n",
              " '242': <tf.Tensor 'Constant_33:0' shape=() dtype=int64>,\n",
              " '243': <tf.Tensor 'Gather_34:0' shape=(1, 128) dtype=int64>,\n",
              " '244': <tf.Tensor 'Constant_35:0' shape=() dtype=int64>,\n",
              " '245': <tf.Tensor 'Gather_36:0' shape=(1, 128) dtype=int64>,\n",
              " '246': <tf.Tensor 'Sub_37:0' shape=(1, 128) dtype=int64>,\n",
              " '247': <tf.Tensor 'Gather_38:0' shape=(1, 128, 768) dtype=float32>,\n",
              " '248': <tf.Tensor 'Constant_39:0' shape=() dtype=int64>,\n",
              " '249': <tf.Tensor 'Gather_40:0' shape=(1, 128) dtype=int64>,\n",
              " '250': <tf.Tensor 'Constant_41:0' shape=() dtype=int64>,\n",
              " '251': <tf.Tensor 'Gather_42:0' shape=(1, 128) dtype=int64>,\n",
              " '252': <tf.Tensor 'Sub_43:0' shape=(1, 128) dtype=int64>,\n",
              " '253': <tf.Tensor 'Gather_44:0' shape=(1, 128, 768) dtype=float32>,\n",
              " '254': <tf.Tensor 'Gather_45:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '255': <tf.Tensor 'Add_46:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '256': <tf.Tensor 'Add_47:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '257': <tf.Tensor 'Add_48:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '258': <tf.Tensor 'Add_49:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '259': <tf.Tensor 'Add_50:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '260': <tf.Tensor 'Add_51:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '261': <tf.Tensor 'Add_52:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '262': <tf.Tensor 'Add_53:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '263': <tf.Tensor 'ReduceMean_54:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '264': <tf.Tensor 'Sub_55:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '265': <tf.Tensor 'Constant_56:0' shape=() dtype=float32>,\n",
              " '266': <tf.Tensor 'Pow_57:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '267': <tf.Tensor 'ReduceMean_58:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '268': <tf.Tensor 'Constant_59:0' shape=() dtype=float32>,\n",
              " '269': <tf.Tensor 'Add_60:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '270': <tf.Tensor 'Sqrt_61:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '271': <tf.Tensor 'Div_62:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '272': <tf.Tensor 'Mul_63:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '273': <tf.Tensor 'Add_64:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '275': <tf.Tensor 'MatMul_65:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '276': <tf.Tensor 'Add_66:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '278': <tf.Tensor 'MatMul_67:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '279': <tf.Tensor 'Add_68:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '281': <tf.Tensor 'MatMul_69:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '282': <tf.Tensor 'Add_70:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '283': <tf.Tensor 'Shape_71:0' shape=(3,) dtype=int64>,\n",
              " '284': <tf.Tensor 'Constant_72:0' shape=() dtype=int64>,\n",
              " '285': <tf.Tensor 'Gather_73:0' shape=() dtype=int64>,\n",
              " '286': <tf.Tensor 'Shape_74:0' shape=(3,) dtype=int64>,\n",
              " '287': <tf.Tensor 'Constant_75:0' shape=() dtype=int64>,\n",
              " '288': <tf.Tensor 'Gather_76:0' shape=() dtype=int64>,\n",
              " '291': <tf.Tensor 'Unsqueeze_77:0' shape=(1,) dtype=int64>,\n",
              " '292': <tf.Tensor 'Unsqueeze_78:0' shape=(1,) dtype=int64>,\n",
              " '295': <tf.Tensor 'Concat_79:0' shape=(4,) dtype=int64>,\n",
              " '296': <tf.Tensor 'Reshape_80:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '297': <tf.Tensor 'Transpose_81:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '298': <tf.Tensor 'Shape_82:0' shape=(3,) dtype=int64>,\n",
              " '299': <tf.Tensor 'Constant_83:0' shape=() dtype=int64>,\n",
              " '300': <tf.Tensor 'Gather_84:0' shape=() dtype=int64>,\n",
              " '301': <tf.Tensor 'Shape_85:0' shape=(3,) dtype=int64>,\n",
              " '302': <tf.Tensor 'Constant_86:0' shape=() dtype=int64>,\n",
              " '303': <tf.Tensor 'Gather_87:0' shape=() dtype=int64>,\n",
              " '306': <tf.Tensor 'Unsqueeze_88:0' shape=(1,) dtype=int64>,\n",
              " '307': <tf.Tensor 'Unsqueeze_89:0' shape=(1,) dtype=int64>,\n",
              " '310': <tf.Tensor 'Concat_90:0' shape=(4,) dtype=int64>,\n",
              " '311': <tf.Tensor 'Reshape_91:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '312': <tf.Tensor 'Shape_92:0' shape=(3,) dtype=int64>,\n",
              " '313': <tf.Tensor 'Constant_93:0' shape=() dtype=int64>,\n",
              " '314': <tf.Tensor 'Gather_94:0' shape=() dtype=int64>,\n",
              " '315': <tf.Tensor 'Shape_95:0' shape=(3,) dtype=int64>,\n",
              " '316': <tf.Tensor 'Constant_96:0' shape=() dtype=int64>,\n",
              " '317': <tf.Tensor 'Gather_97:0' shape=() dtype=int64>,\n",
              " '320': <tf.Tensor 'Unsqueeze_98:0' shape=(1,) dtype=int64>,\n",
              " '321': <tf.Tensor 'Unsqueeze_99:0' shape=(1,) dtype=int64>,\n",
              " '324': <tf.Tensor 'Concat_100:0' shape=(4,) dtype=int64>,\n",
              " '325': <tf.Tensor 'Reshape_101:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '326': <tf.Tensor 'Transpose_102:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '327': <tf.Tensor 'Transpose_103:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '328': <tf.Tensor 'MatMul_104:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '329': <tf.Tensor 'Constant_105:0' shape=() dtype=float32>,\n",
              " '330': <tf.Tensor 'Div_106:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '331': <tf.Tensor 'Add_107:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '332': <tf.Tensor 'Softmax_108:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '333': <tf.Tensor 'MatMul_109:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '334': <tf.Tensor 'Transpose_110:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '335': <tf.Tensor 'Shape_111:0' shape=(4,) dtype=int64>,\n",
              " '336': <tf.Tensor 'Constant_112:0' shape=() dtype=int64>,\n",
              " '337': <tf.Tensor 'Gather_113:0' shape=() dtype=int64>,\n",
              " '338': <tf.Tensor 'Shape_114:0' shape=(4,) dtype=int64>,\n",
              " '339': <tf.Tensor 'Constant_115:0' shape=() dtype=int64>,\n",
              " '340': <tf.Tensor 'Gather_116:0' shape=() dtype=int64>,\n",
              " '342': <tf.Tensor 'Unsqueeze_117:0' shape=(1,) dtype=int64>,\n",
              " '343': <tf.Tensor 'Unsqueeze_118:0' shape=(1,) dtype=int64>,\n",
              " '345': <tf.Tensor 'Concat_119:0' shape=(3,) dtype=int64>,\n",
              " '346': <tf.Tensor 'Reshape_120:0' shape=(?, ?, ?) dtype=float32>,\n",
              " '348': <tf.Tensor 'MatMul_121:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '349': <tf.Tensor 'Add_122:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '350': <tf.Tensor 'Add_123:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '351': <tf.Tensor 'ReduceMean_124:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '352': <tf.Tensor 'Sub_125:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '353': <tf.Tensor 'Constant_126:0' shape=() dtype=float32>,\n",
              " '354': <tf.Tensor 'Pow_127:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '355': <tf.Tensor 'ReduceMean_128:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '356': <tf.Tensor 'Constant_129:0' shape=() dtype=float32>,\n",
              " '357': <tf.Tensor 'Add_130:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '358': <tf.Tensor 'Sqrt_131:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '359': <tf.Tensor 'Div_132:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '360': <tf.Tensor 'Mul_133:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '361': <tf.Tensor 'Add_134:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '363': <tf.Tensor 'MatMul_135:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '364': <tf.Tensor 'Add_136:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '365': <tf.Tensor 'Constant_137:0' shape=() dtype=float32>,\n",
              " '366': <tf.Tensor 'Div_138:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '367': <tf.Tensor 'Erf_139:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '368': <tf.Tensor 'Constant_140:0' shape=() dtype=float32>,\n",
              " '369': <tf.Tensor 'Add_141:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '370': <tf.Tensor 'Mul_142:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '371': <tf.Tensor 'Constant_143:0' shape=() dtype=float32>,\n",
              " '372': <tf.Tensor 'Mul_144:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '374': <tf.Tensor 'MatMul_145:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '375': <tf.Tensor 'Add_146:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '376': <tf.Tensor 'Add_147:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '377': <tf.Tensor 'ReduceMean_148:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '378': <tf.Tensor 'Sub_149:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '379': <tf.Tensor 'Constant_150:0' shape=() dtype=float32>,\n",
              " '380': <tf.Tensor 'Pow_151:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '381': <tf.Tensor 'ReduceMean_152:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '382': <tf.Tensor 'Constant_153:0' shape=() dtype=float32>,\n",
              " '383': <tf.Tensor 'Add_154:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '384': <tf.Tensor 'Sqrt_155:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '385': <tf.Tensor 'Div_156:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '386': <tf.Tensor 'Mul_157:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '387': <tf.Tensor 'Add_158:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '389': <tf.Tensor 'MatMul_159:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '390': <tf.Tensor 'Add_160:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '392': <tf.Tensor 'MatMul_161:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '393': <tf.Tensor 'Add_162:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '395': <tf.Tensor 'MatMul_163:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '396': <tf.Tensor 'Add_164:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '397': <tf.Tensor 'Shape_165:0' shape=(3,) dtype=int64>,\n",
              " '398': <tf.Tensor 'Constant_166:0' shape=() dtype=int64>,\n",
              " '399': <tf.Tensor 'Gather_167:0' shape=() dtype=int64>,\n",
              " '400': <tf.Tensor 'Shape_168:0' shape=(3,) dtype=int64>,\n",
              " '401': <tf.Tensor 'Constant_169:0' shape=() dtype=int64>,\n",
              " '402': <tf.Tensor 'Gather_170:0' shape=() dtype=int64>,\n",
              " '405': <tf.Tensor 'Unsqueeze_171:0' shape=(1,) dtype=int64>,\n",
              " '406': <tf.Tensor 'Unsqueeze_172:0' shape=(1,) dtype=int64>,\n",
              " '409': <tf.Tensor 'Concat_173:0' shape=(4,) dtype=int64>,\n",
              " '410': <tf.Tensor 'Reshape_174:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '411': <tf.Tensor 'Transpose_175:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '412': <tf.Tensor 'Shape_176:0' shape=(3,) dtype=int64>,\n",
              " '413': <tf.Tensor 'Constant_177:0' shape=() dtype=int64>,\n",
              " '414': <tf.Tensor 'Gather_178:0' shape=() dtype=int64>,\n",
              " '415': <tf.Tensor 'Shape_179:0' shape=(3,) dtype=int64>,\n",
              " '416': <tf.Tensor 'Constant_180:0' shape=() dtype=int64>,\n",
              " '417': <tf.Tensor 'Gather_181:0' shape=() dtype=int64>,\n",
              " '420': <tf.Tensor 'Unsqueeze_182:0' shape=(1,) dtype=int64>,\n",
              " '421': <tf.Tensor 'Unsqueeze_183:0' shape=(1,) dtype=int64>,\n",
              " '424': <tf.Tensor 'Concat_184:0' shape=(4,) dtype=int64>,\n",
              " '425': <tf.Tensor 'Reshape_185:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '426': <tf.Tensor 'Shape_186:0' shape=(3,) dtype=int64>,\n",
              " '427': <tf.Tensor 'Constant_187:0' shape=() dtype=int64>,\n",
              " '428': <tf.Tensor 'Gather_188:0' shape=() dtype=int64>,\n",
              " '429': <tf.Tensor 'Shape_189:0' shape=(3,) dtype=int64>,\n",
              " '430': <tf.Tensor 'Constant_190:0' shape=() dtype=int64>,\n",
              " '431': <tf.Tensor 'Gather_191:0' shape=() dtype=int64>,\n",
              " '434': <tf.Tensor 'Unsqueeze_192:0' shape=(1,) dtype=int64>,\n",
              " '435': <tf.Tensor 'Unsqueeze_193:0' shape=(1,) dtype=int64>,\n",
              " '438': <tf.Tensor 'Concat_194:0' shape=(4,) dtype=int64>,\n",
              " '439': <tf.Tensor 'Reshape_195:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '440': <tf.Tensor 'Transpose_196:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '441': <tf.Tensor 'Transpose_197:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '442': <tf.Tensor 'MatMul_198:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '443': <tf.Tensor 'Constant_199:0' shape=() dtype=float32>,\n",
              " '444': <tf.Tensor 'Div_200:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '445': <tf.Tensor 'Add_201:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '446': <tf.Tensor 'Softmax_202:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '447': <tf.Tensor 'MatMul_203:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '448': <tf.Tensor 'Transpose_204:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '449': <tf.Tensor 'Shape_205:0' shape=(4,) dtype=int64>,\n",
              " '450': <tf.Tensor 'Constant_206:0' shape=() dtype=int64>,\n",
              " '451': <tf.Tensor 'Gather_207:0' shape=() dtype=int64>,\n",
              " '452': <tf.Tensor 'Shape_208:0' shape=(4,) dtype=int64>,\n",
              " '453': <tf.Tensor 'Constant_209:0' shape=() dtype=int64>,\n",
              " '454': <tf.Tensor 'Gather_210:0' shape=() dtype=int64>,\n",
              " '456': <tf.Tensor 'Unsqueeze_211:0' shape=(1,) dtype=int64>,\n",
              " '457': <tf.Tensor 'Unsqueeze_212:0' shape=(1,) dtype=int64>,\n",
              " '459': <tf.Tensor 'Concat_213:0' shape=(3,) dtype=int64>,\n",
              " '460': <tf.Tensor 'Reshape_214:0' shape=(?, ?, ?) dtype=float32>,\n",
              " '462': <tf.Tensor 'MatMul_215:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '463': <tf.Tensor 'Add_216:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '464': <tf.Tensor 'Add_217:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '465': <tf.Tensor 'ReduceMean_218:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '466': <tf.Tensor 'Sub_219:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '467': <tf.Tensor 'Constant_220:0' shape=() dtype=float32>,\n",
              " '468': <tf.Tensor 'Pow_221:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '469': <tf.Tensor 'ReduceMean_222:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '470': <tf.Tensor 'Constant_223:0' shape=() dtype=float32>,\n",
              " '471': <tf.Tensor 'Add_224:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '472': <tf.Tensor 'Sqrt_225:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '473': <tf.Tensor 'Div_226:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '474': <tf.Tensor 'Mul_227:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '475': <tf.Tensor 'Add_228:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '477': <tf.Tensor 'MatMul_229:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '478': <tf.Tensor 'Add_230:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '479': <tf.Tensor 'Constant_231:0' shape=() dtype=float32>,\n",
              " '480': <tf.Tensor 'Div_232:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '481': <tf.Tensor 'Erf_233:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '482': <tf.Tensor 'Constant_234:0' shape=() dtype=float32>,\n",
              " '483': <tf.Tensor 'Add_235:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '484': <tf.Tensor 'Mul_236:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '485': <tf.Tensor 'Constant_237:0' shape=() dtype=float32>,\n",
              " '486': <tf.Tensor 'Mul_238:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '488': <tf.Tensor 'MatMul_239:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '489': <tf.Tensor 'Add_240:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '490': <tf.Tensor 'Add_241:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '491': <tf.Tensor 'ReduceMean_242:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '492': <tf.Tensor 'Sub_243:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '493': <tf.Tensor 'Constant_244:0' shape=() dtype=float32>,\n",
              " '494': <tf.Tensor 'Pow_245:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '495': <tf.Tensor 'ReduceMean_246:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '496': <tf.Tensor 'Constant_247:0' shape=() dtype=float32>,\n",
              " '497': <tf.Tensor 'Add_248:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '498': <tf.Tensor 'Sqrt_249:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '499': <tf.Tensor 'Div_250:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '500': <tf.Tensor 'Mul_251:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '501': <tf.Tensor 'Add_252:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '503': <tf.Tensor 'MatMul_253:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '504': <tf.Tensor 'Add_254:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '506': <tf.Tensor 'MatMul_255:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '507': <tf.Tensor 'Add_256:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '509': <tf.Tensor 'MatMul_257:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '510': <tf.Tensor 'Add_258:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '511': <tf.Tensor 'Shape_259:0' shape=(3,) dtype=int64>,\n",
              " '512': <tf.Tensor 'Constant_260:0' shape=() dtype=int64>,\n",
              " '513': <tf.Tensor 'Gather_261:0' shape=() dtype=int64>,\n",
              " '514': <tf.Tensor 'Shape_262:0' shape=(3,) dtype=int64>,\n",
              " '515': <tf.Tensor 'Constant_263:0' shape=() dtype=int64>,\n",
              " '516': <tf.Tensor 'Gather_264:0' shape=() dtype=int64>,\n",
              " '519': <tf.Tensor 'Unsqueeze_265:0' shape=(1,) dtype=int64>,\n",
              " '520': <tf.Tensor 'Unsqueeze_266:0' shape=(1,) dtype=int64>,\n",
              " '523': <tf.Tensor 'Concat_267:0' shape=(4,) dtype=int64>,\n",
              " '524': <tf.Tensor 'Reshape_268:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '525': <tf.Tensor 'Transpose_269:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '526': <tf.Tensor 'Shape_270:0' shape=(3,) dtype=int64>,\n",
              " '527': <tf.Tensor 'Constant_271:0' shape=() dtype=int64>,\n",
              " '528': <tf.Tensor 'Gather_272:0' shape=() dtype=int64>,\n",
              " '529': <tf.Tensor 'Shape_273:0' shape=(3,) dtype=int64>,\n",
              " '530': <tf.Tensor 'Constant_274:0' shape=() dtype=int64>,\n",
              " '531': <tf.Tensor 'Gather_275:0' shape=() dtype=int64>,\n",
              " '534': <tf.Tensor 'Unsqueeze_276:0' shape=(1,) dtype=int64>,\n",
              " '535': <tf.Tensor 'Unsqueeze_277:0' shape=(1,) dtype=int64>,\n",
              " '538': <tf.Tensor 'Concat_278:0' shape=(4,) dtype=int64>,\n",
              " '539': <tf.Tensor 'Reshape_279:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '540': <tf.Tensor 'Shape_280:0' shape=(3,) dtype=int64>,\n",
              " '541': <tf.Tensor 'Constant_281:0' shape=() dtype=int64>,\n",
              " '542': <tf.Tensor 'Gather_282:0' shape=() dtype=int64>,\n",
              " '543': <tf.Tensor 'Shape_283:0' shape=(3,) dtype=int64>,\n",
              " '544': <tf.Tensor 'Constant_284:0' shape=() dtype=int64>,\n",
              " '545': <tf.Tensor 'Gather_285:0' shape=() dtype=int64>,\n",
              " '548': <tf.Tensor 'Unsqueeze_286:0' shape=(1,) dtype=int64>,\n",
              " '549': <tf.Tensor 'Unsqueeze_287:0' shape=(1,) dtype=int64>,\n",
              " '552': <tf.Tensor 'Concat_288:0' shape=(4,) dtype=int64>,\n",
              " '553': <tf.Tensor 'Reshape_289:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '554': <tf.Tensor 'Transpose_290:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '555': <tf.Tensor 'Transpose_291:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '556': <tf.Tensor 'MatMul_292:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '557': <tf.Tensor 'Constant_293:0' shape=() dtype=float32>,\n",
              " '558': <tf.Tensor 'Div_294:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '559': <tf.Tensor 'Add_295:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '560': <tf.Tensor 'Softmax_296:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '561': <tf.Tensor 'MatMul_297:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '562': <tf.Tensor 'Transpose_298:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '563': <tf.Tensor 'Shape_299:0' shape=(4,) dtype=int64>,\n",
              " '564': <tf.Tensor 'Constant_300:0' shape=() dtype=int64>,\n",
              " '565': <tf.Tensor 'Gather_301:0' shape=() dtype=int64>,\n",
              " '566': <tf.Tensor 'Shape_302:0' shape=(4,) dtype=int64>,\n",
              " '567': <tf.Tensor 'Constant_303:0' shape=() dtype=int64>,\n",
              " '568': <tf.Tensor 'Gather_304:0' shape=() dtype=int64>,\n",
              " '570': <tf.Tensor 'Unsqueeze_305:0' shape=(1,) dtype=int64>,\n",
              " '571': <tf.Tensor 'Unsqueeze_306:0' shape=(1,) dtype=int64>,\n",
              " '573': <tf.Tensor 'Concat_307:0' shape=(3,) dtype=int64>,\n",
              " '574': <tf.Tensor 'Reshape_308:0' shape=(?, ?, ?) dtype=float32>,\n",
              " '576': <tf.Tensor 'MatMul_309:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '577': <tf.Tensor 'Add_310:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '578': <tf.Tensor 'Add_311:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '579': <tf.Tensor 'ReduceMean_312:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '580': <tf.Tensor 'Sub_313:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '581': <tf.Tensor 'Constant_314:0' shape=() dtype=float32>,\n",
              " '582': <tf.Tensor 'Pow_315:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '583': <tf.Tensor 'ReduceMean_316:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '584': <tf.Tensor 'Constant_317:0' shape=() dtype=float32>,\n",
              " '585': <tf.Tensor 'Add_318:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '586': <tf.Tensor 'Sqrt_319:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '587': <tf.Tensor 'Div_320:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '588': <tf.Tensor 'Mul_321:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '589': <tf.Tensor 'Add_322:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '591': <tf.Tensor 'MatMul_323:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '592': <tf.Tensor 'Add_324:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '593': <tf.Tensor 'Constant_325:0' shape=() dtype=float32>,\n",
              " '594': <tf.Tensor 'Div_326:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '595': <tf.Tensor 'Erf_327:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '596': <tf.Tensor 'Constant_328:0' shape=() dtype=float32>,\n",
              " '597': <tf.Tensor 'Add_329:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '598': <tf.Tensor 'Mul_330:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '599': <tf.Tensor 'Constant_331:0' shape=() dtype=float32>,\n",
              " '600': <tf.Tensor 'Mul_332:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '602': <tf.Tensor 'MatMul_333:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '603': <tf.Tensor 'Add_334:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '604': <tf.Tensor 'Add_335:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '605': <tf.Tensor 'ReduceMean_336:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '606': <tf.Tensor 'Sub_337:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '607': <tf.Tensor 'Constant_338:0' shape=() dtype=float32>,\n",
              " '608': <tf.Tensor 'Pow_339:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '609': <tf.Tensor 'ReduceMean_340:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '610': <tf.Tensor 'Constant_341:0' shape=() dtype=float32>,\n",
              " '611': <tf.Tensor 'Add_342:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '612': <tf.Tensor 'Sqrt_343:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '613': <tf.Tensor 'Div_344:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '614': <tf.Tensor 'Mul_345:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '615': <tf.Tensor 'Add_346:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '617': <tf.Tensor 'MatMul_347:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '618': <tf.Tensor 'Add_348:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '620': <tf.Tensor 'MatMul_349:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '621': <tf.Tensor 'Add_350:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '623': <tf.Tensor 'MatMul_351:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '624': <tf.Tensor 'Add_352:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '625': <tf.Tensor 'Shape_353:0' shape=(3,) dtype=int64>,\n",
              " '626': <tf.Tensor 'Constant_354:0' shape=() dtype=int64>,\n",
              " '627': <tf.Tensor 'Gather_355:0' shape=() dtype=int64>,\n",
              " '628': <tf.Tensor 'Shape_356:0' shape=(3,) dtype=int64>,\n",
              " '629': <tf.Tensor 'Constant_357:0' shape=() dtype=int64>,\n",
              " '630': <tf.Tensor 'Gather_358:0' shape=() dtype=int64>,\n",
              " '633': <tf.Tensor 'Unsqueeze_359:0' shape=(1,) dtype=int64>,\n",
              " '634': <tf.Tensor 'Unsqueeze_360:0' shape=(1,) dtype=int64>,\n",
              " '637': <tf.Tensor 'Concat_361:0' shape=(4,) dtype=int64>,\n",
              " '638': <tf.Tensor 'Reshape_362:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '639': <tf.Tensor 'Transpose_363:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '640': <tf.Tensor 'Shape_364:0' shape=(3,) dtype=int64>,\n",
              " '641': <tf.Tensor 'Constant_365:0' shape=() dtype=int64>,\n",
              " '642': <tf.Tensor 'Gather_366:0' shape=() dtype=int64>,\n",
              " '643': <tf.Tensor 'Shape_367:0' shape=(3,) dtype=int64>,\n",
              " '644': <tf.Tensor 'Constant_368:0' shape=() dtype=int64>,\n",
              " '645': <tf.Tensor 'Gather_369:0' shape=() dtype=int64>,\n",
              " '648': <tf.Tensor 'Unsqueeze_370:0' shape=(1,) dtype=int64>,\n",
              " '649': <tf.Tensor 'Unsqueeze_371:0' shape=(1,) dtype=int64>,\n",
              " '652': <tf.Tensor 'Concat_372:0' shape=(4,) dtype=int64>,\n",
              " '653': <tf.Tensor 'Reshape_373:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '654': <tf.Tensor 'Shape_374:0' shape=(3,) dtype=int64>,\n",
              " '655': <tf.Tensor 'Constant_375:0' shape=() dtype=int64>,\n",
              " '656': <tf.Tensor 'Gather_376:0' shape=() dtype=int64>,\n",
              " '657': <tf.Tensor 'Shape_377:0' shape=(3,) dtype=int64>,\n",
              " '658': <tf.Tensor 'Constant_378:0' shape=() dtype=int64>,\n",
              " '659': <tf.Tensor 'Gather_379:0' shape=() dtype=int64>,\n",
              " '662': <tf.Tensor 'Unsqueeze_380:0' shape=(1,) dtype=int64>,\n",
              " '663': <tf.Tensor 'Unsqueeze_381:0' shape=(1,) dtype=int64>,\n",
              " '666': <tf.Tensor 'Concat_382:0' shape=(4,) dtype=int64>,\n",
              " '667': <tf.Tensor 'Reshape_383:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '668': <tf.Tensor 'Transpose_384:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '669': <tf.Tensor 'Transpose_385:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '670': <tf.Tensor 'MatMul_386:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '671': <tf.Tensor 'Constant_387:0' shape=() dtype=float32>,\n",
              " '672': <tf.Tensor 'Div_388:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '673': <tf.Tensor 'Add_389:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '674': <tf.Tensor 'Softmax_390:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '675': <tf.Tensor 'MatMul_391:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '676': <tf.Tensor 'Transpose_392:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '677': <tf.Tensor 'Shape_393:0' shape=(4,) dtype=int64>,\n",
              " '678': <tf.Tensor 'Constant_394:0' shape=() dtype=int64>,\n",
              " '679': <tf.Tensor 'Gather_395:0' shape=() dtype=int64>,\n",
              " '680': <tf.Tensor 'Shape_396:0' shape=(4,) dtype=int64>,\n",
              " '681': <tf.Tensor 'Constant_397:0' shape=() dtype=int64>,\n",
              " '682': <tf.Tensor 'Gather_398:0' shape=() dtype=int64>,\n",
              " '684': <tf.Tensor 'Unsqueeze_399:0' shape=(1,) dtype=int64>,\n",
              " '685': <tf.Tensor 'Unsqueeze_400:0' shape=(1,) dtype=int64>,\n",
              " '687': <tf.Tensor 'Concat_401:0' shape=(3,) dtype=int64>,\n",
              " '688': <tf.Tensor 'Reshape_402:0' shape=(?, ?, ?) dtype=float32>,\n",
              " '690': <tf.Tensor 'MatMul_403:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '691': <tf.Tensor 'Add_404:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '692': <tf.Tensor 'Add_405:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '693': <tf.Tensor 'ReduceMean_406:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '694': <tf.Tensor 'Sub_407:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '695': <tf.Tensor 'Constant_408:0' shape=() dtype=float32>,\n",
              " '696': <tf.Tensor 'Pow_409:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '697': <tf.Tensor 'ReduceMean_410:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '698': <tf.Tensor 'Constant_411:0' shape=() dtype=float32>,\n",
              " '699': <tf.Tensor 'Add_412:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '700': <tf.Tensor 'Sqrt_413:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '701': <tf.Tensor 'Div_414:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '702': <tf.Tensor 'Mul_415:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '703': <tf.Tensor 'Add_416:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '705': <tf.Tensor 'MatMul_417:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '706': <tf.Tensor 'Add_418:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '707': <tf.Tensor 'Constant_419:0' shape=() dtype=float32>,\n",
              " '708': <tf.Tensor 'Div_420:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '709': <tf.Tensor 'Erf_421:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '710': <tf.Tensor 'Constant_422:0' shape=() dtype=float32>,\n",
              " '711': <tf.Tensor 'Add_423:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '712': <tf.Tensor 'Mul_424:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '713': <tf.Tensor 'Constant_425:0' shape=() dtype=float32>,\n",
              " '714': <tf.Tensor 'Mul_426:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '716': <tf.Tensor 'MatMul_427:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '717': <tf.Tensor 'Add_428:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '718': <tf.Tensor 'Add_429:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '719': <tf.Tensor 'ReduceMean_430:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '720': <tf.Tensor 'Sub_431:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '721': <tf.Tensor 'Constant_432:0' shape=() dtype=float32>,\n",
              " '722': <tf.Tensor 'Pow_433:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '723': <tf.Tensor 'ReduceMean_434:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '724': <tf.Tensor 'Constant_435:0' shape=() dtype=float32>,\n",
              " '725': <tf.Tensor 'Add_436:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '726': <tf.Tensor 'Sqrt_437:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '727': <tf.Tensor 'Div_438:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '728': <tf.Tensor 'Mul_439:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '729': <tf.Tensor 'Add_440:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '731': <tf.Tensor 'MatMul_441:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '732': <tf.Tensor 'Add_442:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '734': <tf.Tensor 'MatMul_443:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '735': <tf.Tensor 'Add_444:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '737': <tf.Tensor 'MatMul_445:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '738': <tf.Tensor 'Add_446:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '739': <tf.Tensor 'Shape_447:0' shape=(3,) dtype=int64>,\n",
              " '740': <tf.Tensor 'Constant_448:0' shape=() dtype=int64>,\n",
              " '741': <tf.Tensor 'Gather_449:0' shape=() dtype=int64>,\n",
              " '742': <tf.Tensor 'Shape_450:0' shape=(3,) dtype=int64>,\n",
              " '743': <tf.Tensor 'Constant_451:0' shape=() dtype=int64>,\n",
              " '744': <tf.Tensor 'Gather_452:0' shape=() dtype=int64>,\n",
              " '747': <tf.Tensor 'Unsqueeze_453:0' shape=(1,) dtype=int64>,\n",
              " '748': <tf.Tensor 'Unsqueeze_454:0' shape=(1,) dtype=int64>,\n",
              " '751': <tf.Tensor 'Concat_455:0' shape=(4,) dtype=int64>,\n",
              " '752': <tf.Tensor 'Reshape_456:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '753': <tf.Tensor 'Transpose_457:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '754': <tf.Tensor 'Shape_458:0' shape=(3,) dtype=int64>,\n",
              " '755': <tf.Tensor 'Constant_459:0' shape=() dtype=int64>,\n",
              " '756': <tf.Tensor 'Gather_460:0' shape=() dtype=int64>,\n",
              " '757': <tf.Tensor 'Shape_461:0' shape=(3,) dtype=int64>,\n",
              " '758': <tf.Tensor 'Constant_462:0' shape=() dtype=int64>,\n",
              " '759': <tf.Tensor 'Gather_463:0' shape=() dtype=int64>,\n",
              " '762': <tf.Tensor 'Unsqueeze_464:0' shape=(1,) dtype=int64>,\n",
              " '763': <tf.Tensor 'Unsqueeze_465:0' shape=(1,) dtype=int64>,\n",
              " '766': <tf.Tensor 'Concat_466:0' shape=(4,) dtype=int64>,\n",
              " '767': <tf.Tensor 'Reshape_467:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '768': <tf.Tensor 'Shape_468:0' shape=(3,) dtype=int64>,\n",
              " '769': <tf.Tensor 'Constant_469:0' shape=() dtype=int64>,\n",
              " '770': <tf.Tensor 'Gather_470:0' shape=() dtype=int64>,\n",
              " '771': <tf.Tensor 'Shape_471:0' shape=(3,) dtype=int64>,\n",
              " '772': <tf.Tensor 'Constant_472:0' shape=() dtype=int64>,\n",
              " '773': <tf.Tensor 'Gather_473:0' shape=() dtype=int64>,\n",
              " '776': <tf.Tensor 'Unsqueeze_474:0' shape=(1,) dtype=int64>,\n",
              " '777': <tf.Tensor 'Unsqueeze_475:0' shape=(1,) dtype=int64>,\n",
              " '780': <tf.Tensor 'Concat_476:0' shape=(4,) dtype=int64>,\n",
              " '781': <tf.Tensor 'Reshape_477:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '782': <tf.Tensor 'Transpose_478:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '783': <tf.Tensor 'Transpose_479:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '784': <tf.Tensor 'MatMul_480:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '785': <tf.Tensor 'Constant_481:0' shape=() dtype=float32>,\n",
              " '786': <tf.Tensor 'Div_482:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '787': <tf.Tensor 'Add_483:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '788': <tf.Tensor 'Softmax_484:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '789': <tf.Tensor 'MatMul_485:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '790': <tf.Tensor 'Transpose_486:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '791': <tf.Tensor 'Shape_487:0' shape=(4,) dtype=int64>,\n",
              " '792': <tf.Tensor 'Constant_488:0' shape=() dtype=int64>,\n",
              " '793': <tf.Tensor 'Gather_489:0' shape=() dtype=int64>,\n",
              " '794': <tf.Tensor 'Shape_490:0' shape=(4,) dtype=int64>,\n",
              " '795': <tf.Tensor 'Constant_491:0' shape=() dtype=int64>,\n",
              " '796': <tf.Tensor 'Gather_492:0' shape=() dtype=int64>,\n",
              " '798': <tf.Tensor 'Unsqueeze_493:0' shape=(1,) dtype=int64>,\n",
              " '799': <tf.Tensor 'Unsqueeze_494:0' shape=(1,) dtype=int64>,\n",
              " '801': <tf.Tensor 'Concat_495:0' shape=(3,) dtype=int64>,\n",
              " '802': <tf.Tensor 'Reshape_496:0' shape=(?, ?, ?) dtype=float32>,\n",
              " '804': <tf.Tensor 'MatMul_497:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '805': <tf.Tensor 'Add_498:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '806': <tf.Tensor 'Add_499:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '807': <tf.Tensor 'ReduceMean_500:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '808': <tf.Tensor 'Sub_501:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '809': <tf.Tensor 'Constant_502:0' shape=() dtype=float32>,\n",
              " '810': <tf.Tensor 'Pow_503:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '811': <tf.Tensor 'ReduceMean_504:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '812': <tf.Tensor 'Constant_505:0' shape=() dtype=float32>,\n",
              " '813': <tf.Tensor 'Add_506:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '814': <tf.Tensor 'Sqrt_507:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '815': <tf.Tensor 'Div_508:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '816': <tf.Tensor 'Mul_509:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '817': <tf.Tensor 'Add_510:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '819': <tf.Tensor 'MatMul_511:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '820': <tf.Tensor 'Add_512:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '821': <tf.Tensor 'Constant_513:0' shape=() dtype=float32>,\n",
              " '822': <tf.Tensor 'Div_514:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '823': <tf.Tensor 'Erf_515:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '824': <tf.Tensor 'Constant_516:0' shape=() dtype=float32>,\n",
              " '825': <tf.Tensor 'Add_517:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '826': <tf.Tensor 'Mul_518:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '827': <tf.Tensor 'Constant_519:0' shape=() dtype=float32>,\n",
              " '828': <tf.Tensor 'Mul_520:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '830': <tf.Tensor 'MatMul_521:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '831': <tf.Tensor 'Add_522:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '832': <tf.Tensor 'Add_523:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '833': <tf.Tensor 'ReduceMean_524:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '834': <tf.Tensor 'Sub_525:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '835': <tf.Tensor 'Constant_526:0' shape=() dtype=float32>,\n",
              " '836': <tf.Tensor 'Pow_527:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '837': <tf.Tensor 'ReduceMean_528:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '838': <tf.Tensor 'Constant_529:0' shape=() dtype=float32>,\n",
              " '839': <tf.Tensor 'Add_530:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '840': <tf.Tensor 'Sqrt_531:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '841': <tf.Tensor 'Div_532:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '842': <tf.Tensor 'Mul_533:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '843': <tf.Tensor 'Add_534:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '845': <tf.Tensor 'MatMul_535:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '846': <tf.Tensor 'Add_536:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '848': <tf.Tensor 'MatMul_537:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '849': <tf.Tensor 'Add_538:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '851': <tf.Tensor 'MatMul_539:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '852': <tf.Tensor 'Add_540:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '853': <tf.Tensor 'Shape_541:0' shape=(3,) dtype=int64>,\n",
              " '854': <tf.Tensor 'Constant_542:0' shape=() dtype=int64>,\n",
              " '855': <tf.Tensor 'Gather_543:0' shape=() dtype=int64>,\n",
              " '856': <tf.Tensor 'Shape_544:0' shape=(3,) dtype=int64>,\n",
              " '857': <tf.Tensor 'Constant_545:0' shape=() dtype=int64>,\n",
              " '858': <tf.Tensor 'Gather_546:0' shape=() dtype=int64>,\n",
              " '861': <tf.Tensor 'Unsqueeze_547:0' shape=(1,) dtype=int64>,\n",
              " '862': <tf.Tensor 'Unsqueeze_548:0' shape=(1,) dtype=int64>,\n",
              " '865': <tf.Tensor 'Concat_549:0' shape=(4,) dtype=int64>,\n",
              " '866': <tf.Tensor 'Reshape_550:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '867': <tf.Tensor 'Transpose_551:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '868': <tf.Tensor 'Shape_552:0' shape=(3,) dtype=int64>,\n",
              " '869': <tf.Tensor 'Constant_553:0' shape=() dtype=int64>,\n",
              " '870': <tf.Tensor 'Gather_554:0' shape=() dtype=int64>,\n",
              " '871': <tf.Tensor 'Shape_555:0' shape=(3,) dtype=int64>,\n",
              " '872': <tf.Tensor 'Constant_556:0' shape=() dtype=int64>,\n",
              " '873': <tf.Tensor 'Gather_557:0' shape=() dtype=int64>,\n",
              " '876': <tf.Tensor 'Unsqueeze_558:0' shape=(1,) dtype=int64>,\n",
              " '877': <tf.Tensor 'Unsqueeze_559:0' shape=(1,) dtype=int64>,\n",
              " '880': <tf.Tensor 'Concat_560:0' shape=(4,) dtype=int64>,\n",
              " '881': <tf.Tensor 'Reshape_561:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '882': <tf.Tensor 'Shape_562:0' shape=(3,) dtype=int64>,\n",
              " '883': <tf.Tensor 'Constant_563:0' shape=() dtype=int64>,\n",
              " '884': <tf.Tensor 'Gather_564:0' shape=() dtype=int64>,\n",
              " '885': <tf.Tensor 'Shape_565:0' shape=(3,) dtype=int64>,\n",
              " '886': <tf.Tensor 'Constant_566:0' shape=() dtype=int64>,\n",
              " '887': <tf.Tensor 'Gather_567:0' shape=() dtype=int64>,\n",
              " '890': <tf.Tensor 'Unsqueeze_568:0' shape=(1,) dtype=int64>,\n",
              " '891': <tf.Tensor 'Unsqueeze_569:0' shape=(1,) dtype=int64>,\n",
              " '894': <tf.Tensor 'Concat_570:0' shape=(4,) dtype=int64>,\n",
              " '895': <tf.Tensor 'Reshape_571:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '896': <tf.Tensor 'Transpose_572:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '897': <tf.Tensor 'Transpose_573:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '898': <tf.Tensor 'MatMul_574:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '899': <tf.Tensor 'Constant_575:0' shape=() dtype=float32>,\n",
              " '900': <tf.Tensor 'Div_576:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '901': <tf.Tensor 'Add_577:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '902': <tf.Tensor 'Softmax_578:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '903': <tf.Tensor 'MatMul_579:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '904': <tf.Tensor 'Transpose_580:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '905': <tf.Tensor 'Shape_581:0' shape=(4,) dtype=int64>,\n",
              " '906': <tf.Tensor 'Constant_582:0' shape=() dtype=int64>,\n",
              " '907': <tf.Tensor 'Gather_583:0' shape=() dtype=int64>,\n",
              " '908': <tf.Tensor 'Shape_584:0' shape=(4,) dtype=int64>,\n",
              " '909': <tf.Tensor 'Constant_585:0' shape=() dtype=int64>,\n",
              " '910': <tf.Tensor 'Gather_586:0' shape=() dtype=int64>,\n",
              " '912': <tf.Tensor 'Unsqueeze_587:0' shape=(1,) dtype=int64>,\n",
              " '913': <tf.Tensor 'Unsqueeze_588:0' shape=(1,) dtype=int64>,\n",
              " '915': <tf.Tensor 'Concat_589:0' shape=(3,) dtype=int64>,\n",
              " '916': <tf.Tensor 'Reshape_590:0' shape=(?, ?, ?) dtype=float32>,\n",
              " '918': <tf.Tensor 'MatMul_591:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '919': <tf.Tensor 'Add_592:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '920': <tf.Tensor 'Add_593:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '921': <tf.Tensor 'ReduceMean_594:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '922': <tf.Tensor 'Sub_595:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '923': <tf.Tensor 'Constant_596:0' shape=() dtype=float32>,\n",
              " '924': <tf.Tensor 'Pow_597:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '925': <tf.Tensor 'ReduceMean_598:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '926': <tf.Tensor 'Constant_599:0' shape=() dtype=float32>,\n",
              " '927': <tf.Tensor 'Add_600:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '928': <tf.Tensor 'Sqrt_601:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '929': <tf.Tensor 'Div_602:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '930': <tf.Tensor 'Mul_603:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '931': <tf.Tensor 'Add_604:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '933': <tf.Tensor 'MatMul_605:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '934': <tf.Tensor 'Add_606:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '935': <tf.Tensor 'Constant_607:0' shape=() dtype=float32>,\n",
              " '936': <tf.Tensor 'Div_608:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '937': <tf.Tensor 'Erf_609:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '938': <tf.Tensor 'Constant_610:0' shape=() dtype=float32>,\n",
              " '939': <tf.Tensor 'Add_611:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '940': <tf.Tensor 'Mul_612:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '941': <tf.Tensor 'Constant_613:0' shape=() dtype=float32>,\n",
              " '942': <tf.Tensor 'Mul_614:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '944': <tf.Tensor 'MatMul_615:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '945': <tf.Tensor 'Add_616:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '946': <tf.Tensor 'Add_617:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '947': <tf.Tensor 'ReduceMean_618:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '948': <tf.Tensor 'Sub_619:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '949': <tf.Tensor 'Constant_620:0' shape=() dtype=float32>,\n",
              " '950': <tf.Tensor 'Pow_621:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '951': <tf.Tensor 'ReduceMean_622:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '952': <tf.Tensor 'Constant_623:0' shape=() dtype=float32>,\n",
              " '953': <tf.Tensor 'Add_624:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '954': <tf.Tensor 'Sqrt_625:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '955': <tf.Tensor 'Div_626:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '956': <tf.Tensor 'Mul_627:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '957': <tf.Tensor 'Add_628:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '959': <tf.Tensor 'MatMul_629:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '960': <tf.Tensor 'Add_630:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '962': <tf.Tensor 'MatMul_631:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '963': <tf.Tensor 'Add_632:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '965': <tf.Tensor 'MatMul_633:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '966': <tf.Tensor 'Add_634:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '967': <tf.Tensor 'Shape_635:0' shape=(3,) dtype=int64>,\n",
              " '968': <tf.Tensor 'Constant_636:0' shape=() dtype=int64>,\n",
              " '969': <tf.Tensor 'Gather_637:0' shape=() dtype=int64>,\n",
              " '970': <tf.Tensor 'Shape_638:0' shape=(3,) dtype=int64>,\n",
              " '971': <tf.Tensor 'Constant_639:0' shape=() dtype=int64>,\n",
              " '972': <tf.Tensor 'Gather_640:0' shape=() dtype=int64>,\n",
              " '975': <tf.Tensor 'Unsqueeze_641:0' shape=(1,) dtype=int64>,\n",
              " '976': <tf.Tensor 'Unsqueeze_642:0' shape=(1,) dtype=int64>,\n",
              " '979': <tf.Tensor 'Concat_643:0' shape=(4,) dtype=int64>,\n",
              " '980': <tf.Tensor 'Reshape_644:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '981': <tf.Tensor 'Transpose_645:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '982': <tf.Tensor 'Shape_646:0' shape=(3,) dtype=int64>,\n",
              " '983': <tf.Tensor 'Constant_647:0' shape=() dtype=int64>,\n",
              " '984': <tf.Tensor 'Gather_648:0' shape=() dtype=int64>,\n",
              " '985': <tf.Tensor 'Shape_649:0' shape=(3,) dtype=int64>,\n",
              " '986': <tf.Tensor 'Constant_650:0' shape=() dtype=int64>,\n",
              " '987': <tf.Tensor 'Gather_651:0' shape=() dtype=int64>,\n",
              " '990': <tf.Tensor 'Unsqueeze_652:0' shape=(1,) dtype=int64>,\n",
              " '991': <tf.Tensor 'Unsqueeze_653:0' shape=(1,) dtype=int64>,\n",
              " '994': <tf.Tensor 'Concat_654:0' shape=(4,) dtype=int64>,\n",
              " '995': <tf.Tensor 'Reshape_655:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '996': <tf.Tensor 'Shape_656:0' shape=(3,) dtype=int64>,\n",
              " '997': <tf.Tensor 'Constant_657:0' shape=() dtype=int64>,\n",
              " '998': <tf.Tensor 'Gather_658:0' shape=() dtype=int64>,\n",
              " '999': <tf.Tensor 'Shape_659:0' shape=(3,) dtype=int64>,\n",
              " '1000': <tf.Tensor 'Constant_660:0' shape=() dtype=int64>,\n",
              " '1001': <tf.Tensor 'Gather_661:0' shape=() dtype=int64>,\n",
              " '1004': <tf.Tensor 'Unsqueeze_662:0' shape=(1,) dtype=int64>,\n",
              " '1005': <tf.Tensor 'Unsqueeze_663:0' shape=(1,) dtype=int64>,\n",
              " '1008': <tf.Tensor 'Concat_664:0' shape=(4,) dtype=int64>,\n",
              " '1009': <tf.Tensor 'Reshape_665:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '1010': <tf.Tensor 'Transpose_666:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '1011': <tf.Tensor 'Transpose_667:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '1012': <tf.Tensor 'MatMul_668:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '1013': <tf.Tensor 'Constant_669:0' shape=() dtype=float32>,\n",
              " '1014': <tf.Tensor 'Div_670:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '1015': <tf.Tensor 'Add_671:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '1016': <tf.Tensor 'Softmax_672:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '1017': <tf.Tensor 'MatMul_673:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '1018': <tf.Tensor 'Transpose_674:0' shape=(?, ?, ?, ?) dtype=float32>,\n",
              " '1019': <tf.Tensor 'Shape_675:0' shape=(4,) dtype=int64>,\n",
              " '1020': <tf.Tensor 'Constant_676:0' shape=() dtype=int64>,\n",
              " '1021': <tf.Tensor 'Gather_677:0' shape=() dtype=int64>,\n",
              " '1022': <tf.Tensor 'Shape_678:0' shape=(4,) dtype=int64>,\n",
              " '1023': <tf.Tensor 'Constant_679:0' shape=() dtype=int64>,\n",
              " '1024': <tf.Tensor 'Gather_680:0' shape=() dtype=int64>,\n",
              " '1026': <tf.Tensor 'Unsqueeze_681:0' shape=(1,) dtype=int64>,\n",
              " '1027': <tf.Tensor 'Unsqueeze_682:0' shape=(1,) dtype=int64>,\n",
              " '1029': <tf.Tensor 'Concat_683:0' shape=(3,) dtype=int64>,\n",
              " '1030': <tf.Tensor 'Reshape_684:0' shape=(?, ?, ?) dtype=float32>,\n",
              " '1032': <tf.Tensor 'MatMul_685:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '1033': <tf.Tensor 'Add_686:0' shape=(?, ?, 768) dtype=float32>,\n",
              " '1034': <tf.Tensor 'Add_687:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '1035': <tf.Tensor 'ReduceMean_688:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '1036': <tf.Tensor 'Sub_689:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '1037': <tf.Tensor 'Constant_690:0' shape=() dtype=float32>,\n",
              " '1038': <tf.Tensor 'Pow_691:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '1039': <tf.Tensor 'ReduceMean_692:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '1040': <tf.Tensor 'Constant_693:0' shape=() dtype=float32>,\n",
              " '1041': <tf.Tensor 'Add_694:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '1042': <tf.Tensor 'Sqrt_695:0' shape=(?, 128, 1) dtype=float32>,\n",
              " '1043': <tf.Tensor 'Div_696:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '1044': <tf.Tensor 'Mul_697:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '1045': <tf.Tensor 'Add_698:0' shape=(?, 128, 768) dtype=float32>,\n",
              " '1047': <tf.Tensor 'MatMul_699:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '1048': <tf.Tensor 'Add_700:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '1049': <tf.Tensor 'Constant_701:0' shape=() dtype=float32>,\n",
              " '1050': <tf.Tensor 'Div_702:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '1051': <tf.Tensor 'Erf_703:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '1052': <tf.Tensor 'Constant_704:0' shape=() dtype=float32>,\n",
              " '1053': <tf.Tensor 'Add_705:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '1054': <tf.Tensor 'Mul_706:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " '1055': <tf.Tensor 'Constant_707:0' shape=() dtype=float32>,\n",
              " '1056': <tf.Tensor 'Mul_708:0' shape=(?, 128, 3072) dtype=float32>,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TTuoFxYyC_G3",
        "outputId": "66ac3f40-067f-42d3-e5a8-9ef40ab6933a"
      },
      "source": [
        "tf_rep.outputs"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['outputs']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "YQ7m3b3hQOJ_",
        "outputId": "2c4be51c-89b1-43ec-e3be-fdb584388ee3"
      },
      "source": [
        "tf_rep.outputs[0]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'outputs'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "bm3KuiGz6YRm",
        "outputId": "8438b306-30c6-43df-921b-96447cfa6351"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import shutil\n",
        "\n",
        "tf.reset_default_graph()            \n",
        "\n",
        "\n",
        "input_ids_tensor = tf_rep.tensor_dict[\"input_ids\"]\n",
        "input_bbox_tensor = tf_rep.tensor_dict[\"input_bbox\"]\n",
        "attention_mask_tensor = tf_rep.tensor_dict[\"attention_mask\"]\n",
        "token_type_ids_tensor = tf_rep.tensor_dict[\"token_type_ids\"]\n",
        "\n",
        "output_tensor = tf_rep.tensor_dict[\"outputs\"]\n",
        "\n",
        "shutil.rmtree(f\"{TF_MODEL_PATH}/{MODEL_NAME}\", ignore_errors=True)\n",
        "\n",
        "with tf.Session(graph=tf_rep.graph) as session:\n",
        "    \n",
        "    a = tf.Variable(0)\n",
        "    \n",
        "    init = tf.global_variables_initializer()\n",
        "    \n",
        "    loss = tf.identity(output_tensor, name=\"loss\")\n",
        "    logits = tf.identity(output_tensor, name=\"logits\")\n",
        "    hidden_states = tf.identity(output_tensor, name=\"hidden_states\")\n",
        "    attentions = tf.identity(output_tensor, name=\"attentions\")\n",
        "     \n",
        "    session.run(init)    \n",
        "    \n",
        "    tf.saved_model.simple_save(\n",
        "        session,\n",
        "        f\"{TF_MODEL_PATH}/{MODEL_NAME}\",\n",
        "        inputs={\n",
        "            \"input_ids\": input_ids_tensor,\n",
        "            \"input_bbox\": input_bbox_tensor,\n",
        "            \"attention_mask\": attention_mask_tensor,\n",
        "            \"token_type_ids\": token_type_ids_tensor\n",
        "        },\n",
        "        outputs={\n",
        "            \"loss\": loss,\n",
        "            \"logits\": logits,\n",
        "            \"hidden_states\": hidden_states,\n",
        "            \"attentions\": attentions\n",
        "        }\n",
        "    )\n",
        "    \n",
        "import os\n",
        "os.mkdir(f\"{TF_MODEL_PATH}/{MODEL_NAME}/assets\")\n",
        "with open(f\"{TF_MODEL_PATH}/{MODEL_NAME}/assets/labels.txt\", \"w\") as F:\n",
        "    for label_id in config.id2label:\n",
        "        F.write(config.id2label[label_id] + \"\\n\")\n",
        "\n",
        "shutil.copy(f\"{PRETRAINED_MODEL}/vocab.txt\", f\"{TF_MODEL_PATH}/{MODEL_NAME}/assets/vocab.txt\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-14-e22f5a4e9ba0>:42: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
            "INFO:tensorflow:Assets added to graph.\n",
            "INFO:tensorflow:No assets to write.\n",
            "INFO:tensorflow:SavedModel written to: /content/drive/MyDrive/data/Models/tf/LayoutLMSROIE/saved_model.pb\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/data/Models/tf/LayoutLMSROIE/assets/vocab.txt'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQH4xp6p6YI9",
        "outputId": "c5671091-6c0f-4b60-c7ce-3e013b3b135a"
      },
      "source": [
        "!cd $TF_MODEL_PATH/$MODEL_NAME ; zip -r ../\"$MODEL_NAME\".zip . *"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: variables/ (stored 0%)\n",
            "  adding: variables/variables.data-00000-of-00001 (stored 0%)\n",
            "  adding: variables/variables.index (deflated 39%)\n",
            "  adding: saved_model.pb (deflated 8%)\n",
            "  adding: assets/ (stored 0%)\n",
            "  adding: assets/labels.txt (deflated 38%)\n",
            "  adding: assets/vocab.txt (deflated 53%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0L8oEm-hMiC_",
        "outputId": "f3eafa71-c329-4b09-8609-38f805c5b5eb"
      },
      "source": [
        "!ls $TF_MODEL_PATH/$MODEL_NAME/assets"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "labels.txt  vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lw7dnVdUMu_I",
        "outputId": "5adf41a1-d06b-49e4-8e6c-b3d6161c36cd"
      },
      "source": [
        "!cat $TF_MODEL_PATH/$MODEL_NAME/assets/labels.txt"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LABEL_0\n",
            "LABEL_1\n",
            "LABEL_2\n",
            "LABEL_3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKF9q5EZj66n",
        "outputId": "8163eb6f-dace-4eea-bac6-f5b216bd745f"
      },
      "source": [
        "from layoutlm import LayoutlmConfig , LayoutlmForSequenceClassification\n",
        "import torch\n",
        "\n",
        "config = LayoutlmConfig.from_pretrained(\n",
        "    PRETRAINED_MODEL\n",
        ")\n",
        "\n",
        "model = LayoutlmForSequenceClassification.from_pretrained(\n",
        "    PRETRAINED_MODEL,\n",
        "    from_tf=False,\n",
        "    config=config,\n",
        "    cache_dir=None,\n",
        ")\n",
        "\n",
        "dummy_input = {\n",
        "    \"input_ids\": \n",
        "      torch.zeros(1, 128, requires_grad=False, device=\"cpu\").long(),\n",
        "    \"bbox\":\n",
        "      torch.zeros(1, 128, 4, requires_grad=False, device=\"cpu\").long(),\n",
        "    \"attention_mask\":\n",
        "      torch.ones(1, 128, requires_grad=False, device=\"cpu\").long(),    \n",
        "    \"token_type_ids\":\n",
        "      torch.ones(1, 128, requires_grad=False, device=\"cpu\").long(),        \n",
        "}\n",
        "\n",
        "dummy_output = model(**dummy_input)\n",
        "\n",
        "print(\"Model output\")\n",
        "print(dummy_output)\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model output\n",
            "(tensor([[-0.7394, -0.2048,  0.0249,  0.1010]], grad_fn=<AddmmBackward>),)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XxKBzAOknjo",
        "outputId": "e55ee567-8429-4bf4-b48a-7d9d69448421"
      },
      "source": [
        "import os\n",
        "\n",
        "if not os.path.exists(ONNX_MODEL_PATH):\n",
        "    os.mkdir(ONNX_MODEL_PATH)\n",
        "    \n",
        "torch.onnx.export(\n",
        "    model, \n",
        "    (\n",
        "      dummy_input[\"input_ids\"], \n",
        "      dummy_input[\"bbox\"],\n",
        "      dummy_input[\"attention_mask\"],\n",
        "      dummy_input[\"token_type_ids\"],\n",
        "    ),\n",
        "    f\"{ONNX_MODEL_PATH}/{MODEL_NAME}\",\n",
        "    verbose=False,\n",
        "    input_names=['input_ids', 'input_bbox', 'attention_mask', 'token_type_ids'],\n",
        "    output_names=[\"outputs\"],\n",
        "    dynamic_axes={\n",
        "        'input_ids': {0: 'batch', 1: 'max_seq'}, \n",
        "        'attention_mask': {0: 'batch', 1: 'max_seq'}, \n",
        "        'token_type_ids': {0: 'batch', 1: 'max_seq'}, \n",
        "        'bbox': {0: 'batch', 1: 'max_seq'},\n",
        "    }\n",
        ")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/onnx/utils.py:1187: UserWarning: Provided key bbox for dynamic axes is not a valid input/output name\n",
            "  warnings.warn(\"Provided key {} for dynamic axes is not a valid input/output name\".format(key))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjdbPkxYo7hg"
      },
      "source": [
        "import onnx_tf\n",
        "import onnx\n",
        "\n",
        "onnx_model = onnx.load(f\"{ONNX_MODEL_PATH}/{MODEL_NAME}\")"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krZg-cwdo91x"
      },
      "source": [
        "onnx_model"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hJQM2C_mUTa"
      },
      "source": [
        "\n",
        "    #\"/content/drive/MyDrive/data/Models/onnx/LayoutLMSROIE\")\n",
        "    #f\"{ONNX_MODEL_PATH}/{MODEL_NAME}\")\n",
        "tf_rep = onnx_tf.backend.prepare(onnx_model)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SiCouexQsFTc",
        "outputId": "175709b9-b2be-4f30-d477-7f0e7b0b93c7"
      },
      "source": [
        "tf_rep.tensor_dict"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "UhoPSzqQr3Jm",
        "outputId": "09c6b9fd-b4ec-4c08-d277-afa74998bee5"
      },
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "import shutil\n",
        "\n",
        "tf.reset_default_graph()            \n",
        "\n",
        "\n",
        "input_ids_tensor = tf_rep.tensor_dict[\"input_ids\"]\n",
        "input_bbox_tensor = tf_rep.tensor_dict[\"input_bbox\"]\n",
        "attention_mask_tensor = tf_rep.tensor_dict[\"attention_mask\"]\n",
        "token_type_ids_tensor = tf_rep.tensor_dict[\"token_type_ids\"]\n",
        "\n",
        "output_tensor = tf_rep.tensor_dict[\"outputs\"]\n",
        "\n",
        "shutil.rmtree(f\"{TF_MODEL_PATH}/{MODEL_NAME}\", ignore_errors=True)\n",
        "\n",
        "with tf.Session(graph=tf_rep.graph) as session:\n",
        "    \n",
        "    a = tf.Variable(0)\n",
        "    \n",
        "    init = tf.global_variables_initializer()\n",
        "\n",
        "    logits = tf.identity(output_tensor, name=\"logits\")\n",
        "    probs = tf.nn.softmax(output_tensor, axis=-1, name=\"probs\")\n",
        "    predictions = tf.arg_max(logits, dimension=-1, name=\"predictions\")\n",
        "        \n",
        "    session.run(init)    \n",
        "    \n",
        "    tf.saved_model.simple_save(\n",
        "        session,\n",
        "        f\"{TF_MODEL_PATH}/{MODEL_NAME}\",\n",
        "        inputs={\n",
        "            \"input_ids\": input_ids_tensor,\n",
        "            \"input_bbox\": input_bbox_tensor,\n",
        "            \"attention_mask\": attention_mask_tensor,\n",
        "            \"token_type_ids\": token_type_ids_tensor\n",
        "        },\n",
        "        outputs={\n",
        "            \"logits\": logits,\n",
        "            \"probs\": probs,\n",
        "            \"predictions\": predictions\n",
        "        }\n",
        "    )\n",
        "    \n",
        "import os\n",
        "os.mkdir(f\"{TF_MODEL_PATH}/{MODEL_NAME}/assets\")\n",
        "with open(f\"{TF_MODEL_PATH}/{MODEL_NAME}/assets/labels.txt\", \"w\") as F:\n",
        "    for label_id in config.id2label:\n",
        "        F.write(config.id2label[label_id] + \"\\n\")\n",
        "\n",
        "shutil.copy(f\"{PRETRAINED_MODEL}/vocab.txt\", f\"{TF_MODEL_PATH}/{MODEL_NAME}/assets/vocab.txt\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-7ea7febb2e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0minput_ids_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_rep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0minput_bbox_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_rep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"input_bbox\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mattention_mask_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_rep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"attention_mask\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'input_ids'"
          ]
        }
      ]
    }
  ]
}